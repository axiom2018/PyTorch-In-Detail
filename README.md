<img src="https://github.com/axiom2018/PyTorch-In-Detail/blob/main/PyTorch_In_Detail.png?raw=true"/>

# Description

I really love using PyTorch & NLP. I'm constantly explore the basics and more advanced concepts in both. The primary reason I'm putting this on Github is to help others 
understand both NLP concepts and PyTorch basics. <b><i>The code is extremely well commented and potentially can help others learn as well.</i></b> Due to certain links, 
sites, and even documentation with poor explanations, I figured I might as well share my understanding. Also, since I love NLP, the "NLP_In_Detail" file all about just 
that. Playing around with different NLP functionality. However the "Basics_In_Detail" file is strictly non NLP PyTorch code. 


### <b><i>2 side note to keep in mind: </i></b>
1) Admittedly the comment formatting is a tiny bit off. Why? Well I was working on both portions of code at my regular job. So I was using Google Colab on my phone and in 
order to properly <i>SEE</i> the comments, I had to not make them so long in a horizontal sense.

2) I've documented every error I've overcome in great detail and they're part of the comments to help others get over the same errors. Hopefully it does help
people.

### So what's this project?

1) PyTorch_NLP_In_Detail.ipynb

A lot of <b>IN DEPTH</b> code about the basics/intermediate functionality of NLP within PyTorch. Heavily commented and outputs along the way so the individual
seeing it can visually see and follow along.

  - Torchtext datasets
  - Next & Iter
  - Enumeration
  - Tokenization with & without PyTorch
  - Counter
  - Vocab
  - Encoding/Decoding strings
  - Ngrams
  - Bag of words
  - Padding
  - Dataset
  - Dataloader
  - Neural Networks
    1) Basics of input/outut of a layer and how it works (Ex: Linear, Embedding, etc)
    2) Loss functions
    3) Dimension operations
    4) Models
    5) Updating embedding weights of a model
    6) Requires Grad
    7) Predictions explained in detail
    8) Detach
  - Gensim
  - Glove
  - Datapipes
    1) IterableWrapper
    2) FileLister
    3) Map a datapipe
   
  - Build Vocab From Iterator (with yield function)
  - Transforms
  - Batches
  - Lambdas
  - Packed Sequences
  - Character Encoding
  - Bert
  - TensorDataset



2) PyTorch_Basics_In_Detail.ipynb

Explanations about the basics of the libraries functions with Tensors.

  - Argmax/min
  - Reshape
  - View
  - Multinomial
  - <i>Predictions</i>
  - Indexing (Various methods)
  - Slicing (Various methods)
  - One hot encoding
  - To/from numpy conversions
  - Math (Scalar and more)
  - Cumsum
  - Matrix Multiplication
  - Mean (across both dimensions)
  - ones/zeros_like
  - Rand/Randn
  - Arrange
  - Cat
  - Stack
  - Eye
  - Diag
  - Numel
  - Unsqueeze/Squeeze
  - Round
  - Transpose
  - Flatten

I hope the comments I made clears things up for any beginner out there a bit confused, or at least provide a different way to go about thinking OF a particular function/ability
inside the PyTorch library










