{"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOcQCKwEsMFxN+bHyI5warD"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch as t\nimport numpy as np\nimport torchtext\nfrom torchtext.datasets import AG_NEWS\nfrom torchtext.data.utils import get_tokenizer\nimport collections\n\n!pip install 'portalocker>=2.8.2'","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11366,"status":"ok","timestamp":1707705730876,"user":{"displayName":"Omar Moodie","userId":"04801176971567262759"},"user_tz":480},"id":"l4zE4eSwDopU","outputId":"7e4815dc-36e3-441f-a56a-781e0005d923"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":"Requirement already satisfied: portalocker>=2.8.2 in /usr/local/lib/python3.10/dist-packages (2.8.2)\n"}]},{"cell_type":"markdown","source":"# 1) Torch text datasets","metadata":{"id":"tt7RVlhgsIrI"}},{"cell_type":"code","source":"''' According to this link, https://pytorch.org/text/stable/datasets.html pretty much every\n    single torchtext (tt) dataset (ds) has root and split arguments.\n\n    1) root - ??? Directory where ds are saved ???\n    2) split - train or test for ag_news, but for a ds like SST2 it has train, test and DEV. '''\ntrain, test = AG_NEWS()","metadata":{"id":"bU1BbW-AlWfE","executionInfo":{"status":"ok","timestamp":1707705730878,"user_tz":480,"elapsed":79,"user":{"displayName":"Omar Moodie","userId":"04801176971567262759"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"''' Iter gives ability to of course loop (technically) over the object. As of now its type\n    is \"ShardingFilterIterDataPipe\". After iter? It's\n    \"<generator object ShardingFilterIterDataPipe.__iter__ at 0x7d2b405bc660>\" '''\nx = iter(train)\n\nx","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":76,"status":"ok","timestamp":1707705730879,"user":{"displayName":"Omar Moodie","userId":"04801176971567262759"},"user_tz":480},"id":"sVbCU6Edqs8C","outputId":"77cc178f-c573-4c6c-d5bf-74a1ccc5ae85"},"execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":["<generator object ShardingFilterIterDataPipe.__iter__ at 0x7dd03da399a0>"]},"metadata":{}}]},{"cell_type":"code","source":"''' Just keeps getting the next value, can also use a default value if end is reached.\n    https://stackoverflow.com/questions/76302971/question-in-pytorch-transformer-tutorial-about-nonetype-object-has-no-attribut '''\nnext(iter(train))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":55,"status":"ok","timestamp":1707705730880,"user":{"displayName":"Omar Moodie","userId":"04801176971567262759"},"user_tz":480},"id":"su71-J1glcPu","outputId":"b0643694-1c36-44a0-da57-e99aa9c86b71"},"execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":["(3,\n"," \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\")"]},"metadata":{}}]},{"cell_type":"code","source":"# Zip is good for a certain range, 2, 5, etc. n in general. Very useful.\n# for i, x in zip(range(2), train):\n#   print(f'Index {i}. x:\\n{x}\\n\\n')\n\n# Enumerate works fine as well.\nfor i, x in enumerate(train):\n  print(f'Index {i}:\\nx: {x}')\n  break","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":42,"status":"ok","timestamp":1707705730880,"user":{"displayName":"Omar Moodie","userId":"04801176971567262759"},"user_tz":480},"id":"AHDuAGLSnjOX","outputId":"c2b34374-0bd4-4296-bdf0-39f6c3edce5d"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":"Index 0:\n\nx: (3, \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\")\n"},{"output_type":"stream","name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/utils/data/datapipes/iter/combining.py:333: UserWarning: Some child DataPipes are not exhausted when __iter__ is called. We are resetting the buffer and each child DataPipe will read from the start again.\n\n  warnings.warn(\"Some child DataPipes are not exhausted when __iter__ is called. We are resetting \"\n"}]},{"cell_type":"markdown","source":"# 2) Tokenization","metadata":{"id":"kGgiwL6qsMNh"}},{"cell_type":"code","source":"# Get list of sentences\ns = []\nfor i, x in zip(range(3), train):\n  s.append(x[1])\n\nprint(f'List of sentences to tokenize:\\n\\n{s}\\nTotal sentences: {len(s)}')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31,"status":"ok","timestamp":1707705730881,"user":{"displayName":"Omar Moodie","userId":"04801176971567262759"},"user_tz":480},"id":"5PtOKwD7sRj1","outputId":"dbac990c-1bc8-4fcd-bb3d-b4f4b25f31ab"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":"List of sentences to tokenize:\n\n\n\n[\"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\", 'Carlyle Looks Toward Commercial Aerospace (Reuters) Reuters - Private investment firm Carlyle Group,\\\\which has a reputation for making well-timed and occasionally\\\\controversial plays in the defense industry, has quietly placed\\\\its bets on another part of the market.', \"Oil and Economy Cloud Stocks' Outlook (Reuters) Reuters - Soaring crude prices plus worries\\\\about the economy and the outlook for earnings are expected to\\\\hang over the stock market next week during the depth of the\\\\summer doldrums.\"]\n\nTotal sentences: 3\n"}]},{"cell_type":"code","source":"tk = get_tokenizer('basic_english')\n\n# ts = tokenized sentences. !!! do \"tk(s[0])\" for individual sentences !!!\nts = [tk(sent) for sent in s]\n\nts","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":425,"status":"ok","timestamp":1707705731287,"user":{"displayName":"Omar Moodie","userId":"04801176971567262759"},"user_tz":480},"id":"pbvlcfoOof_K","outputId":"f06eb2ba-ae92-4f30-f1bd-c46765925534"},"execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":["[['wall',\n","  'st',\n","  '.',\n","  'bears',\n","  'claw',\n","  'back',\n","  'into',\n","  'the',\n","  'black',\n","  '(',\n","  'reuters',\n","  ')',\n","  'reuters',\n","  '-',\n","  'short-sellers',\n","  ',',\n","  'wall',\n","  'street',\n","  \"'\",\n","  's',\n","  'dwindling\\\\band',\n","  'of',\n","  'ultra-cynics',\n","  ',',\n","  'are',\n","  'seeing',\n","  'green',\n","  'again',\n","  '.'],\n"," ['carlyle',\n","  'looks',\n","  'toward',\n","  'commercial',\n","  'aerospace',\n","  '(',\n","  'reuters',\n","  ')',\n","  'reuters',\n","  '-',\n","  'private',\n","  'investment',\n","  'firm',\n","  'carlyle',\n","  'group',\n","  ',',\n","  '\\\\which',\n","  'has',\n","  'a',\n","  'reputation',\n","  'for',\n","  'making',\n","  'well-timed',\n","  'and',\n","  'occasionally\\\\controversial',\n","  'plays',\n","  'in',\n","  'the',\n","  'defense',\n","  'industry',\n","  ',',\n","  'has',\n","  'quietly',\n","  'placed\\\\its',\n","  'bets',\n","  'on',\n","  'another',\n","  'part',\n","  'of',\n","  'the',\n","  'market',\n","  '.'],\n"," ['oil',\n","  'and',\n","  'economy',\n","  'cloud',\n","  'stocks',\n","  \"'\",\n","  'outlook',\n","  '(',\n","  'reuters',\n","  ')',\n","  'reuters',\n","  '-',\n","  'soaring',\n","  'crude',\n","  'prices',\n","  'plus',\n","  'worries\\\\about',\n","  'the',\n","  'economy',\n","  'and',\n","  'the',\n","  'outlook',\n","  'for',\n","  'earnings',\n","  'are',\n","  'expected',\n","  'to\\\\hang',\n","  'over',\n","  'the',\n","  'stock',\n","  'market',\n","  'next',\n","  'week',\n","  'during',\n","  'the',\n","  'depth',\n","  'of',\n","  'the\\\\summer',\n","  'doldrums',\n","  '.']]"]},"metadata":{}}]},{"cell_type":"code","source":"# counter just counts how many times its seen something.\n\n# 1) Give first tokenized str\n# counter = collections.Counter(ts[0])\n# counter\n\n# 2) Init default and update it with tokenized str\n# counter = collections.Counter()\n# counter.update(ts[0])\n# counter\n\n# 3) Use whole ds with it (part of it here)\n# counter = collections.Counter()\n# for i, x in zip(range(3), train):\n#   counter.update(tk(x[1]))\n# counter\n\n# 4) The 3rd option used train directly, can also use the tokenized sentences in the list \"ts\".\ncounter = collections.Counter()\nfor sent in ts:\n  counter.update(sent)\ncounter","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":160,"status":"ok","timestamp":1707705731287,"user":{"displayName":"Omar Moodie","userId":"04801176971567262759"},"user_tz":480},"id":"MR6meOMxrwl4","outputId":"7d6c4373-73fb-498c-a7ea-7c56b35f19db"},"execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":["Counter({'wall': 2,\n","         'st': 1,\n","         '.': 4,\n","         'bears': 1,\n","         'claw': 1,\n","         'back': 1,\n","         'into': 1,\n","         'the': 7,\n","         'black': 1,\n","         '(': 3,\n","         'reuters': 6,\n","         ')': 3,\n","         '-': 3,\n","         'short-sellers': 1,\n","         ',': 4,\n","         'street': 1,\n","         \"'\": 2,\n","         's': 1,\n","         'dwindling\\\\band': 1,\n","         'of': 3,\n","         'ultra-cynics': 1,\n","         'are': 2,\n","         'seeing': 1,\n","         'green': 1,\n","         'again': 1,\n","         'carlyle': 2,\n","         'looks': 1,\n","         'toward': 1,\n","         'commercial': 1,\n","         'aerospace': 1,\n","         'private': 1,\n","         'investment': 1,\n","         'firm': 1,\n","         'group': 1,\n","         '\\\\which': 1,\n","         'has': 2,\n","         'a': 1,\n","         'reputation': 1,\n","         'for': 2,\n","         'making': 1,\n","         'well-timed': 1,\n","         'and': 3,\n","         'occasionally\\\\controversial': 1,\n","         'plays': 1,\n","         'in': 1,\n","         'defense': 1,\n","         'industry': 1,\n","         'quietly': 1,\n","         'placed\\\\its': 1,\n","         'bets': 1,\n","         'on': 1,\n","         'another': 1,\n","         'part': 1,\n","         'market': 2,\n","         'oil': 1,\n","         'economy': 2,\n","         'cloud': 1,\n","         'stocks': 1,\n","         'outlook': 2,\n","         'soaring': 1,\n","         'crude': 1,\n","         'prices': 1,\n","         'plus': 1,\n","         'worries\\\\about': 1,\n","         'earnings': 1,\n","         'expected': 1,\n","         'to\\\\hang': 1,\n","         'over': 1,\n","         'stock': 1,\n","         'next': 1,\n","         'week': 1,\n","         'during': 1,\n","         'depth': 1,\n","         'the\\\\summer': 1,\n","         'doldrums': 1})"]},"metadata":{}}]},{"cell_type":"code","source":"# vocab is a dictionary\nv = torchtext.vocab.vocab(counter, min_freq=1)\n\nprint(v)\nprint(v.vocab)\nprint(len(v.vocab))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":153,"status":"ok","timestamp":1707705731288,"user":{"displayName":"Omar Moodie","userId":"04801176971567262759"},"user_tz":480},"id":"w9iglw_AtTs8","outputId":"fe528d59-6c6f-4568-d94d-9d23b5033200"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":"Vocab()\n\n<torchtext._torchtext.Vocab object at 0x7dd0387828f0>\n\n75\n"}]},{"cell_type":"code","source":"# Returns dictionary of word/assigned number in key/value pairs.\nv.get_stoi()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":145,"status":"ok","timestamp":1707705731288,"user":{"displayName":"Omar Moodie","userId":"04801176971567262759"},"user_tz":480},"id":"qx5m2x4HxVzU","outputId":"d11c0cc4-c346-40ab-99c8-ecd93b46df6f"},"execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":["{'depth': 72,\n"," 'during': 71,\n"," 'next': 69,\n"," 'over': 67,\n"," 'to\\\\hang': 66,\n"," 'earnings': 64,\n"," 'worries\\\\about': 63,\n"," 'prices': 61,\n"," 'crude': 60,\n"," 'dwindling\\\\band': 18,\n"," 'green': 23,\n"," 'group': 33,\n"," 'has': 35,\n"," 'private': 30,\n"," 'of': 19,\n"," 'carlyle': 25,\n"," 'looks': 26,\n"," ',': 14,\n"," 'street': 15,\n"," 'plus': 62,\n"," 'black': 8,\n"," 'toward': 27,\n"," 'bears': 3,\n"," 'the\\\\summer': 73,\n"," 'week': 70,\n"," 'reuters': 10,\n"," 'again': 24,\n"," ')': 11,\n"," '.': 2,\n"," '\\\\which': 34,\n"," 'st': 1,\n"," 'market': 53,\n"," 'the': 7,\n"," 'in': 44,\n"," 'expected': 65,\n"," '(': 9,\n"," 'are': 21,\n"," 'part': 52,\n"," \"'\": 16,\n"," 'claw': 4,\n"," 'into': 6,\n"," 'short-sellers': 13,\n"," '-': 12,\n"," 'aerospace': 29,\n"," 'commercial': 28,\n"," 'investment': 31,\n"," 'firm': 32,\n"," 'seeing': 22,\n"," 'making': 39,\n"," 'for': 38,\n"," 'another': 51,\n"," 'cloud': 56,\n"," 'back': 5,\n"," 'outlook': 58,\n"," 'a': 36,\n"," 'on': 50,\n"," 'reputation': 37,\n"," 's': 17,\n"," 'well-timed': 40,\n"," 'and': 41,\n"," 'wall': 0,\n"," 'industry': 46,\n"," 'soaring': 59,\n"," 'stocks': 57,\n"," 'occasionally\\\\controversial': 42,\n"," 'stock': 68,\n"," 'bets': 49,\n"," 'doldrums': 74,\n"," 'ultra-cynics': 20,\n"," 'plays': 43,\n"," 'defense': 45,\n"," 'quietly': 47,\n"," 'placed\\\\its': 48,\n"," 'oil': 54,\n"," 'economy': 55}"]},"metadata":{}}]},{"cell_type":"code","source":"#  Returns list of all words. showing first 10\nv.get_itos()[:10]","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":140,"status":"ok","timestamp":1707705731288,"user":{"displayName":"Omar Moodie","userId":"04801176971567262759"},"user_tz":480},"id":"dEaVpFs7v9vK","outputId":"454ee6cf-38e9-4cb0-be24-d9f634ad5a80"},"execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":["['wall', 'st', '.', 'bears', 'claw', 'back', 'into', 'the', 'black', '(']"]},"metadata":{}}]},{"cell_type":"code","source":"# zip is cool.\nfor i, x in zip(range(5), v.get_itos()):\n  print(f'Numerical value in dictionary: {i}. Assigned word: {x}')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":133,"status":"ok","timestamp":1707705731289,"user":{"displayName":"Omar Moodie","userId":"04801176971567262759"},"user_tz":480},"id":"USywxXp5umdD","outputId":"ce0ebd74-f2f6-4ba7-b38c-6615a5538a18"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":"Numerical value in dictionary: 0. Assigned word: wall\n\nNumerical value in dictionary: 1. Assigned word: st\n\nNumerical value in dictionary: 2. Assigned word: .\n\nNumerical value in dictionary: 3. Assigned word: bears\n\nNumerical value in dictionary: 4. Assigned word: claw\n"}]},{"cell_type":"code","source":"''' Convert sentence into nums. es = example sentence. Get the tokenized sentence.\n    Loop through it, get_stoi() remember returns dictionary of str/num key/value pairs.\n    So give it str (or token) to get num back. '''\nes = ts[0]\n\nnumerical_sentence = [v.get_stoi()[cur_token] for cur_token in es]\n\nprint(f'Example sentence:\\n{es}\\n\\nNumerical version of same sentence:\\n{numerical_sentence}')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":128,"status":"ok","timestamp":1707705731289,"user":{"displayName":"Omar Moodie","userId":"04801176971567262759"},"user_tz":480},"id":"VczjKh7sxvuP","outputId":"4f7c3a76-3df7-435a-b85b-7bc3e21da7ae"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":"Example sentence:\n\n['wall', 'st', '.', 'bears', 'claw', 'back', 'into', 'the', 'black', '(', 'reuters', ')', 'reuters', '-', 'short-sellers', ',', 'wall', 'street', \"'\", 's', 'dwindling\\\\band', 'of', 'ultra-cynics', ',', 'are', 'seeing', 'green', 'again', '.']\n\n\n\nNumerical version of same sentence:\n\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 10, 12, 13, 14, 0, 15, 16, 17, 18, 19, 20, 14, 21, 22, 23, 24, 2]\n"}]},{"cell_type":"code","source":"# Create lists with tokens and their numerical conversions.\npairs = []\nfor cur_sent in ts:\n  pairs.append([list((v.get_stoi()[cur_token], cur_token)) for cur_token in cur_sent])\npairs","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":120,"status":"ok","timestamp":1707705731289,"user":{"displayName":"Omar Moodie","userId":"04801176971567262759"},"user_tz":480},"id":"42c2T59l03-K","outputId":"02935411-3986-4ca0-af17-67cbc62d41dc"},"execution_count":14,"outputs":[{"output_type":"execute_result","execution_count":14,"data":{"text/plain":["[[[0, 'wall'],\n","  [1, 'st'],\n","  [2, '.'],\n","  [3, 'bears'],\n","  [4, 'claw'],\n","  [5, 'back'],\n","  [6, 'into'],\n","  [7, 'the'],\n","  [8, 'black'],\n","  [9, '('],\n","  [10, 'reuters'],\n","  [11, ')'],\n","  [10, 'reuters'],\n","  [12, '-'],\n","  [13, 'short-sellers'],\n","  [14, ','],\n","  [0, 'wall'],\n","  [15, 'street'],\n","  [16, \"'\"],\n","  [17, 's'],\n","  [18, 'dwindling\\\\band'],\n","  [19, 'of'],\n","  [20, 'ultra-cynics'],\n","  [14, ','],\n","  [21, 'are'],\n","  [22, 'seeing'],\n","  [23, 'green'],\n","  [24, 'again'],\n","  [2, '.']],\n"," [[25, 'carlyle'],\n","  [26, 'looks'],\n","  [27, 'toward'],\n","  [28, 'commercial'],\n","  [29, 'aerospace'],\n","  [9, '('],\n","  [10, 'reuters'],\n","  [11, ')'],\n","  [10, 'reuters'],\n","  [12, '-'],\n","  [30, 'private'],\n","  [31, 'investment'],\n","  [32, 'firm'],\n","  [25, 'carlyle'],\n","  [33, 'group'],\n","  [14, ','],\n","  [34, '\\\\which'],\n","  [35, 'has'],\n","  [36, 'a'],\n","  [37, 'reputation'],\n","  [38, 'for'],\n","  [39, 'making'],\n","  [40, 'well-timed'],\n","  [41, 'and'],\n","  [42, 'occasionally\\\\controversial'],\n","  [43, 'plays'],\n","  [44, 'in'],\n","  [7, 'the'],\n","  [45, 'defense'],\n","  [46, 'industry'],\n","  [14, ','],\n","  [35, 'has'],\n","  [47, 'quietly'],\n","  [48, 'placed\\\\its'],\n","  [49, 'bets'],\n","  [50, 'on'],\n","  [51, 'another'],\n","  [52, 'part'],\n","  [19, 'of'],\n","  [7, 'the'],\n","  [53, 'market'],\n","  [2, '.']],\n"," [[54, 'oil'],\n","  [41, 'and'],\n","  [55, 'economy'],\n","  [56, 'cloud'],\n","  [57, 'stocks'],\n","  [16, \"'\"],\n","  [58, 'outlook'],\n","  [9, '('],\n","  [10, 'reuters'],\n","  [11, ')'],\n","  [10, 'reuters'],\n","  [12, '-'],\n","  [59, 'soaring'],\n","  [60, 'crude'],\n","  [61, 'prices'],\n","  [62, 'plus'],\n","  [63, 'worries\\\\about'],\n","  [7, 'the'],\n","  [55, 'economy'],\n","  [41, 'and'],\n","  [7, 'the'],\n","  [58, 'outlook'],\n","  [38, 'for'],\n","  [64, 'earnings'],\n","  [21, 'are'],\n","  [65, 'expected'],\n","  [66, 'to\\\\hang'],\n","  [67, 'over'],\n","  [7, 'the'],\n","  [68, 'stock'],\n","  [53, 'market'],\n","  [69, 'next'],\n","  [70, 'week'],\n","  [71, 'during'],\n","  [7, 'the'],\n","  [72, 'depth'],\n","  [19, 'of'],\n","  [73, 'the\\\\summer'],\n","  [74, 'doldrums'],\n","  [2, '.']]]"]},"metadata":{}}]},{"cell_type":"code","source":"v.get_itos()[21]","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":114,"status":"ok","timestamp":1707705731290,"user":{"displayName":"Omar Moodie","userId":"04801176971567262759"},"user_tz":480},"id":"B92rWUj61iqI","outputId":"2fd18a37-c80a-4464-9427-afdab54e2c65"},"execution_count":15,"outputs":[{"output_type":"execute_result","execution_count":15,"data":{"text/plain":["'are'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{}}]},{"cell_type":"code","source":"def encode(str_to_encode):\n  return [v.get_stoi()[token] for token in str_to_encode]\n\n''' get_itos works for decoding because the vocab object already assigned numbers\n    to words. So as of right now, v.get_stoi()[0] gets the word in the dictionary\n    with assigned num 0. '''\ndef decode(nums_to_decode):\n  return [v.get_itos()[num] for num in nums_to_decode]\n\n# es = example str declared in earlier cell. already tokenized.\nencoded_str = encode(es)\nprint(f'Example str:\\n{es}\\n\\nEncoded str:\\n{encoded_str}\\n\\n')\n\ndecoded_str = decode(encoded_str)\nprint(f'Decoded str:\\n{decoded_str}')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":111,"status":"ok","timestamp":1707705731290,"user":{"displayName":"Omar Moodie","userId":"04801176971567262759"},"user_tz":480},"id":"7b-Ug0oa4ZTG","outputId":"8e321e32-d749-4768-dcfb-4df7d16a8b1b"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":"Example str:\n\n['wall', 'st', '.', 'bears', 'claw', 'back', 'into', 'the', 'black', '(', 'reuters', ')', 'reuters', '-', 'short-sellers', ',', 'wall', 'street', \"'\", 's', 'dwindling\\\\band', 'of', 'ultra-cynics', ',', 'are', 'seeing', 'green', 'again', '.']\n\n\n\nEncoded str:\n\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 10, 12, 13, 14, 0, 15, 16, 17, 18, 19, 20, 14, 21, 22, 23, 24, 2]\n\n\n\n\n\nDecoded str:\n\n['wall', 'st', '.', 'bears', 'claw', 'back', 'into', 'the', 'black', '(', 'reuters', ')', 'reuters', '-', 'short-sellers', ',', 'wall', 'street', \"'\", 's', 'dwindling\\\\band', 'of', 'ultra-cynics', ',', 'are', 'seeing', 'green', 'again', '.']\n"}]},{"cell_type":"markdown","source":"# 3) N grams","metadata":{"id":"CjFiSV8U2twx"}},{"cell_type":"code","source":"from torchtext.data.utils import ngrams_iterator\n\n''' Ngrams will help solve multiword expression issues like \"hamburger\" because \"ham\" and\n    \"burger\" can be 2 separate words. Can't always represent both of those words with the same\n    vector. The update func gets pairs because ngrams=2. If the goal was to be able to understand\n    3 sets of words, ngrams will be 3. Downside is this WILL example the counter object\n    by a lot. Specifically len(v) * 2/3/etc. '''\n\n# nc = ngrams counter\nnc = collections.Counter()\nnc.update(ngrams_iterator(es, ngrams=2))\nnc","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":98,"status":"ok","timestamp":1707705731290,"user":{"displayName":"Omar Moodie","userId":"04801176971567262759"},"user_tz":480},"id":"m_kIhGd72tBi","outputId":"39b3b6e6-9355-4e77-eb33-f1c476686429"},"execution_count":17,"outputs":[{"output_type":"execute_result","execution_count":17,"data":{"text/plain":["Counter({'wall': 2,\n","         'st': 1,\n","         '.': 2,\n","         'bears': 1,\n","         'claw': 1,\n","         'back': 1,\n","         'into': 1,\n","         'the': 1,\n","         'black': 1,\n","         '(': 1,\n","         'reuters': 2,\n","         ')': 1,\n","         '-': 1,\n","         'short-sellers': 1,\n","         ',': 2,\n","         'street': 1,\n","         \"'\": 1,\n","         's': 1,\n","         'dwindling\\\\band': 1,\n","         'of': 1,\n","         'ultra-cynics': 1,\n","         'are': 1,\n","         'seeing': 1,\n","         'green': 1,\n","         'again': 1,\n","         'wall st': 1,\n","         'st .': 1,\n","         '. bears': 1,\n","         'bears claw': 1,\n","         'claw back': 1,\n","         'back into': 1,\n","         'into the': 1,\n","         'the black': 1,\n","         'black (': 1,\n","         '( reuters': 1,\n","         'reuters )': 1,\n","         ') reuters': 1,\n","         'reuters -': 1,\n","         '- short-sellers': 1,\n","         'short-sellers ,': 1,\n","         ', wall': 1,\n","         'wall street': 1,\n","         \"street '\": 1,\n","         \"' s\": 1,\n","         's dwindling\\\\band': 1,\n","         'dwindling\\\\band of': 1,\n","         'of ultra-cynics': 1,\n","         'ultra-cynics ,': 1,\n","         ', are': 1,\n","         'are seeing': 1,\n","         'seeing green': 1,\n","         'green again': 1,\n","         'again .': 1})"]},"metadata":{}}]},{"cell_type":"code","source":"for i, a in zip(range(3), nc):\n  print(a)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":86,"status":"ok","timestamp":1707705731291,"user":{"displayName":"Omar Moodie","userId":"04801176971567262759"},"user_tz":480},"id":"5Rvc8GDQ5x9g","outputId":"a8b31755-b9bf-4fa6-a960-5e42cad3710e"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":"wall\n\nst\n\n.\n"}]},{"cell_type":"markdown","source":"# 4) Bag of words (bow) & more","metadata":{"id":"mTYBptfA6bbZ"}},{"cell_type":"code","source":"# A bow is simply seeing how many times a word occurs. Get the first 3 sentences num representations here\nnum_sents = [encode(tk(a[1])) for i, a in zip(range(3), train)]\n\nfor x in num_sents:\n  print(x)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":77,"status":"ok","timestamp":1707705731291,"user":{"displayName":"Omar Moodie","userId":"04801176971567262759"},"user_tz":480},"id":"GehUiJzi6ak1","outputId":"a4bc010d-c28b-4658-dca3-c37e5a9bfca7"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":"[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 10, 12, 13, 14, 0, 15, 16, 17, 18, 19, 20, 14, 21, 22, 23, 24, 2]\n\n[25, 26, 27, 28, 29, 9, 10, 11, 10, 12, 30, 31, 32, 25, 33, 14, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 7, 45, 46, 14, 35, 47, 48, 49, 50, 51, 52, 19, 7, 53, 2]\n\n[54, 41, 55, 56, 57, 16, 58, 9, 10, 11, 10, 12, 59, 60, 61, 62, 63, 7, 55, 41, 7, 58, 38, 64, 21, 65, 66, 67, 7, 68, 53, 69, 70, 71, 7, 72, 19, 73, 74, 2]\n"}]},{"cell_type":"code","source":"# Get tensor of length of vocab. With first 3 sentences in ag_news USED for vocab, this will be 75.\na = t.zeros(len(v))\n\n# Loop over first num sentence seen in previous cell.\nfor num in num_sents[0]:\n  ''' Ex: v.get_stoi() has \"wall\" paired with num 0. this will increase index 0 by 1. Keep in mind,\n      we can access index 0 in this \"a\" tensor, and give that index to v.get_stoi()[] and it'll\n      return the proper word '''\n  a[num] = a[num] + 1\n\na","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":70,"status":"ok","timestamp":1707705731291,"user":{"displayName":"Omar Moodie","userId":"04801176971567262759"},"user_tz":480},"id":"nKSxj--U7zYE","outputId":"69ed6a6b-e448-452c-f6e9-69b83cc93793"},"execution_count":20,"outputs":[{"output_type":"execute_result","execution_count":20,"data":{"text/plain":["tensor([2., 1., 2., 1., 1., 1., 1., 1., 1., 1., 2., 1., 1., 1., 2., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0.])"]},"metadata":{}}]},{"cell_type":"code","source":"''' Want to combine tensors? Stack helps. MUST be same dimensions. dim=1 gives vertical\n    alignment, dim=0 gives horizontal.  '''\nfirst_tensor = t.tensor([1,2,3])\nsecond_tensor = t.tensor([5,5,5])\n\nv_tensor = t.stack([first_tensor, second_tensor],dim=1)\nh_tensor = t.stack([first_tensor, second_tensor],dim=0)\n\nprint(f'Vertical tensor:\\n{v_tensor}\\n\\nHorizontal tensor:\\n{h_tensor}\\n')\nprint(f'Vertical tensor shape: {v_tensor.shape}\\nHorizontal tensor shape: {h_tensor.shape}')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":63,"status":"ok","timestamp":1707705731291,"user":{"displayName":"Omar Moodie","userId":"04801176971567262759"},"user_tz":480},"id":"gXh0puNL_GEf","outputId":"4745fc77-75f8-4cc2-f2d4-d9fe2279004d"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":"Vertical tensor:\n\ntensor([[1, 5],\n\n        [2, 5],\n\n        [3, 5]])\n\n\n\nHorizontal tensor:\n\ntensor([[1, 2, 3],\n\n        [5, 5, 5]])\n\n\n\nVertical tensor shape: torch.Size([3, 2])\n\nHorizontal tensor shape: torch.Size([2, 3])\n"}]},{"cell_type":"code","source":"''' num_sents aren't the same size which is required for models like embedding, so padding will be\n    demonstrated. map wil take the len func and apply it to every num sentence and list will get\n    all the lengths. Then max just gets the biggest one. Quick and easy. '''\nmax_length = max(list(map(len, num_sents)))\n\n''' Convert sent to tensor first, and 0, max length - len of current sentence just makes sure we get\n    the CORRECT amount of 0s. '''\npadded_num_sents = [t.nn.functional.pad(t.tensor(sent), (0, max_length - len(sent))) for sent in num_sents]\n\nprint(padded_num_sents)\n\nfor x in padded_num_sents:\n  print(len(x))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":58,"status":"ok","timestamp":1707705731291,"user":{"displayName":"Omar Moodie","userId":"04801176971567262759"},"user_tz":480},"id":"RIfR9IwwAVl7","outputId":"e5199be1-fa96-47e0-e3a1-affcd8e03cd2"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":"[tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 10, 12, 13, 14,  0, 15,\n\n        16, 17, 18, 19, 20, 14, 21, 22, 23, 24,  2,  0,  0,  0,  0,  0,  0,  0,\n\n         0,  0,  0,  0,  0,  0]), tensor([25, 26, 27, 28, 29,  9, 10, 11, 10, 12, 30, 31, 32, 25, 33, 14, 34, 35,\n\n        36, 37, 38, 39, 40, 41, 42, 43, 44,  7, 45, 46, 14, 35, 47, 48, 49, 50,\n\n        51, 52, 19,  7, 53,  2]), tensor([54, 41, 55, 56, 57, 16, 58,  9, 10, 11, 10, 12, 59, 60, 61, 62, 63,  7,\n\n        55, 41,  7, 58, 38, 64, 21, 65, 66, 67,  7, 68, 53, 69, 70, 71,  7, 72,\n\n        19, 73, 74,  2,  0,  0])]\n\n42\n\n42\n\n42\n"}]},{"cell_type":"markdown","source":"# 5) Dataset & Data Loader","metadata":{"id":"mjYnc216CeMA"}},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\n\n''' Datasets are good because they can potentially load data only when necessary instead of all at once\n    like with image processing tasks. Also a way to keep things organized. Must override len and getitem. '''\nclass TestDataset(Dataset):\n  def __init__(self, data_to_use):\n    self.data = data_to_use\n\n  def __getitem__(self, index):\n    return self.data[index]\n\n  def __len__(self):\n    return len(self.data)\n\n# The collate_fn arg in DataLoader which extra things to the dataset before it's saved in data loader.\ndef sub(num):\n  return t.tensor([cur_tensor_num.item() - 1 for cur_tensor_num in num])\n\n# Get some generic data. \"tensor([ 0,  2,  4,  6,  8, 10, 12, 14, 16, 18])\"\nx = t.tensor([x * 2 for x in range(10)])\ntds = TestDataset(x)\n\n\n''' tdl = test data loader (dl) Very efficient way of loading data. Also when using the collate_fn arg, it\n    seems like the DataLoader GIVES the data to whatever func as a list. Strange.\n    Uncomment/comment whichever below DataLoader to see results.  '''\n# tdl = DataLoader(tds, 1, shuffle=False, collate_fn=sub)\ntdl = DataLoader(tds, 1, shuffle=False)\n\nfor x in tdl:\n  print(x)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":50,"status":"ok","timestamp":1707705731291,"user":{"displayName":"Omar Moodie","userId":"04801176971567262759"},"user_tz":480},"id":"BfgkIesPCiHQ","outputId":"6c0fadc1-5f1c-40d6-fa33-bc73aa19c958"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":"tensor([0])\n\ntensor([2])\n\ntensor([4])\n\ntensor([6])\n\ntensor([8])\n\ntensor([10])\n\ntensor([12])\n\ntensor([14])\n\ntensor([16])\n\ntensor([18])\n"}]},{"cell_type":"markdown","source":"# 6) Basic layer, activation function, etc","metadata":{"id":"jo4vd58bHIlR"}},{"cell_type":"code","source":"# Seeing inputs of a linear layer and what it'll output.\nt.nn.Linear(len(v), 3)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":45,"status":"ok","timestamp":1707705731292,"user":{"displayName":"Omar Moodie","userId":"04801176971567262759"},"user_tz":480},"id":"wPebsROfHL22","outputId":"df596bbe-2b12-4d58-ad27-dc15c4373372"},"execution_count":24,"outputs":[{"output_type":"execute_result","execution_count":24,"data":{"text/plain":["Linear(in_features=75, out_features=3, bias=True)"]},"metadata":{}}]},{"cell_type":"code","source":"x = t.tensor([[2,8,9],\n              [5,1,3],\n              [4,8,7]], dtype=t.float64)\n\n''' ??? 1 is likely vertical (row by row) and 0 horizontal (column by column). ??? Softmax\n    converts things to probabilities, so log softmax does the same but with log applied.\n    Also logsoftmax is for classification\n    https://www.baeldung.com/cs/softmax-vs-log-softmax '''\nls = t.nn.LogSoftmax(dim=1)\n\nprint(x)\nprint(ls(x))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39,"status":"ok","timestamp":1707705731292,"user":{"displayName":"Omar Moodie","userId":"04801176971567262759"},"user_tz":480},"id":"DN7bmhUXIknl","outputId":"ce1972a8-6ac1-4b42-c0cf-9e6c95b2f059"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":"tensor([[2., 8., 9.],\n\n        [5., 1., 3.],\n\n        [4., 8., 7.]], dtype=torch.float64)\n\ntensor([[-7.3139, -1.3139, -0.3139],\n\n        [-0.1429, -4.1429, -2.1429],\n\n        [-4.3266, -0.3266, -1.3266]], dtype=torch.float64)\n"}]},{"cell_type":"code","source":"# Sequential is just layers in an order.\nnetwork = t.nn.Sequential(t.nn.Linear(len(v), 3),\n                          t.nn.LogSoftmax(dim=1))\n\nnetwork","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33,"status":"ok","timestamp":1707705731292,"user":{"displayName":"Omar Moodie","userId":"04801176971567262759"},"user_tz":480},"id":"hqTidUl_LQwB","outputId":"6875dd45-5ab2-4dc7-8fe5-5aaae1199947"},"execution_count":26,"outputs":[{"output_type":"execute_result","execution_count":26,"data":{"text/plain":["Sequential(\n","  (0): Linear(in_features=75, out_features=3, bias=True)\n","  (1): LogSoftmax(dim=1)\n",")"]},"metadata":{}}]},{"cell_type":"code","source":"''' len(v) because model input is equal to vocab length.\n    1) \"TypeError: linear(): argument 'input' (position 1) must be Tensor, not list\"\n          I converted it to a tensor because of this.\n\n    2) \"RuntimeError: mat1 and mat2 must have the same dtype, but got Long and Float\"\n          I checked the input_test dtype and it was torch.int64. Apparently that\n          qualifies as a long? A QUICK fix would be to change the input_test tensor\n          to dtype=t.float32, but I also wanted to check models input.\n\n          2.2) Checking model input.\n                Help from link:\n                https://discuss.pytorch.org/t/get-appropriate-model-in-output-type-programmatically/53742\n\n                Doing:\n                \"z = t.nn.Linear(len(v), 3)\n                list(z.parameters())\" returns a list of tensors. First tensor is 2d\n                because it has 3 inner tensors of 75 values, the vocab size.\n\n                Ex:\n                \"tensor([[-0.0353, -0.0916,  0.0258,  0.0546, -0.0598,  0.0273, -0.0447, -0.0129,\n                           0.0199, -0.0067,  0.0418,  0.1102, -0.0363, -0.0615, -0.1136,  0.0627],\n\n                          [0.0922, -0.0013, -0.0645, -0.0640, -0.0426,  0.0972,  0.0951, -0.0859,\n                            0.0891,  0.1113, -0.0431, -0.0607,  0.0699, -0.0706,  0.0240, -0.0716],\n\n                          [-0.0369,  0.0732,  0.0284, -0.0249,  0.0937, -0.0938,  0.0555,  0.0908,\n                           -0.0923, -0.0790,  0.0530,  0.0607,  0.1147,  0.0963, -0.0195, -0.1021]]\"\n\n                It's in 2d. Strange. I guess input must be in 2d as well.\n\n          But to the point of this section, which is 2, the error can be fixed by changing the\n          type of the input to dtype=t.float32.\n\n\n    3) \"IndexError: Dimension out of range (expected to be in range of [-1, 0], but got 1)\"\n          Then this one came up because I BELIEVE the input tensor was not 2d. I used\n          \"t.unsqueeze(input_test, dim=0)\" which ADDS a dimension horizontally so now its definitely\n          2d. Shape is \"torch.Size([1, 75])\"\n\n     '''\ninput_test = t.tensor([i * 2 for i in range(len(v))], dtype=t.float32)\n# uit = updated input test\nuit = t.unsqueeze(input_test, dim=0)\nprint(f'Input for model:\\n{input_test}\\n\\nType: {input_test.dtype}\\n\\nNEW input for model:\\n{uit}\\n\\n')\n\n# Show model result.\nnetwork(uit)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":395,"status":"ok","timestamp":1707705731659,"user":{"displayName":"Omar Moodie","userId":"04801176971567262759"},"user_tz":480},"id":"Q9crrNFOLycX","outputId":"2d96d4b6-b0d6-4c62-c7ba-3b126dc5deb8"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":"Input for model:\n\ntensor([  0.,   2.,   4.,   6.,   8.,  10.,  12.,  14.,  16.,  18.,  20.,  22.,\n\n         24.,  26.,  28.,  30.,  32.,  34.,  36.,  38.,  40.,  42.,  44.,  46.,\n\n         48.,  50.,  52.,  54.,  56.,  58.,  60.,  62.,  64.,  66.,  68.,  70.,\n\n         72.,  74.,  76.,  78.,  80.,  82.,  84.,  86.,  88.,  90.,  92.,  94.,\n\n         96.,  98., 100., 102., 104., 106., 108., 110., 112., 114., 116., 118.,\n\n        120., 122., 124., 126., 128., 130., 132., 134., 136., 138., 140., 142.,\n\n        144., 146., 148.])\n\n\n\nType: torch.float32\n\n\n\nNEW input for model:\n\ntensor([[  0.,   2.,   4.,   6.,   8.,  10.,  12.,  14.,  16.,  18.,  20.,  22.,\n\n          24.,  26.,  28.,  30.,  32.,  34.,  36.,  38.,  40.,  42.,  44.,  46.,\n\n          48.,  50.,  52.,  54.,  56.,  58.,  60.,  62.,  64.,  66.,  68.,  70.,\n\n          72.,  74.,  76.,  78.,  80.,  82.,  84.,  86.,  88.,  90.,  92.,  94.,\n\n          96.,  98., 100., 102., 104., 106., 108., 110., 112., 114., 116., 118.,\n\n         120., 122., 124., 126., 128., 130., 132., 134., 136., 138., 140., 142.,\n\n         144., 146., 148.]])\n\n\n\n\n"},{"output_type":"execute_result","execution_count":27,"data":{"text/plain":["tensor([[  0.0000, -26.0792, -37.4430]], grad_fn=<LogSoftmaxBackward0>)"]},"metadata":{}}]},{"cell_type":"code","source":"''' Most basic model ever. Embedding takes in v size and outputs dimension size of whatever requested.\n    And that'll be input to the Linear layer of course.\n\n    Errors:\n    1) \"RuntimeError: Expected tensor for argument #1 'indices' to have one of the following scalar\n        types: Long, Int; but got torch.FloatTensor instead (while checking arguments for embedding)\"\n\n        Solution: \"uit = uit.type(t.long)\" type conversion\n\n\n    2) \"IndexError: index out of range in self\"\n\n        Understanding the error: https://rollbar.com/blog/how-to-handle-index-out-of-range-in-self-pytorch/#\n        The code at the beginning is simple and I made my own test code\n        \"r = t.nn.Embedding(10, 5)\n        m = t.tensor([9])\n        r(m)\"\n        The thing is, if the tensor value is 10, it breaks and gives same error. But if its 9 or less, it\n        works fine. Which tells me that the MAX range it'll accept is 10. Anything greater and it breaks.\n        Of course it indexes from 0. The above is just for a 1d dimensional tensor.\n\n        Solution: I was given numerical input to the model when the VOCAB didn't match it. The vocab\n          went to num 75. Yet I tried giving the model:\n          \"tensor([[  0.,   2.,   4.,   6.,   8.,  10.,  12.,  14.,  16.,  18.,  20.,  22.,\n                      24.,  26.,  28.,  30.,  32.,  34.,  36.,  38.,  40.,  42.,  44.,  46.,\n                      48.,  50.,  52.,  54.,  56.,  58.,  60.,  62.,  64.,  66.,  68.,  70.,\n                      72.,  74.,  76.,  78.,  80.,  82.,  84.,  86.,  88.,  90.,  92.,  94.,\n                      96.,  98., 100., 102., 104., 106., 108., 110., 112., 114., 116., 118.,\n                      120., 122., 124., 126., 128., 130., 132., 134., 136., 138., 140., 142.,\n                      144., 146., 148.]])\"\n          The aforementioned link helped me understand this with t.all(). Initially I thought\n          t.nn.Embedding(vocab size, etc) meant the LENGTH of the input tensor couldn't be bigger\n          than vocab size, but it was checking for INDIVIDUAL numbers instead. Example code below:\n\n          \" r = t.nn.Embedding(len(v), 5) # vocab len 75\n            m = t.tensor([9,4,2,4,1,4,5,8,3,6,5,2,3,2,4,6,2,4,6,5,5,5,55,31,2]) # Will pass!\n            # m = t.tensor([9,4,2,4,1,4,5,8,74,10,75]) # Will fail!\n            # m = t.tensor([9,4,2,4,1,4,5,8,74,10,74]) # Will pass!\n\n            # All literally checks ALL values in tensor.\n            if t.all(m >= 0):\n              print(f'Passed. Tensor is: {m.shape}')\n            if t.all(m < r.num_embeddings):\n              print(f'Passed. Tensor is: {m.shape}')\n            else:\n              print(f'!!! Failed. Tensor shape: {uit.shape} and num embeddings: {embedding.num_embeddings} !!!')\"\n\n\n\n    3) \"RuntimeError: mat1 and mat2 shapes cannot be multiplied (1x29 and 5x3)\"\n        Why did this happen? 1x29 is the size of the num input tenor which is:\n        \"tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 10, 12, 13, 14,  0, 15,\n                 16, 17, 18, 19, 20, 14, 21, 22, 23, 24,  2])\"\n         Real tokenized sentence of above numerical sentence is:\n            \"['wall', 'st', '.', 'bears', 'claw', 'back', 'into', 'the', 'black', '(',\n               'reuters', ')', 'reuters', '-', 'short-sellers', ',', 'wall', 'street', \"'\", 's',\n               'dwindling\\\\band', 'of', 'ultra-cynics', ',', 'are', 'seeing', 'green', 'again', '.']\"\n\n\n        Solution 1: I commented out:\n          \"# x = t.mean(x,dim=1)\n           # print(f'x shape after t.mean: {x.shape}\\nx after t.mean:\\n{x}')\"\n           And it worked perfectly. Why?\n\n           Answer: Because if input is:\n             \"tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 10, 12, 13, 14,  0, 15,\n                      16, 17, 18, 19, 20, 14, 21, 22, 23, 24,  2])\", that's length 29. If\n                      embedding dimension arg for model (which is the output of the embedding\n                      layer and input to the linear layer) is say, 5, then the embedding\n                      layer will output a 2d matrix of size 29,5 because there's 29 values in\n                      the original tensor so theres a nested tensor for each one. Remember the\n                      embedding dimension is INPUT to the linear layer, it has the same value\n                      of 5. Since the embedding layer output shape is 29,5 , it works.\n\n\n          Solution 2: I used t.mean(x,dim=0) which get the mean in a horizontal fashion. Why did\n            it work? BEFORE matrix x goes into the embedding layer, the tensor is:\n            \"tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 10, 12, 13, 14,  0, 15,\n                     16, 17, 18, 19, 20, 14, 21, 22, 23, 24,  2])\" More importantly the shape/size\n            is 29. AFTER the matrix x goes through the embedding layer, it's shape/size is (29,5).\n            It's now 2d. Why? Well because the output of the embedding layer (called embed_dim)\n            is 5. So it gets 29 matrices of length 5 each. Then the linear layers INPUT is embed_dim\n            as well which is of course 5. So the linear layer can take a 2d matrix as long as the\n            columns of the 2d matrix (the \"5\" in 29,5) matches the linear layers INPUT (input is\n            also 5).\n            Ex Code:\n            \"td = t.tensor([[1,4,2,8],\n                            [6,9,3,7]], dtype=t.float32)\n              x = t.nn.Linear(4, 1)\n              x(td)\"\n\n            Will print something like:\n            \"tensor([[2.5558],\n                     [4.6453]], grad_fn=<AddmmBackward0>)\"\n\n            Ex code 2 (1d):\n            \" # 1d linear layer test. Tensor is \"tensor([5., 5., 5.])\", shape is torch.Size([3])\n              e = t.tensor([5] * 3, dtype=t.float32)\n              x = t.nn.Linear(3, 1)\n              # Will print something like \"tensor([0.6625], grad_fn=<ViewBackward0>)\" is linear output is 1.\n              print(x(e))\"\n\n\n\n          Conclusion: Solving the issue WITHOUT messing with t.mean(x, dim=1) is impossible. Simply\n            because of the dimensions of both x (after it goes through t.mean) and the input of the\n            linear layer.\n            1) Dimension of x after t.mean(x, dim=1) - torch.Size([29])\n            2) Dimensions of linear layer - 5,3. 5 input, 3 output.\n\n            I initially THOUGHT the REAL size was 30, due to programming indexing from 0. If that\n            was the case I had an idea to resize the x matrix into shape (6,5) because that'll be\n            accepted by the linear linear and it'd work. As a matter of fact I wrote some test\n            code for just that issue, resizing a tensor that was initially 30 in length but the\n            wrong input size for a linear layer that had input as 5. See code below:\n            \"\n              # Get same values.\n              t.manual_seed(0)\n\n              # nt = new tensor. Make tensor of size 30, (0-29)\n              nt = t.rand(30)\n              print(f'New tensor:\\n{nt}\\nNew tensor SIZE: {nt.shape}\\n\\n')\n\n              # Create a linear layer which only takes 1d tensors of 5, and 2d tensors of (n, 5).\n              ll = t.nn.Linear(5, 1)\n\n              # Try reshaping the new tensor to be in form (n, 5). First get size and check if its divisible by embed_dim (ed) 5\n              ed = 5\n              cur_mat_size = nt.size()[0]\n\n              # Can 30 be divided by 5? If so, we can make a new tensor evenly.\n              if cur_mat_size % ed == 0:\n                rows_for_reshape = int(cur_mat_size / ed)\n\n                # nm = new matrix.\n                nm = t.reshape(nt, (rows_for_reshape, ed))\n                print(f'New reshaped matrix is:\\n{nm}\\nNew reshaped matrix shape: {nm.shape}\\n\\n')\n\n                print(ll(nm))\n            \"\n\n            Feel free to copy and past in a different cell. The point of the code was to demonstrate how\n            it would be POSSIBLE to reshape a tensor so it can be passed to a linear layer, which I initially\n            thought was possible with the tensor([ 0,  1,  2,  3,  4,  5,  6,  7, etc]) input tensor used\n            below. But I remembered it was size 29 and not 30. '''\n\nclass EmbedClassifier(t.nn.Module):\n  def __init__(self, vocab_size, embed_dim, num_class):\n    super().__init__()\n    self.embedding = t.nn.Embedding(num_embeddings=vocab_size, embedding_dim=embed_dim)\n    self.fc = t.nn.Linear(embed_dim, num_class)\n\n  def forward(self, x):\n    print(f'x shape: {x.shape}\\nx BEFORE embedding:\\n{x}\\n\\n')\n    x = self.embedding(x)\n    print(f'x shape: {x.shape}\\nx AFTER embedding is: {x}\\n\\n')\n    x = t.mean(x,dim=0)\n    print(f'x shape after t.mean: {x.shape}\\nx after t.mean:\\n{x}\\n\\n')\n\n    return self.fc(x)\n\nec = EmbedClassifier(len(v), 5, 3)\n\n''' Tokenized text is:\n    \"['wall', 'st', '.', 'bears', 'claw', 'back', 'into', 'the', 'black', '(',\n      'reuters', ')', 'reuters', '-', 'short-sellers', ',', 'wall', 'street',\n      \"'\", 's', 'dwindling\\\\band', 'of', 'ultra-cynics', ',', 'are', 'seeing',\n      'green', 'again', '.']\n\n    Must get appropriate input for the model. Length is 29. Actual tensor is:\n    \"tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 10, 12, 13, 14,  0, 15,\n              16, 17, 18, 19, 20, 14, 21, 22, 23, 24,  2])\"  '''\nt_test = t.tensor([v.get_stoi()[cur_token] for cur_token in es], dtype=t.long)\n\nx = ec(t_test)\nprint(f'Returned tensor x:\\n{x}\\nReturned tensor x shape: {x.shape}')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":64,"status":"ok","timestamp":1707705731660,"user":{"displayName":"Omar Moodie","userId":"04801176971567262759"},"user_tz":480},"id":"1idStA3YWqJ3","outputId":"edd70acb-abe1-43b8-e140-706bc86cbc62"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":"x shape: torch.Size([29])\n\nx BEFORE embedding:\n\ntensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 10, 12, 13, 14,  0, 15,\n\n        16, 17, 18, 19, 20, 14, 21, 22, 23, 24,  2])\n\n\n\n\n\nx shape: torch.Size([29, 5])\n\nx AFTER embedding is: tensor([[-1.1908e+00, -2.1081e-01, -2.9817e-01, -3.5324e-01,  4.2111e-01],\n\n        [-2.9621e-01, -1.1288e+00, -1.8752e+00, -1.2576e+00, -9.7593e-01],\n\n        [-3.3415e-01, -6.8127e-01,  1.0206e+00,  9.0301e-01, -6.6421e-01],\n\n        [ 1.1420e+00,  1.3447e+00,  1.7629e+00, -9.2219e-01,  1.0127e+00],\n\n        [ 2.5227e-01, -3.3943e-01, -1.5154e-01, -5.7956e-01, -6.1363e-01],\n\n        [ 8.0078e-01, -8.4058e-03, -2.6809e-01,  3.6670e-01, -8.7147e-01],\n\n        [ 3.5158e-01,  9.7037e-01, -6.1841e-01, -1.7150e+00, -9.4477e-01],\n\n        [ 5.6200e-02, -1.3585e+00, -1.5107e+00,  1.8437e-01, -1.1318e+00],\n\n        [-4.4572e-01,  1.7038e-01,  9.6803e-01, -4.9766e-01,  2.4211e+00],\n\n        [ 8.4083e-02,  1.3674e-01, -1.1200e-01, -1.2794e+00,  4.8112e-01],\n\n        [-3.2511e-01,  1.2637e+00,  3.0319e+00, -1.7106e-01, -1.5574e+00],\n\n        [-1.3395e-01, -1.2261e-02,  5.7549e-01, -4.3395e-01, -1.7950e-01],\n\n        [-3.2511e-01,  1.2637e+00,  3.0319e+00, -1.7106e-01, -1.5574e+00],\n\n        [ 3.9644e-01,  3.0643e-02, -3.0668e-01, -8.6101e-01, -9.6468e-01],\n\n        [-5.4013e-01, -8.8454e-01,  5.9310e-01,  4.7474e-01, -8.8687e-01],\n\n        [-7.1413e-01,  9.3311e-01, -1.5028e+00,  2.2423e-01,  1.3635e+00],\n\n        [-1.1908e+00, -2.1081e-01, -2.9817e-01, -3.5324e-01,  4.2111e-01],\n\n        [-1.7817e+00, -1.3880e+00, -5.0155e-01, -4.2099e-01,  5.2547e-01],\n\n        [ 9.2339e-01,  1.5365e+00, -1.2359e+00, -9.8602e-01,  5.3560e-01],\n\n        [-9.5344e-01,  1.5216e+00, -2.5985e-03,  3.0238e-01,  8.4563e-01],\n\n        [-1.1308e+00, -5.9252e-01, -1.0334e+00,  1.0114e+00,  4.9759e-01],\n\n        [-1.1516e-02, -8.5977e-01,  5.9038e-02, -9.7705e-01,  1.1238e+00],\n\n        [ 3.5628e-01, -3.6851e-01, -6.1963e-01, -4.2227e-01, -2.8116e+00],\n\n        [-7.1413e-01,  9.3311e-01, -1.5028e+00,  2.2423e-01,  1.3635e+00],\n\n        [-3.0770e-01, -4.8818e-01,  1.5327e+00, -1.5249e+00, -4.9166e-01],\n\n        [-2.8156e-01, -2.0995e-01, -2.3335e-01, -1.1894e+00, -3.4772e-01],\n\n        [-1.9881e-01, -5.2293e-01, -3.6105e-01, -4.3697e-01, -8.2985e-02],\n\n        [-2.2953e-01, -1.4091e+00,  1.4600e+00,  1.7599e+00, -8.4887e-01],\n\n        [-3.3415e-01, -6.8127e-01,  1.0206e+00,  9.0301e-01, -6.6421e-01]],\n\n       grad_fn=<EmbeddingBackward0>)\n\n\n\n\n\nx shape after t.mean: torch.Size([5])\n\nx after t.mean:\n\ntensor([-0.2440, -0.0431,  0.0905, -0.2827, -0.1580], grad_fn=<MeanBackward1>)\n\n\n\n\n\nReturned tensor x:\n\ntensor([-0.2359,  0.2123,  0.0163], grad_fn=<ViewBackward0>)\n\nReturned tensor x shape: torch.Size([3])\n"}]},{"cell_type":"code","source":"''' This code documents why solving the 3rd error: \"RuntimeError: mat1 and mat2 shapes cannot\n    be multiplied (1x29 and 5x3)\" in the above cell, was impossible. '''\n\n# Get same values.\nt.manual_seed(0)\n\n# nt = new tensor. Make tensor of size 30, (0-29)\nnt = t.rand(30)\nprint(f'New tensor:\\n{nt}\\nNew tensor SIZE: {nt.shape}\\n\\n')\n\n# Create a linear layer which only takes 1d tensors of 5, and 2d tensors of (n, 5).\nll = t.nn.Linear(5, 1)\n\n# Try reshaping the new tensor to be in form (n, 5). First get size and check if its divisible by embed_dim (ed) 5\ned = 5\ncur_mat_size = nt.size()[0]\n\n# Can 30 be divided by 5? If so, we can make a new tensor evenly.\nif cur_mat_size % ed == 0:\n  rows_for_reshape = int(cur_mat_size / ed)\n\n  # nm = new matrix.\n  nm = t.reshape(nt, (rows_for_reshape, ed))\n  print(f'New reshaped matrix is:\\n{nm}\\nNew reshaped matrix shape: {nm.shape}\\n\\n')\n\n  print(ll(nm))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RiWS4I5YhLyc","executionInfo":{"status":"ok","timestamp":1707705731660,"user_tz":480,"elapsed":38,"user":{"displayName":"Omar Moodie","userId":"04801176971567262759"}},"outputId":"932ae9aa-ce4c-4681-9004-285e70d579ff"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":"New tensor:\n\ntensor([0.4963, 0.7682, 0.0885, 0.1320, 0.3074, 0.6341, 0.4901, 0.8964, 0.4556,\n\n        0.6323, 0.3489, 0.4017, 0.0223, 0.1689, 0.2939, 0.5185, 0.6977, 0.8000,\n\n        0.1610, 0.2823, 0.6816, 0.9152, 0.3971, 0.8742, 0.4194, 0.5529, 0.9527,\n\n        0.0362, 0.1852, 0.3734])\n\nNew tensor SIZE: torch.Size([30])\n\n\n\n\n\nNew reshaped matrix is:\n\ntensor([[0.4963, 0.7682, 0.0885, 0.1320, 0.3074],\n\n        [0.6341, 0.4901, 0.8964, 0.4556, 0.6323],\n\n        [0.3489, 0.4017, 0.0223, 0.1689, 0.2939],\n\n        [0.5185, 0.6977, 0.8000, 0.1610, 0.2823],\n\n        [0.6816, 0.9152, 0.3971, 0.8742, 0.4194],\n\n        [0.5529, 0.9527, 0.0362, 0.1852, 0.3734]])\n\nNew reshaped matrix shape: torch.Size([6, 5])\n\n\n\n\n\ntensor([[-0.3574],\n\n        [-0.8912],\n\n        [-0.4575],\n\n        [-0.5929],\n\n        [-0.6101],\n\n        [-0.3124]], grad_fn=<AddmmBackward0>)\n"}]},{"cell_type":"markdown","source":"# 7) Gensim","metadata":{"id":"fRtH-ez2ytZG"}},{"cell_type":"code","source":"import gensim.downloader as api\n\n'''\n\nCommenting this out because it takes forever to download\n\n'''\n\n# # w2v has word embeddings and pytorch neural nets work with them.\n# w2v = api.load('word2vec-google-news-300')\n\n# print(type(w2v['taco'])) # Returns numpy.ndarray\n# print(w2v['taco'][:10]) # Get first 10 values of 300 embedded vector.\n\n# ''' [('Jackson', 0.5326348543167114),\n#      ('Prince', 0.5306329727172852),\n#      ('Tupou_V.', 0.5292826294898987),\n#      ('KIng', 0.5227501392364502),\n#      ('e_mail_robert.king_@', 0.5173623561859131)] '''\n# print(w2v.similar_by_word('King', topn=5)) # This got the values in below comment.\n\n# '''\n# w is vehicle and x is 0.7821096181869507\n# w is cars and x is 0.7423831224441528\n# w is SUV and x is 0.7160962224006653\n# w is minivan and x is 0.6907036900520325\n# w is truck and x is 0.6735789775848389\n# w is Car and x is 0.6677608489990234\n# w is Ford_Focus and x is 0.667320191860199\n# w is Honda_Civic and x is 0.6626849174499512\n# w is Jeep and x is 0.651133120059967\n# w is pickup_truck and x is 0.6441438794136047 '''\n\n# # This gets comment above.\n# for w, x in w2v.most_similar('car'):\n#   print(f'w is {w} and x is {x}')","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"NsYpORhtytMj","executionInfo":{"status":"ok","timestamp":1707705732102,"user_tz":480,"elapsed":466,"user":{"displayName":"Omar Moodie","userId":"04801176971567262759"}},"outputId":"875e6d4e-73f1-4690-d860-d3d8f3385e24"},"execution_count":30,"outputs":[{"output_type":"execute_result","execution_count":30,"data":{"text/plain":["'\\n\\nCommenting this out because it takes forever to download\\n\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{}}]},{"cell_type":"code","source":"# A bit quicker to download.\nte = api.load(\"glove-twitter-25\")","metadata":{"id":"PZ5iz1dV6N12","executionInfo":{"status":"ok","timestamp":1707705759911,"user_tz":480,"elapsed":27827,"user":{"displayName":"Omar Moodie","userId":"04801176971567262759"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"''' .vocab can't be used with this set of embeddings, so key_to_index returns a dictionary. Also\n     index_to_key returns a list which is much better.'''\nlen(te.key_to_index)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"luE9EBQr7lRh","executionInfo":{"status":"ok","timestamp":1707705759914,"user_tz":480,"elapsed":71,"user":{"displayName":"Omar Moodie","userId":"04801176971567262759"}},"outputId":"e7bfc601-e95a-4331-dc4e-04126cb5cbde"},"execution_count":32,"outputs":[{"output_type":"execute_result","execution_count":32,"data":{"text/plain":["1193514"]},"metadata":{}}]},{"cell_type":"code","source":"all_words = te.index_to_key\nselected_word = all_words[0]\nemb = te[selected_word]\n\nprint(f'Word: {selected_word}\\nEmbedding FOR {selected_word}:\\n{emb}')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OE9xLVIG8OIW","executionInfo":{"status":"ok","timestamp":1707705759918,"user_tz":480,"elapsed":59,"user":{"displayName":"Omar Moodie","userId":"04801176971567262759"}},"outputId":"e393ed46-7ed9-4e27-a37f-668f60e8be45"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":"Word: <user>\n\nEmbedding FOR <user>:\n\n[ 0.62415   0.62476  -0.082335  0.20101  -0.13741  -0.11431   0.77909\n\n  2.6356   -0.46351   0.57465  -0.024888 -0.015466 -2.9696   -0.49876\n\n  0.095034 -0.94879  -0.017336 -0.86349  -1.3348    0.046811  0.36999\n\n -0.57663  -0.48469   0.40078   0.75345 ]\n"}]},{"cell_type":"markdown","source":"# 8) Updating embedding weights with pre trained embeddings","metadata":{"id":"TPZubnmE9rp-"}},{"cell_type":"code","source":"''' The concept of this is literally one embedding layer borrowing/taking embedding values.\n    In a real model, there might be certain words that don't have proper embedding values at\n    all. So why not plug those holes up? First I'll use an example embedding layer. It'll\n    take a vocab size and output a embed_dim size tensor.\n\n    The issue that also happened in the EmbedClassifier model should be talked about here.\n    The second error that happened was \"IndexError: index out of range in self\". Basically,\n    to sum the error, if there's a tensor like t.tensor([15]) and the embedding layer is:\n    t.nn.Embedding(num_embeddings=15, embedding_dim=5), we can't pass the tensor to it. The\n    embedding first arg is the MAX value for ALL elements in a given tensor. So I need to be\n    careful about the size of the embedding layer.\n\n    Errors:\n    1) \"RuntimeError: a view of a leaf Variable that requires grad is being used in an\n        in-place operation.\"\n\n        Solution: el.weight.requires_grad = False '''\n\n# Get max length of vocab dictionary.\nel = t.nn.Embedding(num_embeddings=len(te.key_to_index), embedding_dim=25)\nel.weight.requires_grad = False\n\nnum_words = 5\n\n# Loop for first 5 words.\nfor i, x in zip(range(num_words), all_words):\n  print(f'-----Index {i}-----\\nWord: {x}\\nWord embedding in glove embeddings:\\n{te[x]}\\n\\n')\n  print(f'--- Previous model embedding:\\n{el.weight[i]}')\n  # Update the embedding with embedding in downloaded word embeddings (currently \"glove-twitter-25\")\n  el.weight[i] = t.tensor(te[x], dtype=t.float32)\n  print(f'--- UPDATE model embedding:\\n{el.weight[i]}\\n\\n')\n\n# Get all new weights and display them.\nupdated_weights = el.weight[:num_words]\nprint(f'New updated first {num_words} word embeddings in embedding layer:\\n{updated_weights}')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ljE-xb5G9pKn","executionInfo":{"status":"ok","timestamp":1707705760145,"user_tz":480,"elapsed":268,"user":{"displayName":"Omar Moodie","userId":"04801176971567262759"}},"outputId":"5f94ce14-3c00-4519-99e7-86816058fda1"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":"-----Index 0-----\n\nWord: <user>\n\nWord embedding in glove embeddings:\n\n[ 0.62415   0.62476  -0.082335  0.20101  -0.13741  -0.11431   0.77909\n\n  2.6356   -0.46351   0.57465  -0.024888 -0.015466 -2.9696   -0.49876\n\n  0.095034 -0.94879  -0.017336 -0.86349  -1.3348    0.046811  0.36999\n\n -0.57663  -0.48469   0.40078   0.75345 ]\n\n\n\n\n\n--- Previous model embedding:\n\ntensor([ 0.4397,  0.1124,  0.6408,  0.4412, -0.2159, -0.7425,  0.5627,  0.2596,\n\n         0.5229,  2.3022, -1.4689, -1.5867,  1.2032,  0.0845, -1.2001, -0.0048,\n\n        -0.2303, -0.3918,  0.5433, -0.3952,  0.2055, -0.4503, -0.5731, -0.5554,\n\n        -1.5312])\n\n--- UPDATE model embedding:\n\ntensor([ 0.6241,  0.6248, -0.0823,  0.2010, -0.1374, -0.1143,  0.7791,  2.6356,\n\n        -0.4635,  0.5746, -0.0249, -0.0155, -2.9696, -0.4988,  0.0950, -0.9488,\n\n        -0.0173, -0.8635, -1.3348,  0.0468,  0.3700, -0.5766, -0.4847,  0.4008,\n\n         0.7534])\n\n\n\n\n\n-----Index 1-----\n\nWord: .\n\nWord embedding in glove embeddings:\n\n[ 0.69586  -1.1469   -0.41797  -0.022311 -0.023801  0.82358   1.2228\n\n  1.741    -0.90979   1.3725    0.1153   -0.63906  -3.2252    0.61269\n\n  0.33544  -0.57058  -0.50861  -0.16575  -0.98153  -0.8213    0.24333\n\n -0.14482  -0.67877   0.7061    0.40833 ]\n\n\n\n\n\n--- Previous model embedding:\n\ntensor([-1.2341,  1.8197, -0.5515, -1.3253,  0.1886, -0.0691, -0.4949, -1.4782,\n\n         2.5672, -0.4731,  0.3356,  1.5091,  2.0820,  1.7067,  2.3804, -1.0670,\n\n         1.1149, -0.1407,  0.8058,  0.3276, -0.7607, -1.5991,  0.0185,  0.8419,\n\n        -0.4000])\n\n--- UPDATE model embedding:\n\ntensor([ 0.6959, -1.1469, -0.4180, -0.0223, -0.0238,  0.8236,  1.2228,  1.7410,\n\n        -0.9098,  1.3725,  0.1153, -0.6391, -3.2252,  0.6127,  0.3354, -0.5706,\n\n        -0.5086, -0.1657, -0.9815, -0.8213,  0.2433, -0.1448, -0.6788,  0.7061,\n\n         0.4083])\n\n\n\n\n\n-----Index 2-----\n\nWord: :\n\nWord embedding in glove embeddings:\n\n[ 1.1242    0.054519 -0.037362  0.10046   0.11923  -0.30009   1.0938\n\n  2.537    -0.072802  1.0491    1.0931    0.066084 -2.7036   -0.14391\n\n -0.22031  -0.99347  -0.65072  -0.030948 -1.0817   -0.64701   0.32341\n\n -0.41612  -0.5268   -0.047166  0.71549 ]\n\n\n\n\n\n--- Previous model embedding:\n\ntensor([ 1.0395,  0.3582, -0.0033, -0.5344,  1.1687,  0.3945, -1.0450, -0.9565,\n\n         0.0335,  0.7101, -1.5353, -0.4127,  0.9663,  1.6248, -2.6133, -1.6965,\n\n        -0.2282,  0.2800,  0.0732,  1.1133,  0.2823,  0.4342,  0.4569, -0.8654,\n\n         0.7813])\n\n--- UPDATE model embedding:\n\ntensor([ 1.1242,  0.0545, -0.0374,  0.1005,  0.1192, -0.3001,  1.0938,  2.5370,\n\n        -0.0728,  1.0491,  1.0931,  0.0661, -2.7036, -0.1439, -0.2203, -0.9935,\n\n        -0.6507, -0.0309, -1.0817, -0.6470,  0.3234, -0.4161, -0.5268, -0.0472,\n\n         0.7155])\n\n\n\n\n\n-----Index 3-----\n\nWord: rt\n\nWord embedding in glove embeddings:\n\n[ 0.74056  0.9155  -0.16352  0.35843  0.05266  0.1456   1.0421   2.8073\n\n  0.12865  1.0492   0.13033  0.20508 -2.6686  -0.50551 -0.29574 -0.91433\n\n -0.40456 -1.0988  -1.0333  -0.17875  0.37979 -0.25922 -0.74854  0.36001\n\n  0.61206]\n\n\n\n\n\n--- Previous model embedding:\n\ntensor([-0.9268,  0.2064, -0.3334, -0.4288,  0.2329,  0.9625,  0.3492, -0.9215,\n\n        -0.0562, -0.7015,  1.0367, -0.6037, -1.2788,  0.1239,  1.1648,  0.9234,\n\n         1.3873,  1.3750,  0.6596,  0.4766, -1.0163,  0.6104,  0.4669,  1.9507,\n\n        -1.0631])\n\n--- UPDATE model embedding:\n\ntensor([ 0.7406,  0.9155, -0.1635,  0.3584,  0.0527,  0.1456,  1.0421,  2.8073,\n\n         0.1286,  1.0492,  0.1303,  0.2051, -2.6686, -0.5055, -0.2957, -0.9143,\n\n        -0.4046, -1.0988, -1.0333, -0.1787,  0.3798, -0.2592, -0.7485,  0.3600,\n\n         0.6121])\n\n\n\n\n\n-----Index 4-----\n\nWord: ,\n\nWord embedding in glove embeddings:\n\n[ 0.84705  -1.0349   -0.050419  0.27164  -0.58659   0.99514   0.25267\n\n  1.6963    0.10313   0.80073   0.74655  -1.2667   -4.036    -0.22557\n\n  0.16322  -0.67015  -0.64812   0.010373 -0.71889  -0.74997   0.24862\n\n  0.10319  -1.1732    0.58196   0.33846 ]\n\n\n\n\n\n--- Previous model embedding:\n\ntensor([ 1.1404, -0.0899,  0.7298, -1.8453, -0.1021, -1.0335, -0.3126,  0.2458,\n\n         0.3772,  1.1012, -1.1428,  0.0376,  0.2886,  0.3866, -0.2011, -0.1179,\n\n        -0.8294, -1.4073,  1.6268,  0.1723, -0.7043,  0.3147,  0.1574,  0.3854,\n\n         0.5737])\n\n--- UPDATE model embedding:\n\ntensor([ 0.8471, -1.0349, -0.0504,  0.2716, -0.5866,  0.9951,  0.2527,  1.6963,\n\n         0.1031,  0.8007,  0.7466, -1.2667, -4.0360, -0.2256,  0.1632, -0.6701,\n\n        -0.6481,  0.0104, -0.7189, -0.7500,  0.2486,  0.1032, -1.1732,  0.5820,\n\n         0.3385])\n\n\n\n\n\nNew updated first 5 word embeddings in embedding layer:\n\ntensor([[ 0.6241,  0.6248, -0.0823,  0.2010, -0.1374, -0.1143,  0.7791,  2.6356,\n\n         -0.4635,  0.5746, -0.0249, -0.0155, -2.9696, -0.4988,  0.0950, -0.9488,\n\n         -0.0173, -0.8635, -1.3348,  0.0468,  0.3700, -0.5766, -0.4847,  0.4008,\n\n          0.7534],\n\n        [ 0.6959, -1.1469, -0.4180, -0.0223, -0.0238,  0.8236,  1.2228,  1.7410,\n\n         -0.9098,  1.3725,  0.1153, -0.6391, -3.2252,  0.6127,  0.3354, -0.5706,\n\n         -0.5086, -0.1657, -0.9815, -0.8213,  0.2433, -0.1448, -0.6788,  0.7061,\n\n          0.4083],\n\n        [ 1.1242,  0.0545, -0.0374,  0.1005,  0.1192, -0.3001,  1.0938,  2.5370,\n\n         -0.0728,  1.0491,  1.0931,  0.0661, -2.7036, -0.1439, -0.2203, -0.9935,\n\n         -0.6507, -0.0309, -1.0817, -0.6470,  0.3234, -0.4161, -0.5268, -0.0472,\n\n          0.7155],\n\n        [ 0.7406,  0.9155, -0.1635,  0.3584,  0.0527,  0.1456,  1.0421,  2.8073,\n\n          0.1286,  1.0492,  0.1303,  0.2051, -2.6686, -0.5055, -0.2957, -0.9143,\n\n         -0.4046, -1.0988, -1.0333, -0.1787,  0.3798, -0.2592, -0.7485,  0.3600,\n\n          0.6121],\n\n        [ 0.8471, -1.0349, -0.0504,  0.2716, -0.5866,  0.9951,  0.2527,  1.6963,\n\n          0.1031,  0.8007,  0.7466, -1.2667, -4.0360, -0.2256,  0.1632, -0.6701,\n\n         -0.6481,  0.0104, -0.7189, -0.7500,  0.2486,  0.1032, -1.1732,  0.5820,\n\n          0.3385]])\n"}]},{"cell_type":"markdown","source":"# 9) Glove embeddings & more","metadata":{"id":"kBvHndWxFfH-"}},{"cell_type":"code","source":"# ttv = torchtext vocab\nttv = torchtext.vocab.GloVe(name='6B', dim=50)","metadata":{"id":"JffEtUNgGQaA","executionInfo":{"status":"ok","timestamp":1707705760530,"user_tz":480,"elapsed":394,"user":{"displayName":"Omar Moodie","userId":"04801176971567262759"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"# Very similar to the vocab created earlier since this has stoi and itos as well\nttv[\"Car\"]","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"skeSoubLUGeZ","executionInfo":{"status":"ok","timestamp":1707705760532,"user_tz":480,"elapsed":154,"user":{"displayName":"Omar Moodie","userId":"04801176971567262759"}},"outputId":"31530f9d-c8d2-459f-e689-eef7f8e437cc"},"execution_count":36,"outputs":[{"output_type":"execute_result","execution_count":36,"data":{"text/plain":["tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0.])"]},"metadata":{}}]},{"cell_type":"code","source":"ttv.stoi","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vl43A1A4VUKV","executionInfo":{"status":"ok","timestamp":1707705760533,"user_tz":480,"elapsed":118,"user":{"displayName":"Omar Moodie","userId":"04801176971567262759"}},"outputId":"a383b7ff-c847-4920-ec2b-92b909b2b6a1"},"execution_count":37,"outputs":[{"output_type":"execute_result","execution_count":37,"data":{"text/plain":["{'the': 0,\n"," ',': 1,\n"," '.': 2,\n"," 'of': 3,\n"," 'to': 4,\n"," 'and': 5,\n"," 'in': 6,\n"," 'a': 7,\n"," '\"': 8,\n"," \"'s\": 9,\n"," 'for': 10,\n"," '-': 11,\n"," 'that': 12,\n"," 'on': 13,\n"," 'is': 14,\n"," 'was': 15,\n"," 'said': 16,\n"," 'with': 17,\n"," 'he': 18,\n"," 'as': 19,\n"," 'it': 20,\n"," 'by': 21,\n"," 'at': 22,\n"," '(': 23,\n"," ')': 24,\n"," 'from': 25,\n"," 'his': 26,\n"," \"''\": 27,\n"," '``': 28,\n"," 'an': 29,\n"," 'be': 30,\n"," 'has': 31,\n"," 'are': 32,\n"," 'have': 33,\n"," 'but': 34,\n"," 'were': 35,\n"," 'not': 36,\n"," 'this': 37,\n"," 'who': 38,\n"," 'they': 39,\n"," 'had': 40,\n"," 'i': 41,\n"," 'which': 42,\n"," 'will': 43,\n"," 'their': 44,\n"," ':': 45,\n"," 'or': 46,\n"," 'its': 47,\n"," 'one': 48,\n"," 'after': 49,\n"," 'new': 50,\n"," 'been': 51,\n"," 'also': 52,\n"," 'we': 53,\n"," 'would': 54,\n"," 'two': 55,\n"," 'more': 56,\n"," \"'\": 57,\n"," 'first': 58,\n"," 'about': 59,\n"," 'up': 60,\n"," 'when': 61,\n"," 'year': 62,\n"," 'there': 63,\n"," 'all': 64,\n"," '--': 65,\n"," 'out': 66,\n"," 'she': 67,\n"," 'other': 68,\n"," 'people': 69,\n"," \"n't\": 70,\n"," 'her': 71,\n"," 'percent': 72,\n"," 'than': 73,\n"," 'over': 74,\n"," 'into': 75,\n"," 'last': 76,\n"," 'some': 77,\n"," 'government': 78,\n"," 'time': 79,\n"," '$': 80,\n"," 'you': 81,\n"," 'years': 82,\n"," 'if': 83,\n"," 'no': 84,\n"," 'world': 85,\n"," 'can': 86,\n"," 'three': 87,\n"," 'do': 88,\n"," ';': 89,\n"," 'president': 90,\n"," 'only': 91,\n"," 'state': 92,\n"," 'million': 93,\n"," 'could': 94,\n"," 'us': 95,\n"," 'most': 96,\n"," '_': 97,\n"," 'against': 98,\n"," 'u.s.': 99,\n"," 'so': 100,\n"," 'them': 101,\n"," 'what': 102,\n"," 'him': 103,\n"," 'united': 104,\n"," 'during': 105,\n"," 'before': 106,\n"," 'may': 107,\n"," 'since': 108,\n"," 'many': 109,\n"," 'while': 110,\n"," 'where': 111,\n"," 'states': 112,\n"," 'because': 113,\n"," 'now': 114,\n"," 'city': 115,\n"," 'made': 116,\n"," 'like': 117,\n"," 'between': 118,\n"," 'did': 119,\n"," 'just': 120,\n"," 'national': 121,\n"," 'day': 122,\n"," 'country': 123,\n"," 'under': 124,\n"," 'such': 125,\n"," 'second': 126,\n"," 'then': 127,\n"," 'company': 128,\n"," 'group': 129,\n"," 'any': 130,\n"," 'through': 131,\n"," 'china': 132,\n"," 'four': 133,\n"," 'being': 134,\n"," 'down': 135,\n"," 'war': 136,\n"," 'back': 137,\n"," 'off': 138,\n"," 'south': 139,\n"," 'american': 140,\n"," 'minister': 141,\n"," 'police': 142,\n"," 'well': 143,\n"," 'including': 144,\n"," 'team': 145,\n"," 'international': 146,\n"," 'week': 147,\n"," 'officials': 148,\n"," 'still': 149,\n"," 'both': 150,\n"," 'even': 151,\n"," 'high': 152,\n"," 'part': 153,\n"," 'told': 154,\n"," 'those': 155,\n"," 'end': 156,\n"," 'former': 157,\n"," 'these': 158,\n"," 'make': 159,\n"," 'billion': 160,\n"," 'work': 161,\n"," 'our': 162,\n"," 'home': 163,\n"," 'school': 164,\n"," 'party': 165,\n"," 'house': 166,\n"," 'old': 167,\n"," 'later': 168,\n"," 'get': 169,\n"," 'another': 170,\n"," 'tuesday': 171,\n"," 'news': 172,\n"," 'long': 173,\n"," 'five': 174,\n"," 'called': 175,\n"," '1': 176,\n"," 'wednesday': 177,\n"," 'military': 178,\n"," 'way': 179,\n"," 'used': 180,\n"," 'much': 181,\n"," 'next': 182,\n"," 'monday': 183,\n"," 'thursday': 184,\n"," 'friday': 185,\n"," 'game': 186,\n"," 'here': 187,\n"," '?': 188,\n"," 'should': 189,\n"," 'take': 190,\n"," 'very': 191,\n"," 'my': 192,\n"," 'north': 193,\n"," 'security': 194,\n"," 'season': 195,\n"," 'york': 196,\n"," 'how': 197,\n"," 'public': 198,\n"," 'early': 199,\n"," 'according': 200,\n"," 'several': 201,\n"," 'court': 202,\n"," 'say': 203,\n"," 'around': 204,\n"," 'foreign': 205,\n"," '10': 206,\n"," 'until': 207,\n"," 'set': 208,\n"," 'political': 209,\n"," 'says': 210,\n"," 'market': 211,\n"," 'however': 212,\n"," 'family': 213,\n"," 'life': 214,\n"," 'same': 215,\n"," 'general': 216,\n"," '': 217,\n"," 'left': 218,\n"," 'good': 219,\n"," 'top': 220,\n"," 'university': 221,\n"," 'going': 222,\n"," 'number': 223,\n"," 'major': 224,\n"," 'known': 225,\n"," 'points': 226,\n"," 'won': 227,\n"," 'six': 228,\n"," 'month': 229,\n"," 'dollars': 230,\n"," 'bank': 231,\n"," '2': 232,\n"," 'iraq': 233,\n"," 'use': 234,\n"," 'members': 235,\n"," 'each': 236,\n"," 'area': 237,\n"," 'found': 238,\n"," 'official': 239,\n"," 'sunday': 240,\n"," 'place': 241,\n"," 'go': 242,\n"," 'based': 243,\n"," 'among': 244,\n"," 'third': 245,\n"," 'times': 246,\n"," 'took': 247,\n"," 'right': 248,\n"," 'days': 249,\n"," 'local': 250,\n"," 'economic': 251,\n"," 'countries': 252,\n"," 'see': 253,\n"," 'best': 254,\n"," 'report': 255,\n"," 'killed': 256,\n"," 'held': 257,\n"," 'business': 258,\n"," 'west': 259,\n"," 'does': 260,\n"," 'own': 261,\n"," '%': 262,\n"," 'came': 263,\n"," 'law': 264,\n"," 'months': 265,\n"," 'women': 266,\n"," \"'re\": 267,\n"," 'power': 268,\n"," 'think': 269,\n"," 'service': 270,\n"," 'children': 271,\n"," 'bush': 272,\n"," 'show': 273,\n"," '/': 274,\n"," 'help': 275,\n"," 'chief': 276,\n"," 'saturday': 277,\n"," 'system': 278,\n"," 'john': 279,\n"," 'support': 280,\n"," 'series': 281,\n"," 'play': 282,\n"," 'office': 283,\n"," 'following': 284,\n"," 'me': 285,\n"," 'meeting': 286,\n"," 'expected': 287,\n"," 'late': 288,\n"," 'washington': 289,\n"," 'games': 290,\n"," 'european': 291,\n"," 'league': 292,\n"," 'reported': 293,\n"," 'final': 294,\n"," 'added': 295,\n"," 'without': 296,\n"," 'british': 297,\n"," 'white': 298,\n"," 'history': 299,\n"," 'man': 300,\n"," 'men': 301,\n"," 'became': 302,\n"," 'want': 303,\n"," 'march': 304,\n"," 'case': 305,\n"," 'few': 306,\n"," 'run': 307,\n"," 'money': 308,\n"," 'began': 309,\n"," 'open': 310,\n"," 'name': 311,\n"," 'trade': 312,\n"," 'center': 313,\n"," '3': 314,\n"," 'israel': 315,\n"," 'oil': 316,\n"," 'too': 317,\n"," 'al': 318,\n"," 'film': 319,\n"," 'win': 320,\n"," 'led': 321,\n"," 'east': 322,\n"," 'central': 323,\n"," '20': 324,\n"," 'air': 325,\n"," 'come': 326,\n"," 'chinese': 327,\n"," 'town': 328,\n"," 'leader': 329,\n"," 'army': 330,\n"," 'line': 331,\n"," 'never': 332,\n"," 'little': 333,\n"," 'played': 334,\n"," 'prime': 335,\n"," 'death': 336,\n"," 'companies': 337,\n"," 'least': 338,\n"," 'put': 339,\n"," 'forces': 340,\n"," 'past': 341,\n"," 'de': 342,\n"," 'half': 343,\n"," 'june': 344,\n"," 'saying': 345,\n"," 'know': 346,\n"," 'federal': 347,\n"," 'french': 348,\n"," 'peace': 349,\n"," 'earlier': 350,\n"," 'capital': 351,\n"," 'force': 352,\n"," 'great': 353,\n"," 'union': 354,\n"," 'near': 355,\n"," 'released': 356,\n"," 'small': 357,\n"," 'department': 358,\n"," 'every': 359,\n"," 'health': 360,\n"," 'japan': 361,\n"," 'head': 362,\n"," 'ago': 363,\n"," 'night': 364,\n"," 'big': 365,\n"," 'cup': 366,\n"," 'election': 367,\n"," 'region': 368,\n"," 'director': 369,\n"," 'talks': 370,\n"," 'program': 371,\n"," 'far': 372,\n"," 'today': 373,\n"," 'statement': 374,\n"," 'july': 375,\n"," 'although': 376,\n"," 'district': 377,\n"," 'again': 378,\n"," 'born': 379,\n"," 'development': 380,\n"," 'leaders': 381,\n"," 'council': 382,\n"," 'close': 383,\n"," 'record': 384,\n"," 'along': 385,\n"," 'county': 386,\n"," 'france': 387,\n"," 'went': 388,\n"," 'point': 389,\n"," 'must': 390,\n"," 'spokesman': 391,\n"," 'your': 392,\n"," 'member': 393,\n"," 'plan': 394,\n"," 'financial': 395,\n"," 'april': 396,\n"," 'recent': 397,\n"," 'campaign': 398,\n"," 'become': 399,\n"," 'troops': 400,\n"," 'whether': 401,\n"," 'lost': 402,\n"," 'music': 403,\n"," '15': 404,\n"," 'got': 405,\n"," 'israeli': 406,\n"," '30': 407,\n"," 'need': 408,\n"," '4': 409,\n"," 'lead': 410,\n"," 'already': 411,\n"," 'russia': 412,\n"," 'though': 413,\n"," 'might': 414,\n"," 'free': 415,\n"," 'hit': 416,\n"," 'rights': 417,\n"," '11': 418,\n"," 'information': 419,\n"," 'away': 420,\n"," '12': 421,\n"," '5': 422,\n"," 'others': 423,\n"," 'control': 424,\n"," 'within': 425,\n"," 'large': 426,\n"," 'economy': 427,\n"," 'press': 428,\n"," 'agency': 429,\n"," 'water': 430,\n"," 'died': 431,\n"," 'career': 432,\n"," 'making': 433,\n"," '...': 434,\n"," 'deal': 435,\n"," 'attack': 436,\n"," 'side': 437,\n"," 'seven': 438,\n"," 'better': 439,\n"," 'less': 440,\n"," 'september': 441,\n"," 'once': 442,\n"," 'clinton': 443,\n"," 'main': 444,\n"," 'due': 445,\n"," 'committee': 446,\n"," 'building': 447,\n"," 'conference': 448,\n"," 'club': 449,\n"," 'january': 450,\n"," 'decision': 451,\n"," 'stock': 452,\n"," 'america': 453,\n"," 'given': 454,\n"," 'give': 455,\n"," 'often': 456,\n"," 'announced': 457,\n"," 'television': 458,\n"," 'industry': 459,\n"," 'order': 460,\n"," 'young': 461,\n"," \"'ve\": 462,\n"," 'palestinian': 463,\n"," 'age': 464,\n"," 'start': 465,\n"," 'administration': 466,\n"," 'russian': 467,\n"," 'prices': 468,\n"," 'round': 469,\n"," 'december': 470,\n"," 'nations': 471,\n"," \"'m\": 472,\n"," 'human': 473,\n"," 'india': 474,\n"," 'defense': 475,\n"," 'asked': 476,\n"," 'total': 477,\n"," 'october': 478,\n"," 'players': 479,\n"," 'bill': 480,\n"," 'important': 481,\n"," 'southern': 482,\n"," 'move': 483,\n"," 'fire': 484,\n"," 'population': 485,\n"," 'rose': 486,\n"," 'november': 487,\n"," 'include': 488,\n"," 'further': 489,\n"," 'nuclear': 490,\n"," 'street': 491,\n"," 'taken': 492,\n"," 'media': 493,\n"," 'different': 494,\n"," 'issue': 495,\n"," 'received': 496,\n"," 'secretary': 497,\n"," 'return': 498,\n"," 'college': 499,\n"," 'working': 500,\n"," 'community': 501,\n"," 'eight': 502,\n"," 'groups': 503,\n"," 'despite': 504,\n"," 'level': 505,\n"," 'largest': 506,\n"," 'whose': 507,\n"," 'attacks': 508,\n"," 'germany': 509,\n"," 'august': 510,\n"," 'change': 511,\n"," 'church': 512,\n"," 'nation': 513,\n"," 'german': 514,\n"," 'station': 515,\n"," 'london': 516,\n"," 'weeks': 517,\n"," 'having': 518,\n"," '18': 519,\n"," 'research': 520,\n"," 'black': 521,\n"," 'services': 522,\n"," 'story': 523,\n"," '6': 524,\n"," 'europe': 525,\n"," 'sales': 526,\n"," 'policy': 527,\n"," 'visit': 528,\n"," 'northern': 529,\n"," 'lot': 530,\n"," 'across': 531,\n"," 'per': 532,\n"," 'current': 533,\n"," 'board': 534,\n"," 'football': 535,\n"," 'ministry': 536,\n"," 'workers': 537,\n"," 'vote': 538,\n"," 'book': 539,\n"," 'fell': 540,\n"," 'seen': 541,\n"," 'role': 542,\n"," 'students': 543,\n"," 'shares': 544,\n"," 'iran': 545,\n"," 'process': 546,\n"," 'agreement': 547,\n"," 'quarter': 548,\n"," 'full': 549,\n"," 'match': 550,\n"," 'started': 551,\n"," 'growth': 552,\n"," 'yet': 553,\n"," 'moved': 554,\n"," 'possible': 555,\n"," 'western': 556,\n"," 'special': 557,\n"," '100': 558,\n"," 'plans': 559,\n"," 'interest': 560,\n"," 'behind': 561,\n"," 'strong': 562,\n"," 'england': 563,\n"," 'named': 564,\n"," 'food': 565,\n"," 'period': 566,\n"," 'real': 567,\n"," 'authorities': 568,\n"," 'car': 569,\n"," 'term': 570,\n"," 'rate': 571,\n"," 'race': 572,\n"," 'nearly': 573,\n"," 'korea': 574,\n"," 'enough': 575,\n"," 'site': 576,\n"," 'opposition': 577,\n"," 'keep': 578,\n"," '25': 579,\n"," 'call': 580,\n"," 'future': 581,\n"," 'taking': 582,\n"," 'island': 583,\n"," '2008': 584,\n"," '2006': 585,\n"," 'road': 586,\n"," 'outside': 587,\n"," 'really': 588,\n"," 'century': 589,\n"," 'democratic': 590,\n"," 'almost': 591,\n"," 'single': 592,\n"," 'share': 593,\n"," 'leading': 594,\n"," 'trying': 595,\n"," 'find': 596,\n"," 'album': 597,\n"," 'senior': 598,\n"," 'minutes': 599,\n"," 'together': 600,\n"," 'congress': 601,\n"," 'index': 602,\n"," 'australia': 603,\n"," 'results': 604,\n"," 'hard': 605,\n"," 'hours': 606,\n"," 'land': 607,\n"," 'action': 608,\n"," 'higher': 609,\n"," 'field': 610,\n"," 'cut': 611,\n"," 'coach': 612,\n"," 'elections': 613,\n"," 'san': 614,\n"," 'issues': 615,\n"," 'executive': 616,\n"," 'february': 617,\n"," 'production': 618,\n"," 'areas': 619,\n"," 'river': 620,\n"," 'face': 621,\n"," 'using': 622,\n"," 'japanese': 623,\n"," 'province': 624,\n"," 'park': 625,\n"," 'price': 626,\n"," 'commission': 627,\n"," 'california': 628,\n"," 'father': 629,\n"," 'son': 630,\n"," 'education': 631,\n"," '7': 632,\n"," 'village': 633,\n"," 'energy': 634,\n"," 'shot': 635,\n"," 'short': 636,\n"," 'africa': 637,\n"," 'key': 638,\n"," 'red': 639,\n"," 'association': 640,\n"," 'average': 641,\n"," 'pay': 642,\n"," 'exchange': 643,\n"," 'eu': 644,\n"," 'something': 645,\n"," 'gave': 646,\n"," 'likely': 647,\n"," 'player': 648,\n"," 'george': 649,\n"," '2007': 650,\n"," 'victory': 651,\n"," '8': 652,\n"," 'low': 653,\n"," 'things': 654,\n"," '2010': 655,\n"," 'pakistan': 656,\n"," '14': 657,\n"," 'post': 658,\n"," 'social': 659,\n"," 'continue': 660,\n"," 'ever': 661,\n"," 'look': 662,\n"," 'chairman': 663,\n"," 'job': 664,\n"," '2000': 665,\n"," 'soldiers': 666,\n"," 'able': 667,\n"," 'parliament': 668,\n"," 'front': 669,\n"," 'himself': 670,\n"," 'problems': 671,\n"," 'private': 672,\n"," 'lower': 673,\n"," 'list': 674,\n"," 'built': 675,\n"," '13': 676,\n"," 'efforts': 677,\n"," 'dollar': 678,\n"," 'miles': 679,\n"," 'included': 680,\n"," 'radio': 681,\n"," 'live': 682,\n"," 'form': 683,\n"," 'david': 684,\n"," 'african': 685,\n"," 'increase': 686,\n"," 'reports': 687,\n"," 'sent': 688,\n"," 'fourth': 689,\n"," 'always': 690,\n"," 'king': 691,\n"," '50': 692,\n"," 'tax': 693,\n"," 'taiwan': 694,\n"," 'britain': 695,\n"," '16': 696,\n"," 'playing': 697,\n"," 'title': 698,\n"," 'middle': 699,\n"," 'meet': 700,\n"," 'global': 701,\n"," 'wife': 702,\n"," '2009': 703,\n"," 'position': 704,\n"," 'located': 705,\n"," 'clear': 706,\n"," 'ahead': 707,\n"," '2004': 708,\n"," '2005': 709,\n"," 'iraqi': 710,\n"," 'english': 711,\n"," 'result': 712,\n"," 'release': 713,\n"," 'violence': 714,\n"," 'goal': 715,\n"," 'project': 716,\n"," 'closed': 717,\n"," 'border': 718,\n"," 'body': 719,\n"," 'soon': 720,\n"," 'crisis': 721,\n"," 'division': 722,\n"," '&amp;': 723,\n"," 'served': 724,\n"," 'tour': 725,\n"," 'hospital': 726,\n"," 'kong': 727,\n"," 'test': 728,\n"," 'hong': 729,\n"," 'u.n.': 730,\n"," 'inc.': 731,\n"," 'technology': 732,\n"," 'believe': 733,\n"," 'organization': 734,\n"," 'published': 735,\n"," 'weapons': 736,\n"," 'agreed': 737,\n"," 'why': 738,\n"," 'nine': 739,\n"," 'summer': 740,\n"," 'wanted': 741,\n"," 'republican': 742,\n"," 'act': 743,\n"," 'recently': 744,\n"," 'texas': 745,\n"," 'course': 746,\n"," 'problem': 747,\n"," 'senate': 748,\n"," 'medical': 749,\n"," 'un': 750,\n"," 'done': 751,\n"," 'reached': 752,\n"," 'star': 753,\n"," 'continued': 754,\n"," 'investors': 755,\n"," 'living': 756,\n"," 'care': 757,\n"," 'signed': 758,\n"," '17': 759,\n"," 'art': 760,\n"," 'provide': 761,\n"," 'worked': 762,\n"," 'presidential': 763,\n"," 'gold': 764,\n"," 'obama': 765,\n"," 'morning': 766,\n"," 'dead': 767,\n"," 'opened': 768,\n"," \"'ll\": 769,\n"," 'event': 770,\n"," 'previous': 771,\n"," 'cost': 772,\n"," 'instead': 773,\n"," 'canada': 774,\n"," 'band': 775,\n"," 'teams': 776,\n"," 'daily': 777,\n"," '2001': 778,\n"," 'available': 779,\n"," 'drug': 780,\n"," 'coming': 781,\n"," '2003': 782,\n"," 'investment': 783,\n"," 's': 784,\n"," 'michael': 785,\n"," 'civil': 786,\n"," 'woman': 787,\n"," 'training': 788,\n"," 'appeared': 789,\n"," '9': 790,\n"," 'involved': 791,\n"," 'indian': 792,\n"," 'similar': 793,\n"," 'situation': 794,\n"," '24': 795,\n"," 'los': 796,\n"," 'running': 797,\n"," 'fighting': 798,\n"," 'mark': 799,\n"," '40': 800,\n"," 'trial': 801,\n"," 'hold': 802,\n"," 'australian': 803,\n"," 'thought': 804,\n"," '!': 805,\n"," 'study': 806,\n"," 'fall': 807,\n"," 'mother': 808,\n"," 'met': 809,\n"," 'relations': 810,\n"," 'anti': 811,\n"," '2002': 812,\n"," 'song': 813,\n"," 'popular': 814,\n"," 'base': 815,\n"," 'tv': 816,\n"," 'ground': 817,\n"," 'markets': 818,\n"," 'ii': 819,\n"," 'newspaper': 820,\n"," 'staff': 821,\n"," 'saw': 822,\n"," 'hand': 823,\n"," 'hope': 824,\n"," 'operations': 825,\n"," 'pressure': 826,\n"," 'americans': 827,\n"," 'eastern': 828,\n"," 'st.': 829,\n"," 'legal': 830,\n"," 'asia': 831,\n"," 'budget': 832,\n"," 'returned': 833,\n"," 'considered': 834,\n"," 'love': 835,\n"," 'wrote': 836,\n"," 'stop': 837,\n"," 'fight': 838,\n"," 'currently': 839,\n"," 'charges': 840,\n"," 'try': 841,\n"," 'aid': 842,\n"," 'ended': 843,\n"," 'management': 844,\n"," 'brought': 845,\n"," 'cases': 846,\n"," 'decided': 847,\n"," 'failed': 848,\n"," 'network': 849,\n"," 'works': 850,\n"," 'gas': 851,\n"," 'turned': 852,\n"," 'fact': 853,\n"," 'vice': 854,\n"," 'ca': 855,\n"," 'mexico': 856,\n"," 'trading': 857,\n"," 'especially': 858,\n"," 'reporters': 859,\n"," 'afghanistan': 860,\n"," 'common': 861,\n"," 'looking': 862,\n"," 'space': 863,\n"," 'rates': 864,\n"," 'manager': 865,\n"," 'loss': 866,\n"," '2011': 867,\n"," 'justice': 868,\n"," 'thousands': 869,\n"," 'james': 870,\n"," 'rather': 871,\n"," 'fund': 872,\n"," 'thing': 873,\n"," 'republic': 874,\n"," 'opening': 875,\n"," 'accused': 876,\n"," 'winning': 877,\n"," 'scored': 878,\n"," 'championship': 879,\n"," 'example': 880,\n"," 'getting': 881,\n"," 'biggest': 882,\n"," 'performance': 883,\n"," 'sports': 884,\n"," '1998': 885,\n"," 'let': 886,\n"," 'allowed': 887,\n"," 'schools': 888,\n"," 'means': 889,\n"," 'turn': 890,\n"," 'leave': 891,\n"," 'no.': 892,\n"," 'robert': 893,\n"," 'personal': 894,\n"," 'stocks': 895,\n"," 'showed': 896,\n"," 'light': 897,\n"," 'arrested': 898,\n"," 'person': 899,\n"," 'either': 900,\n"," 'offer': 901,\n"," 'majority': 902,\n"," 'battle': 903,\n"," '19': 904,\n"," 'class': 905,\n"," 'evidence': 906,\n"," 'makes': 907,\n"," 'society': 908,\n"," 'products': 909,\n"," 'regional': 910,\n"," 'needed': 911,\n"," 'stage': 912,\n"," 'am': 913,\n"," 'doing': 914,\n"," 'families': 915,\n"," 'construction': 916,\n"," 'various': 917,\n"," '1996': 918,\n"," 'sold': 919,\n"," 'independent': 920,\n"," 'kind': 921,\n"," 'airport': 922,\n"," 'paul': 923,\n"," 'judge': 924,\n"," 'internet': 925,\n"," 'movement': 926,\n"," 'room': 927,\n"," 'followed': 928,\n"," 'original': 929,\n"," 'angeles': 930,\n"," 'italy': 931,\n"," '`': 932,\n"," 'data': 933,\n"," 'comes': 934,\n"," 'parties': 935,\n"," 'nothing': 936,\n"," 'sea': 937,\n"," 'bring': 938,\n"," '2012': 939,\n"," 'annual': 940,\n"," 'officer': 941,\n"," 'beijing': 942,\n"," 'present': 943,\n"," 'remain': 944,\n"," 'nato': 945,\n"," '1999': 946,\n"," '22': 947,\n"," 'remains': 948,\n"," 'allow': 949,\n"," 'florida': 950,\n"," 'computer': 951,\n"," '21': 952,\n"," 'contract': 953,\n"," 'coast': 954,\n"," 'created': 955,\n"," 'demand': 956,\n"," 'operation': 957,\n"," 'events': 958,\n"," 'islamic': 959,\n"," 'beat': 960,\n"," 'analysts': 961,\n"," 'interview': 962,\n"," 'helped': 963,\n"," 'child': 964,\n"," 'probably': 965,\n"," 'spent': 966,\n"," 'asian': 967,\n"," 'effort': 968,\n"," 'cooperation': 969,\n"," 'shows': 970,\n"," 'calls': 971,\n"," 'investigation': 972,\n"," 'lives': 973,\n"," 'video': 974,\n"," 'yen': 975,\n"," 'runs': 976,\n"," 'tried': 977,\n"," 'bad': 978,\n"," 'described': 979,\n"," '1994': 980,\n"," 'toward': 981,\n"," 'written': 982,\n"," 'throughout': 983,\n"," 'established': 984,\n"," 'mission': 985,\n"," 'associated': 986,\n"," 'buy': 987,\n"," 'growing': 988,\n"," 'green': 989,\n"," 'forward': 990,\n"," 'competition': 991,\n"," 'poor': 992,\n"," 'latest': 993,\n"," 'banks': 994,\n"," 'question': 995,\n"," '1997': 996,\n"," 'prison': 997,\n"," 'feel': 998,\n"," 'attention': 999,\n"," ...}"]},"metadata":{}}]},{"cell_type":"code","source":"ttv.itos[379]","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"7VX01Sb5VaQ8","executionInfo":{"status":"ok","timestamp":1707705760534,"user_tz":480,"elapsed":100,"user":{"displayName":"Omar Moodie","userId":"04801176971567262759"}},"outputId":"3e515788-6a0e-4059-e0cf-7bb1fa7d020a"},"execution_count":38,"outputs":[{"output_type":"execute_result","execution_count":38,"data":{"text/plain":["'born'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{}}]},{"cell_type":"code","source":"# ft = first tensor, st = second tensor\nft = t.tensor([1,2,3,4,5])\nst = t.tensor([9,8,7,6,-1])\n\ntt = t.tensor([[3,2,4],\n               [1,5,7]])\n\n# 1) add up a 1d tensor. Both below gets 15.\n# print(ft.sum())\n# print(t.sum(ft))\n\n# 2) Add 2d tensor\n# print(tt.sum()) # Total 22\n# print(tt.sum(0)) # 0 = columns, so it adds by column.\n# print(tt.sum(1)) # 1 = rows, so it adds by row\n\n''' 3) Predictons and labels\n       In code projects something like \"torch.sum(predictions == labels).item()\" so\n       why not mess around with that here.\n\n       x = ground truths\n       y = predictions\n'''\n\nx = t.tensor([1,0,1,1,1,1,0,1]) # ground truths\ny = t.tensor([1,1,0,1,1,1,0,1]) # predictions\n\n''' == will get boolean vec on which columns MATCH. Ex in x and y above, index 0 is\n    both 1, so that's true, they equal eachother. Then the sum just how many Trues and\n    adds them since in a numerical fashion True is 1 and False is 0. So:\n    t.sum(tensor([ True, False, False,  True,  True,  True,  True,  True])) will be 6.\n    And of course .item just gets the number itself, out of the tensor. '''\n# print(x == y)\n# print(t.sum(x == y))\nprint(t.sum(x == y).item())","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FUUVsHboXQap","executionInfo":{"status":"ok","timestamp":1707705760537,"user_tz":480,"elapsed":92,"user":{"displayName":"Omar Moodie","userId":"04801176971567262759"}},"outputId":"29c73de7-3cf3-43f4-f1d8-fa2887db9d72"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":"6\n"}]},{"cell_type":"code","source":"''' Argmax is cool, simply gets the indices of highest values.\n    1 - Vertical/Row by row.\n    0 - Horizontal/Column by column.\n\n    So:\n    1 - Indices 1,0,1,2 and the numbers are 7,10,5,22.\n    0 - Indices 1,3,3 and the numbers are 10,20,22.\n\n    Argmin is opposite. '''\n\nz = t.tensor([[3, 7, 1],\n              [10, 3, 5],\n              [4, 5, 1],\n              [4, 20, 22]])\n\nprint(f'---Argmax---')\nprint(t.argmax(z, 1))\nprint(t.argmax(z, 0))\nprint('\\n\\n')\n\nprint(f'---Argmin---')\nprint(t.argmin(z, 1))\nprint(t.argmin(z, 0))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o5A9lVjGgHsO","executionInfo":{"status":"ok","timestamp":1707705760856,"user_tz":480,"elapsed":362,"user":{"displayName":"Omar Moodie","userId":"04801176971567262759"}},"outputId":"97f4e401-8a0c-4941-ab1d-a7ff290cf1d9"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":"---Argmax---\n\ntensor([1, 0, 1, 2])\n\ntensor([1, 3, 3])\n\n\n\n\n\n\n\n---Argmin---\n\ntensor([2, 1, 2, 0])\n\ntensor([0, 1, 0])\n"}]},{"cell_type":"markdown","source":"# 10) Packed Sequences","metadata":{"id":"F0x6CfCTj54V"}},{"cell_type":"code","source":"''' What are packed sequences?\n    Mainly for RNN.\n\n    [[1,2,3,4,5],\n     [6,7,8,0,0],\n     [9,0,0,0,0]]\"\n    Len is 5,3,1. RNN cells train with 1,6,9. Then 2,7. Then 3,8 Etc. So packed sequence is one\n    vec \"[1,6,9,2,7,3,8,4,5]\" Len of vec still 5,3,1.\n\n    First we need sentences of different lengths. \"ts\" is from section 1, tokenized sentences. '''\n\nfor tks in ts:\n  print(tks)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dwwt3Zbej8Zb","executionInfo":{"status":"ok","timestamp":1707705760857,"user_tz":480,"elapsed":349,"user":{"displayName":"Omar Moodie","userId":"04801176971567262759"}},"outputId":"29ac08f9-88ea-4843-f75f-af7bbc7fb9cd"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":"['wall', 'st', '.', 'bears', 'claw', 'back', 'into', 'the', 'black', '(', 'reuters', ')', 'reuters', '-', 'short-sellers', ',', 'wall', 'street', \"'\", 's', 'dwindling\\\\band', 'of', 'ultra-cynics', ',', 'are', 'seeing', 'green', 'again', '.']\n\n['carlyle', 'looks', 'toward', 'commercial', 'aerospace', '(', 'reuters', ')', 'reuters', '-', 'private', 'investment', 'firm', 'carlyle', 'group', ',', '\\\\which', 'has', 'a', 'reputation', 'for', 'making', 'well-timed', 'and', 'occasionally\\\\controversial', 'plays', 'in', 'the', 'defense', 'industry', ',', 'has', 'quietly', 'placed\\\\its', 'bets', 'on', 'another', 'part', 'of', 'the', 'market', '.']\n\n['oil', 'and', 'economy', 'cloud', 'stocks', \"'\", 'outlook', '(', 'reuters', ')', 'reuters', '-', 'soaring', 'crude', 'prices', 'plus', 'worries\\\\about', 'the', 'economy', 'and', 'the', 'outlook', 'for', 'earnings', 'are', 'expected', 'to\\\\hang', 'over', 'the', 'stock', 'market', 'next', 'week', 'during', 'the', 'depth', 'of', 'the\\\\summer', 'doldrums', '.']\n"}]},{"cell_type":"code","source":"# encode them, function in section 1.\nnum_sents = [encode(tks) for tks in ts]\n\nfor ns in num_sents:\n  print(ns)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n4pTRRmVma7-","executionInfo":{"status":"ok","timestamp":1707705760858,"user_tz":480,"elapsed":48,"user":{"displayName":"Omar Moodie","userId":"04801176971567262759"}},"outputId":"667d14c5-5bf7-429b-8f56-21d929bbf8ab"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":"[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 10, 12, 13, 14, 0, 15, 16, 17, 18, 19, 20, 14, 21, 22, 23, 24, 2]\n\n[25, 26, 27, 28, 29, 9, 10, 11, 10, 12, 30, 31, 32, 25, 33, 14, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 7, 45, 46, 14, 35, 47, 48, 49, 50, 51, 52, 19, 7, 53, 2]\n\n[54, 41, 55, 56, 57, 16, 58, 9, 10, 11, 10, 12, 59, 60, 61, 62, 63, 7, 55, 41, 7, 58, 38, 64, 21, 65, 66, 67, 7, 68, 53, 69, 70, 71, 7, 72, 19, 73, 74, 2]\n"}]},{"cell_type":"code","source":"# Now pad. This code was written already in section 1 as well.\npadded_sents = [t.nn.functional.pad(t.tensor(sent), (0, max_length - len(sent))) for sent in num_sents]\n\npadded_sents","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xfhJx_LFmzzy","executionInfo":{"status":"ok","timestamp":1707705760858,"user_tz":480,"elapsed":40,"user":{"displayName":"Omar Moodie","userId":"04801176971567262759"}},"outputId":"103a666d-b3dc-4a1b-c8a1-a805188660c2"},"execution_count":43,"outputs":[{"output_type":"execute_result","execution_count":43,"data":{"text/plain":["[tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 10, 12, 13, 14,  0, 15,\n","         16, 17, 18, 19, 20, 14, 21, 22, 23, 24,  2,  0,  0,  0,  0,  0,  0,  0,\n","          0,  0,  0,  0,  0,  0]),\n"," tensor([25, 26, 27, 28, 29,  9, 10, 11, 10, 12, 30, 31, 32, 25, 33, 14, 34, 35,\n","         36, 37, 38, 39, 40, 41, 42, 43, 44,  7, 45, 46, 14, 35, 47, 48, 49, 50,\n","         51, 52, 19,  7, 53,  2]),\n"," tensor([54, 41, 55, 56, 57, 16, 58,  9, 10, 11, 10, 12, 59, 60, 61, 62, 63,  7,\n","         55, 41,  7, 58, 38, 64, 21, 65, 66, 67,  7, 68, 53, 69, 70, 71,  7, 72,\n","         19, 73, 74,  2,  0,  0])]"]},"metadata":{}}]},{"cell_type":"code","source":"# tens_len = t.tensor(len(padded_sents[0]), dtype=t.int64, device='cpu')\n# tens_len = tens_len.unsqueeze(0)\n\n# t.nn.utils.rnn.pack_padded_sequence(padded_num_sents[0], lengths=tens_len)\n\n# Create 2d tensor of 0s to be used and have the num sents added to them soon.\na = t.zeros((len(padded_sents), len(padded_sents[0])))\n\n# Get lengths of each numerical sentence\nnum_sent_lens = [len(s) for s in num_sents]\nprint(f'Num sent lengths: {num_sent_lens}')\n\n# Get longest one, in this case it's 42.\nmax_len = max(num_sent_lens)\nprint(f'Max length: {max_len}\\n')\n\n''' Loop over the numerical sentences ALONG with the specific lengths. But do so with index,\n    that's why enumerate is used with \"i\". Remember \"a\" is a 2d tensor and I can access each\n    index with \"a[i, etc]\". num_sent will be current numerical sentence, and same concept for\n    sent_len, which will be the current length.\n\n    Ex numerical sentence: \" 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.,\n    10., 12., 13., 14.,  0., 15., 16., 17., 18., 19., 20., 14., 21., 22., 23., 24.,\n    2.\"\n    Ex length: 29\n\n    So if i is 0, then in the tensor of 0's, which is \"a\", go to the tensor in index 0\n    which would be \"[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n    0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n    0., 0., 0., 0.]\" and UP UNTIL the numerical sentence length, which is \":sent_len\",\n    apply the real numerical sentence. '''\nfor i, (num_sent, sent_len) in enumerate(zip(num_sents, num_sent_lens)):\n  a[i, :sent_len] = t.FloatTensor(num_sent)\n\na","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_Q3uBSW-oXIC","executionInfo":{"status":"ok","timestamp":1707705760858,"user_tz":480,"elapsed":34,"user":{"displayName":"Omar Moodie","userId":"04801176971567262759"}},"outputId":"dae8ab6d-3c0b-432d-e1f0-4fccff5519a4"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":"Num sent lengths: [29, 42, 40]\n\nMax length: 42\n\n\n"},{"output_type":"execute_result","execution_count":44,"data":{"text/plain":["tensor([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 10., 12.,\n","         13., 14.,  0., 15., 16., 17., 18., 19., 20., 14., 21., 22., 23., 24.,\n","          2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n","        [25., 26., 27., 28., 29.,  9., 10., 11., 10., 12., 30., 31., 32., 25.,\n","         33., 14., 34., 35., 36., 37., 38., 39., 40., 41., 42., 43., 44.,  7.,\n","         45., 46., 14., 35., 47., 48., 49., 50., 51., 52., 19.,  7., 53.,  2.],\n","        [54., 41., 55., 56., 57., 16., 58.,  9., 10., 11., 10., 12., 59., 60.,\n","         61., 62., 63.,  7., 55., 41.,  7., 58., 38., 64., 21., 65., 66., 67.,\n","          7., 68., 53., 69., 70., 71.,  7., 72., 19., 73., 74.,  2.,  0.,  0.]])"]},"metadata":{}}]},{"cell_type":"code","source":"t.LongTensor(num_sent_lens)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oVRs1T8JKThu","executionInfo":{"status":"ok","timestamp":1707705760858,"user_tz":480,"elapsed":26,"user":{"displayName":"Omar Moodie","userId":"04801176971567262759"}},"outputId":"227199d7-ec09-4a47-f7a6-d146a65dfbf8"},"execution_count":45,"outputs":[{"output_type":"execute_result","execution_count":45,"data":{"text/plain":["tensor([29, 42, 40])"]},"metadata":{}}]},{"cell_type":"code","source":"x, y = t.LongTensor(num_sent_lens).sort(0, descending=True)\n\nprint(x)\nprint(y)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DDzaJNvlKZyY","executionInfo":{"status":"ok","timestamp":1707705760859,"user_tz":480,"elapsed":21,"user":{"displayName":"Omar Moodie","userId":"04801176971567262759"}},"outputId":"d334b03a-e046-47a9-b2b4-7cb32bee6a7d"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":"tensor([42, 40, 29])\n\ntensor([1, 2, 0])\n"}]}]}