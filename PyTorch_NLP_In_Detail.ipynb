{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4zE4eSwDopU",
        "outputId": "8573389b-925c-4f7d-c41e-7b582a1d1c41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: portalocker>=2.8.2 in /usr/local/lib/python3.10/dist-packages (2.8.2)\n"
          ]
        }
      ],
      "source": [
        "import torch as t\n",
        "import numpy as np\n",
        "import torchtext\n",
        "from torchtext.datasets import AG_NEWS\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "import collections\n",
        "\n",
        "!pip install 'portalocker>=2.8.2'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tt7RVlhgsIrI"
      },
      "source": [
        "# 1) Torch text datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bU1BbW-AlWfE"
      },
      "outputs": [],
      "source": [
        "''' According to this link, https://pytorch.org/text/stable/datasets.html pretty much every\n",
        "    single torchtext (tt) dataset (ds) has root and split arguments.\n",
        "\n",
        "    1) root - ??? Directory where ds are saved ???\n",
        "    2) split - train or test for ag_news, but for a ds like SST2 it has train, test and DEV. '''\n",
        "train, test = AG_NEWS()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVbCU6Edqs8C",
        "outputId": "30582a06-0d18-45f8-ef1c-903a125d5530"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object ShardingFilterIterDataPipe.__iter__ at 0x78caf1f33ed0>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "''' Iter gives ability to of course loop (technically) over the object. As of now its type\n",
        "    is \"ShardingFilterIterDataPipe\". After iter? It's\n",
        "    \"<generator object ShardingFilterIterDataPipe.__iter__ at 0x7d2b405bc660>\" '''\n",
        "x = iter(train)\n",
        "\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "su71-J1glcPu",
        "outputId": "8f69e502-749f-4df5-e3ac-2c3b25780f35"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3,\n",
              " \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "''' Just keeps getting the next value, can also use a default value if end is reached.\n",
        "    https://stackoverflow.com/questions/76302971/question-in-pytorch-transformer-tutorial-about-nonetype-object-has-no-attribut '''\n",
        "next(iter(train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHDuAGLSnjOX",
        "outputId": "9853f719-2a60-4675-c599-bb38ad979b42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index 0:\n",
            "x: (3, \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/datapipes/iter/combining.py:333: UserWarning: Some child DataPipes are not exhausted when __iter__ is called. We are resetting the buffer and each child DataPipe will read from the start again.\n",
            "  warnings.warn(\"Some child DataPipes are not exhausted when __iter__ is called. We are resetting \"\n"
          ]
        }
      ],
      "source": [
        "# Zip is good for a certain range, 2, 5, etc. n in general. Very useful.\n",
        "# for i, x in zip(range(2), train):\n",
        "#   print(f'Index {i}. x:\\n{x}\\n\\n')\n",
        "\n",
        "# Enumerate works fine as well.\n",
        "for i, x in enumerate(train):\n",
        "  print(f'Index {i}:\\nx: {x}')\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGgiwL6qsMNh"
      },
      "source": [
        "# 2) Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PtOKwD7sRj1",
        "outputId": "ab28e231-5646-4512-beee-ac116145d549"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "List of sentences to tokenize:\n",
            "\n",
            "[\"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\", 'Carlyle Looks Toward Commercial Aerospace (Reuters) Reuters - Private investment firm Carlyle Group,\\\\which has a reputation for making well-timed and occasionally\\\\controversial plays in the defense industry, has quietly placed\\\\its bets on another part of the market.', \"Oil and Economy Cloud Stocks' Outlook (Reuters) Reuters - Soaring crude prices plus worries\\\\about the economy and the outlook for earnings are expected to\\\\hang over the stock market next week during the depth of the\\\\summer doldrums.\"]\n",
            "Total sentences: 3\n"
          ]
        }
      ],
      "source": [
        "# Get list of sentences\n",
        "s = []\n",
        "for i, x in zip(range(3), train):\n",
        "  s.append(x[1])\n",
        "\n",
        "print(f'List of sentences to tokenize:\\n\\n{s}\\nTotal sentences: {len(s)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbvlcfoOof_K",
        "outputId": "96f5bd81-5604-425c-8295-1fecefebb044"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['wall',\n",
              "  'st',\n",
              "  '.',\n",
              "  'bears',\n",
              "  'claw',\n",
              "  'back',\n",
              "  'into',\n",
              "  'the',\n",
              "  'black',\n",
              "  '(',\n",
              "  'reuters',\n",
              "  ')',\n",
              "  'reuters',\n",
              "  '-',\n",
              "  'short-sellers',\n",
              "  ',',\n",
              "  'wall',\n",
              "  'street',\n",
              "  \"'\",\n",
              "  's',\n",
              "  'dwindling\\\\band',\n",
              "  'of',\n",
              "  'ultra-cynics',\n",
              "  ',',\n",
              "  'are',\n",
              "  'seeing',\n",
              "  'green',\n",
              "  'again',\n",
              "  '.'],\n",
              " ['carlyle',\n",
              "  'looks',\n",
              "  'toward',\n",
              "  'commercial',\n",
              "  'aerospace',\n",
              "  '(',\n",
              "  'reuters',\n",
              "  ')',\n",
              "  'reuters',\n",
              "  '-',\n",
              "  'private',\n",
              "  'investment',\n",
              "  'firm',\n",
              "  'carlyle',\n",
              "  'group',\n",
              "  ',',\n",
              "  '\\\\which',\n",
              "  'has',\n",
              "  'a',\n",
              "  'reputation',\n",
              "  'for',\n",
              "  'making',\n",
              "  'well-timed',\n",
              "  'and',\n",
              "  'occasionally\\\\controversial',\n",
              "  'plays',\n",
              "  'in',\n",
              "  'the',\n",
              "  'defense',\n",
              "  'industry',\n",
              "  ',',\n",
              "  'has',\n",
              "  'quietly',\n",
              "  'placed\\\\its',\n",
              "  'bets',\n",
              "  'on',\n",
              "  'another',\n",
              "  'part',\n",
              "  'of',\n",
              "  'the',\n",
              "  'market',\n",
              "  '.'],\n",
              " ['oil',\n",
              "  'and',\n",
              "  'economy',\n",
              "  'cloud',\n",
              "  'stocks',\n",
              "  \"'\",\n",
              "  'outlook',\n",
              "  '(',\n",
              "  'reuters',\n",
              "  ')',\n",
              "  'reuters',\n",
              "  '-',\n",
              "  'soaring',\n",
              "  'crude',\n",
              "  'prices',\n",
              "  'plus',\n",
              "  'worries\\\\about',\n",
              "  'the',\n",
              "  'economy',\n",
              "  'and',\n",
              "  'the',\n",
              "  'outlook',\n",
              "  'for',\n",
              "  'earnings',\n",
              "  'are',\n",
              "  'expected',\n",
              "  'to\\\\hang',\n",
              "  'over',\n",
              "  'the',\n",
              "  'stock',\n",
              "  'market',\n",
              "  'next',\n",
              "  'week',\n",
              "  'during',\n",
              "  'the',\n",
              "  'depth',\n",
              "  'of',\n",
              "  'the\\\\summer',\n",
              "  'doldrums',\n",
              "  '.']]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "tk = get_tokenizer('basic_english')\n",
        "\n",
        "# ts = tokenized sentences. !!! do \"tk(s[0])\" for individual sentences !!!\n",
        "ts = [tk(sent) for sent in s]\n",
        "\n",
        "ts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MR6meOMxrwl4",
        "outputId": "1adeb8a7-3427-44d3-e122-ae07ebdc2b65"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'wall': 2,\n",
              "         'st': 1,\n",
              "         '.': 4,\n",
              "         'bears': 1,\n",
              "         'claw': 1,\n",
              "         'back': 1,\n",
              "         'into': 1,\n",
              "         'the': 7,\n",
              "         'black': 1,\n",
              "         '(': 3,\n",
              "         'reuters': 6,\n",
              "         ')': 3,\n",
              "         '-': 3,\n",
              "         'short-sellers': 1,\n",
              "         ',': 4,\n",
              "         'street': 1,\n",
              "         \"'\": 2,\n",
              "         's': 1,\n",
              "         'dwindling\\\\band': 1,\n",
              "         'of': 3,\n",
              "         'ultra-cynics': 1,\n",
              "         'are': 2,\n",
              "         'seeing': 1,\n",
              "         'green': 1,\n",
              "         'again': 1,\n",
              "         'carlyle': 2,\n",
              "         'looks': 1,\n",
              "         'toward': 1,\n",
              "         'commercial': 1,\n",
              "         'aerospace': 1,\n",
              "         'private': 1,\n",
              "         'investment': 1,\n",
              "         'firm': 1,\n",
              "         'group': 1,\n",
              "         '\\\\which': 1,\n",
              "         'has': 2,\n",
              "         'a': 1,\n",
              "         'reputation': 1,\n",
              "         'for': 2,\n",
              "         'making': 1,\n",
              "         'well-timed': 1,\n",
              "         'and': 3,\n",
              "         'occasionally\\\\controversial': 1,\n",
              "         'plays': 1,\n",
              "         'in': 1,\n",
              "         'defense': 1,\n",
              "         'industry': 1,\n",
              "         'quietly': 1,\n",
              "         'placed\\\\its': 1,\n",
              "         'bets': 1,\n",
              "         'on': 1,\n",
              "         'another': 1,\n",
              "         'part': 1,\n",
              "         'market': 2,\n",
              "         'oil': 1,\n",
              "         'economy': 2,\n",
              "         'cloud': 1,\n",
              "         'stocks': 1,\n",
              "         'outlook': 2,\n",
              "         'soaring': 1,\n",
              "         'crude': 1,\n",
              "         'prices': 1,\n",
              "         'plus': 1,\n",
              "         'worries\\\\about': 1,\n",
              "         'earnings': 1,\n",
              "         'expected': 1,\n",
              "         'to\\\\hang': 1,\n",
              "         'over': 1,\n",
              "         'stock': 1,\n",
              "         'next': 1,\n",
              "         'week': 1,\n",
              "         'during': 1,\n",
              "         'depth': 1,\n",
              "         'the\\\\summer': 1,\n",
              "         'doldrums': 1})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# counter just counts how many times its seen something.\n",
        "\n",
        "# 1) Give first tokenized str\n",
        "# counter = collections.Counter(ts[0])\n",
        "# counter\n",
        "\n",
        "# 2) Init default and update it with tokenized str\n",
        "# counter = collections.Counter()\n",
        "# counter.update(ts[0])\n",
        "# counter\n",
        "\n",
        "# 3) Use whole ds with it (part of it here)\n",
        "# counter = collections.Counter()\n",
        "# for i, x in zip(range(3), train):\n",
        "#   counter.update(tk(x[1]))\n",
        "# counter\n",
        "\n",
        "# 4) The 3rd option used train directly, can also use the tokenized sentences in the list \"ts\".\n",
        "counter = collections.Counter()\n",
        "for sent in ts:\n",
        "  counter.update(sent)\n",
        "counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9iglw_AtTs8",
        "outputId": "177a18c2-20a9-4ad9-d17d-e577a9aa51f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab()\n",
            "<torchtext._torchtext.Vocab object at 0x78ca2b9a33b0>\n",
            "75\n"
          ]
        }
      ],
      "source": [
        "# vocab is a dictionary\n",
        "v = torchtext.vocab.vocab(counter, min_freq=1)\n",
        "\n",
        "print(v)\n",
        "print(v.vocab)\n",
        "print(len(v.vocab))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qx5m2x4HxVzU",
        "outputId": "79be32ad-5207-40a3-dbe2-f8d85b14b799"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'depth': 72,\n",
              " 'during': 71,\n",
              " 'next': 69,\n",
              " 'over': 67,\n",
              " 'to\\\\hang': 66,\n",
              " 'earnings': 64,\n",
              " 'worries\\\\about': 63,\n",
              " 'prices': 61,\n",
              " 'crude': 60,\n",
              " 'dwindling\\\\band': 18,\n",
              " 'green': 23,\n",
              " 'group': 33,\n",
              " 'has': 35,\n",
              " 'private': 30,\n",
              " 'of': 19,\n",
              " 'carlyle': 25,\n",
              " 'looks': 26,\n",
              " ',': 14,\n",
              " 'street': 15,\n",
              " 'plus': 62,\n",
              " 'black': 8,\n",
              " 'toward': 27,\n",
              " 'bears': 3,\n",
              " 'the\\\\summer': 73,\n",
              " 'week': 70,\n",
              " 'reuters': 10,\n",
              " 'again': 24,\n",
              " ')': 11,\n",
              " '.': 2,\n",
              " '\\\\which': 34,\n",
              " 'st': 1,\n",
              " 'market': 53,\n",
              " 'the': 7,\n",
              " 'in': 44,\n",
              " 'expected': 65,\n",
              " '(': 9,\n",
              " 'are': 21,\n",
              " 'part': 52,\n",
              " \"'\": 16,\n",
              " 'claw': 4,\n",
              " 'into': 6,\n",
              " 'short-sellers': 13,\n",
              " '-': 12,\n",
              " 'aerospace': 29,\n",
              " 'commercial': 28,\n",
              " 'investment': 31,\n",
              " 'firm': 32,\n",
              " 'seeing': 22,\n",
              " 'making': 39,\n",
              " 'for': 38,\n",
              " 'another': 51,\n",
              " 'cloud': 56,\n",
              " 'back': 5,\n",
              " 'outlook': 58,\n",
              " 'a': 36,\n",
              " 'on': 50,\n",
              " 'reputation': 37,\n",
              " 's': 17,\n",
              " 'well-timed': 40,\n",
              " 'and': 41,\n",
              " 'wall': 0,\n",
              " 'industry': 46,\n",
              " 'soaring': 59,\n",
              " 'stocks': 57,\n",
              " 'occasionally\\\\controversial': 42,\n",
              " 'stock': 68,\n",
              " 'bets': 49,\n",
              " 'doldrums': 74,\n",
              " 'ultra-cynics': 20,\n",
              " 'plays': 43,\n",
              " 'defense': 45,\n",
              " 'quietly': 47,\n",
              " 'placed\\\\its': 48,\n",
              " 'oil': 54,\n",
              " 'economy': 55}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Returns dictionary of word/assigned number in key/value pairs.\n",
        "v.get_stoi()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEaVpFs7v9vK",
        "outputId": "316d8d11-153b-41e4-fc96-c866b8f14461"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['wall', 'st', '.', 'bears', 'claw', 'back', 'into', 'the', 'black', '(']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "#  Returns list of all words. showing first 10\n",
        "v.get_itos()[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USywxXp5umdD",
        "outputId": "9ab2772f-4d85-404a-b60e-db8824fcf6a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numerical value in dictionary: 0. Assigned word: wall\n",
            "Numerical value in dictionary: 1. Assigned word: st\n",
            "Numerical value in dictionary: 2. Assigned word: .\n",
            "Numerical value in dictionary: 3. Assigned word: bears\n",
            "Numerical value in dictionary: 4. Assigned word: claw\n"
          ]
        }
      ],
      "source": [
        "# zip is cool.\n",
        "for i, x in zip(range(5), v.get_itos()):\n",
        "  print(f'Numerical value in dictionary: {i}. Assigned word: {x}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VczjKh7sxvuP",
        "outputId": "a4ea111c-04fc-4b99-e16a-0e1f65dea249"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example sentence:\n",
            "['wall', 'st', '.', 'bears', 'claw', 'back', 'into', 'the', 'black', '(', 'reuters', ')', 'reuters', '-', 'short-sellers', ',', 'wall', 'street', \"'\", 's', 'dwindling\\\\band', 'of', 'ultra-cynics', ',', 'are', 'seeing', 'green', 'again', '.']\n",
            "\n",
            "Numerical version of same sentence:\n",
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 10, 12, 13, 14, 0, 15, 16, 17, 18, 19, 20, 14, 21, 22, 23, 24, 2]\n"
          ]
        }
      ],
      "source": [
        "''' Convert sentence into nums. es = example sentence. Get the tokenized sentence.\n",
        "    Loop through it, get_stoi() remember returns dictionary of str/num key/value pairs.\n",
        "    So give it str (or token) to get num back. '''\n",
        "es = ts[0]\n",
        "\n",
        "numerical_sentence = [v.get_stoi()[cur_token] for cur_token in es]\n",
        "\n",
        "print(f'Example sentence:\\n{es}\\n\\nNumerical version of same sentence:\\n{numerical_sentence}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42c2T59l03-K",
        "outputId": "560be01d-5089-4762-de4a-a6294741554a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[[0, 'wall'],\n",
              "  [1, 'st'],\n",
              "  [2, '.'],\n",
              "  [3, 'bears'],\n",
              "  [4, 'claw'],\n",
              "  [5, 'back'],\n",
              "  [6, 'into'],\n",
              "  [7, 'the'],\n",
              "  [8, 'black'],\n",
              "  [9, '('],\n",
              "  [10, 'reuters'],\n",
              "  [11, ')'],\n",
              "  [10, 'reuters'],\n",
              "  [12, '-'],\n",
              "  [13, 'short-sellers'],\n",
              "  [14, ','],\n",
              "  [0, 'wall'],\n",
              "  [15, 'street'],\n",
              "  [16, \"'\"],\n",
              "  [17, 's'],\n",
              "  [18, 'dwindling\\\\band'],\n",
              "  [19, 'of'],\n",
              "  [20, 'ultra-cynics'],\n",
              "  [14, ','],\n",
              "  [21, 'are'],\n",
              "  [22, 'seeing'],\n",
              "  [23, 'green'],\n",
              "  [24, 'again'],\n",
              "  [2, '.']],\n",
              " [[25, 'carlyle'],\n",
              "  [26, 'looks'],\n",
              "  [27, 'toward'],\n",
              "  [28, 'commercial'],\n",
              "  [29, 'aerospace'],\n",
              "  [9, '('],\n",
              "  [10, 'reuters'],\n",
              "  [11, ')'],\n",
              "  [10, 'reuters'],\n",
              "  [12, '-'],\n",
              "  [30, 'private'],\n",
              "  [31, 'investment'],\n",
              "  [32, 'firm'],\n",
              "  [25, 'carlyle'],\n",
              "  [33, 'group'],\n",
              "  [14, ','],\n",
              "  [34, '\\\\which'],\n",
              "  [35, 'has'],\n",
              "  [36, 'a'],\n",
              "  [37, 'reputation'],\n",
              "  [38, 'for'],\n",
              "  [39, 'making'],\n",
              "  [40, 'well-timed'],\n",
              "  [41, 'and'],\n",
              "  [42, 'occasionally\\\\controversial'],\n",
              "  [43, 'plays'],\n",
              "  [44, 'in'],\n",
              "  [7, 'the'],\n",
              "  [45, 'defense'],\n",
              "  [46, 'industry'],\n",
              "  [14, ','],\n",
              "  [35, 'has'],\n",
              "  [47, 'quietly'],\n",
              "  [48, 'placed\\\\its'],\n",
              "  [49, 'bets'],\n",
              "  [50, 'on'],\n",
              "  [51, 'another'],\n",
              "  [52, 'part'],\n",
              "  [19, 'of'],\n",
              "  [7, 'the'],\n",
              "  [53, 'market'],\n",
              "  [2, '.']],\n",
              " [[54, 'oil'],\n",
              "  [41, 'and'],\n",
              "  [55, 'economy'],\n",
              "  [56, 'cloud'],\n",
              "  [57, 'stocks'],\n",
              "  [16, \"'\"],\n",
              "  [58, 'outlook'],\n",
              "  [9, '('],\n",
              "  [10, 'reuters'],\n",
              "  [11, ')'],\n",
              "  [10, 'reuters'],\n",
              "  [12, '-'],\n",
              "  [59, 'soaring'],\n",
              "  [60, 'crude'],\n",
              "  [61, 'prices'],\n",
              "  [62, 'plus'],\n",
              "  [63, 'worries\\\\about'],\n",
              "  [7, 'the'],\n",
              "  [55, 'economy'],\n",
              "  [41, 'and'],\n",
              "  [7, 'the'],\n",
              "  [58, 'outlook'],\n",
              "  [38, 'for'],\n",
              "  [64, 'earnings'],\n",
              "  [21, 'are'],\n",
              "  [65, 'expected'],\n",
              "  [66, 'to\\\\hang'],\n",
              "  [67, 'over'],\n",
              "  [7, 'the'],\n",
              "  [68, 'stock'],\n",
              "  [53, 'market'],\n",
              "  [69, 'next'],\n",
              "  [70, 'week'],\n",
              "  [71, 'during'],\n",
              "  [7, 'the'],\n",
              "  [72, 'depth'],\n",
              "  [19, 'of'],\n",
              "  [73, 'the\\\\summer'],\n",
              "  [74, 'doldrums'],\n",
              "  [2, '.']]]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Create lists with tokens and their numerical conversions.\n",
        "pairs = []\n",
        "for cur_sent in ts:\n",
        "  pairs.append([list((v.get_stoi()[cur_token], cur_token)) for cur_token in cur_sent])\n",
        "pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "B92rWUj61iqI",
        "outputId": "a9b21711-d7f5-4139-8ba3-b28d7d516c65"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'are'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "v.get_itos()[21]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7b-Ug0oa4ZTG",
        "outputId": "3a39b307-5649-4a3f-dfcf-3c1402d8d111"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example str:\n",
            "['wall', 'st', '.', 'bears', 'claw', 'back', 'into', 'the', 'black', '(', 'reuters', ')', 'reuters', '-', 'short-sellers', ',', 'wall', 'street', \"'\", 's', 'dwindling\\\\band', 'of', 'ultra-cynics', ',', 'are', 'seeing', 'green', 'again', '.']\n",
            "\n",
            "Encoded str:\n",
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 10, 12, 13, 14, 0, 15, 16, 17, 18, 19, 20, 14, 21, 22, 23, 24, 2]\n",
            "\n",
            "\n",
            "Decoded str:\n",
            "['wall', 'st', '.', 'bears', 'claw', 'back', 'into', 'the', 'black', '(', 'reuters', ')', 'reuters', '-', 'short-sellers', ',', 'wall', 'street', \"'\", 's', 'dwindling\\\\band', 'of', 'ultra-cynics', ',', 'are', 'seeing', 'green', 'again', '.']\n"
          ]
        }
      ],
      "source": [
        "def encode(str_to_encode):\n",
        "  return [v.get_stoi()[token] for token in str_to_encode]\n",
        "\n",
        "''' get_itos works for decoding because the vocab object already assigned numbers\n",
        "    to words. So as of right now, v.get_stoi()[0] gets the word in the dictionary\n",
        "    with assigned num 0. '''\n",
        "def decode(nums_to_decode):\n",
        "  return [v.get_itos()[num] for num in nums_to_decode]\n",
        "\n",
        "# es = example str declared in earlier cell. already tokenized.\n",
        "encoded_str = encode(es)\n",
        "print(f'Example str:\\n{es}\\n\\nEncoded str:\\n{encoded_str}\\n\\n')\n",
        "\n",
        "decoded_str = decode(encoded_str)\n",
        "print(f'Decoded str:\\n{decoded_str}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjFiSV8U2twx"
      },
      "source": [
        "# 3) N grams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_kIhGd72tBi",
        "outputId": "5909e297-8f54-4edf-aac1-c56e8fd65b8a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'wall': 2,\n",
              "         'st': 1,\n",
              "         '.': 2,\n",
              "         'bears': 1,\n",
              "         'claw': 1,\n",
              "         'back': 1,\n",
              "         'into': 1,\n",
              "         'the': 1,\n",
              "         'black': 1,\n",
              "         '(': 1,\n",
              "         'reuters': 2,\n",
              "         ')': 1,\n",
              "         '-': 1,\n",
              "         'short-sellers': 1,\n",
              "         ',': 2,\n",
              "         'street': 1,\n",
              "         \"'\": 1,\n",
              "         's': 1,\n",
              "         'dwindling\\\\band': 1,\n",
              "         'of': 1,\n",
              "         'ultra-cynics': 1,\n",
              "         'are': 1,\n",
              "         'seeing': 1,\n",
              "         'green': 1,\n",
              "         'again': 1,\n",
              "         'wall st': 1,\n",
              "         'st .': 1,\n",
              "         '. bears': 1,\n",
              "         'bears claw': 1,\n",
              "         'claw back': 1,\n",
              "         'back into': 1,\n",
              "         'into the': 1,\n",
              "         'the black': 1,\n",
              "         'black (': 1,\n",
              "         '( reuters': 1,\n",
              "         'reuters )': 1,\n",
              "         ') reuters': 1,\n",
              "         'reuters -': 1,\n",
              "         '- short-sellers': 1,\n",
              "         'short-sellers ,': 1,\n",
              "         ', wall': 1,\n",
              "         'wall street': 1,\n",
              "         \"street '\": 1,\n",
              "         \"' s\": 1,\n",
              "         's dwindling\\\\band': 1,\n",
              "         'dwindling\\\\band of': 1,\n",
              "         'of ultra-cynics': 1,\n",
              "         'ultra-cynics ,': 1,\n",
              "         ', are': 1,\n",
              "         'are seeing': 1,\n",
              "         'seeing green': 1,\n",
              "         'green again': 1,\n",
              "         'again .': 1})"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "from torchtext.data.utils import ngrams_iterator\n",
        "\n",
        "''' Ngrams will help solve multiword expression issues like \"hamburger\" because \"ham\" and\n",
        "    \"burger\" can be 2 separate words. Can't always represent both of those words with the same\n",
        "    vector. The update func gets pairs because ngrams=2. If the goal was to be able to understand\n",
        "    3 sets of words, ngrams will be 3. Downside is this WILL example the counter object\n",
        "    by a lot. Specifically len(v) * 2/3/etc. '''\n",
        "\n",
        "# nc = ngrams counter\n",
        "nc = collections.Counter()\n",
        "nc.update(ngrams_iterator(es, ngrams=2))\n",
        "nc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Rvc8GDQ5x9g",
        "outputId": "6987540c-693e-4af0-c8f1-4fc7e5c2ca61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wall\n",
            "st\n",
            ".\n"
          ]
        }
      ],
      "source": [
        "for i, a in zip(range(3), nc):\n",
        "  print(a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTYBptfA6bbZ"
      },
      "source": [
        "# 4) Bag of words (bow) & padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GehUiJzi6ak1",
        "outputId": "22438516-9918-4d85-aaa2-c99392924491"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 10, 12, 13, 14, 0, 15, 16, 17, 18, 19, 20, 14, 21, 22, 23, 24, 2]\n",
            "[25, 26, 27, 28, 29, 9, 10, 11, 10, 12, 30, 31, 32, 25, 33, 14, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 7, 45, 46, 14, 35, 47, 48, 49, 50, 51, 52, 19, 7, 53, 2]\n",
            "[54, 41, 55, 56, 57, 16, 58, 9, 10, 11, 10, 12, 59, 60, 61, 62, 63, 7, 55, 41, 7, 58, 38, 64, 21, 65, 66, 67, 7, 68, 53, 69, 70, 71, 7, 72, 19, 73, 74, 2]\n"
          ]
        }
      ],
      "source": [
        "# A bow is simply seeing how many times a word occurs. Get the first 3 sentences num representations here\n",
        "num_sents = [encode(tk(a[1])) for i, a in zip(range(3), train)]\n",
        "\n",
        "for x in num_sents:\n",
        "  print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKSxj--U7zYE",
        "outputId": "5ffbedec-13b7-4909-9e7c-857907bdee0c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2., 1., 2., 1., 1., 1., 1., 1., 1., 1., 2., 1., 1., 1., 2., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# Get tensor of length of vocab. With first 3 sentences in ag_news USED for vocab, this will be 75.\n",
        "a = t.zeros(len(v))\n",
        "\n",
        "# Loop over first num sentence seen in previous cell.\n",
        "for num in num_sents[0]:\n",
        "  ''' Ex: v.get_stoi() has \"wall\" paired with num 0. this will increase index 0 by 1. Keep in mind,\n",
        "      we can access index 0 in this \"a\" tensor, and give that index to v.get_stoi()[] and it'll\n",
        "      return the proper word '''\n",
        "  a[num] = a[num] + 1\n",
        "\n",
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIfR9IwwAVl7",
        "outputId": "652a310e-6263-4161-e14e-72dfce11468b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 10, 12, 13, 14,  0, 15,\n",
            "        16, 17, 18, 19, 20, 14, 21, 22, 23, 24,  2,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0]), tensor([25, 26, 27, 28, 29,  9, 10, 11, 10, 12, 30, 31, 32, 25, 33, 14, 34, 35,\n",
            "        36, 37, 38, 39, 40, 41, 42, 43, 44,  7, 45, 46, 14, 35, 47, 48, 49, 50,\n",
            "        51, 52, 19,  7, 53,  2]), tensor([54, 41, 55, 56, 57, 16, 58,  9, 10, 11, 10, 12, 59, 60, 61, 62, 63,  7,\n",
            "        55, 41,  7, 58, 38, 64, 21, 65, 66, 67,  7, 68, 53, 69, 70, 71,  7, 72,\n",
            "        19, 73, 74,  2,  0,  0])]\n",
            "42\n",
            "42\n",
            "42\n"
          ]
        }
      ],
      "source": [
        "''' num_sents aren't the same size which is required for models like embedding, so padding will be\n",
        "    demonstrated. map wil take the len func and apply it to every num sentence and list will get\n",
        "    all the lengths. Then max just gets the biggest one. Quick and easy. '''\n",
        "max_length = max(list(map(len, num_sents)))\n",
        "\n",
        "''' Convert sent to tensor first, and 0, max length - len of current sentence just makes sure we get\n",
        "    the CORRECT amount of 0s. '''\n",
        "padded_num_sents = [t.nn.functional.pad(t.tensor(sent), (0, max_length - len(sent))) for sent in num_sents]\n",
        "\n",
        "print(padded_num_sents)\n",
        "\n",
        "for x in padded_num_sents:\n",
        "  print(len(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjYnc216CeMA"
      },
      "source": [
        "# 5) Dataset & Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfgkIesPCiHQ",
        "outputId": "4e7f284d-a222-4aa1-877c-8f67553ea896"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0])\n",
            "tensor([2])\n",
            "tensor([4])\n",
            "tensor([6])\n",
            "tensor([8])\n",
            "tensor([10])\n",
            "tensor([12])\n",
            "tensor([14])\n",
            "tensor([16])\n",
            "tensor([18])\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "''' Datasets are good because they can potentially load data only when necessary instead of all at once\n",
        "    like with image processing tasks. Also a way to keep things organized. Must override len and getitem. '''\n",
        "class TestDataset(Dataset):\n",
        "  def __init__(self, data_to_use):\n",
        "    self.data = data_to_use\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.data[index]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "# The collate_fn arg in DataLoader which extra things to the dataset before it's saved in data loader.\n",
        "def sub(num):\n",
        "  return t.tensor([cur_tensor_num.item() - 1 for cur_tensor_num in num])\n",
        "\n",
        "# Get some generic data. \"tensor([ 0,  2,  4,  6,  8, 10, 12, 14, 16, 18])\"\n",
        "x = t.tensor([x * 2 for x in range(10)])\n",
        "tds = TestDataset(x)\n",
        "\n",
        "\n",
        "''' tdl = test data loader (dl) Very efficient way of loading data. Also when using the collate_fn arg, it\n",
        "    seems like the DataLoader GIVES the data to whatever func as a list. Strange.\n",
        "    Uncomment/comment whichever below DataLoader to see results.  '''\n",
        "# tdl = DataLoader(tds, 1, shuffle=False, collate_fn=sub)\n",
        "tdl = DataLoader(tds, 1, shuffle=False)\n",
        "\n",
        "for x in tdl:\n",
        "  print(x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ntd = new test dataset\n",
        "ntd = TestDataset([5,4,3,2])\n",
        "\n",
        "# ndl = new data loader\n",
        "ndl = DataLoader(ntd, batch_size=2)\n",
        "\n",
        "# Gets 2 because of batch size\n",
        "print(len(ndl))\n",
        "\n",
        "# Gets 4 in total. can also do len(dl.dataset)\n",
        "print(len(ndl.dataset.data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4DFyQyTcFap",
        "outputId": "b43972c4-20b2-4349-95d9-155fe107f43e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jo4vd58bHIlR"
      },
      "source": [
        "# 6) Neural Network related topics (Including Models built)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPebsROfHL22",
        "outputId": "e65d26f3-60cf-4695-c73a-a1e6236902ea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=75, out_features=3, bias=True)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "# Seeing inputs of a linear layer and what it'll output.\n",
        "t.nn.Linear(len(v), 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DN7bmhUXIknl",
        "outputId": "5aae62ed-d542-4abb-bd9d-725e68ad47c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2., 8., 9.],\n",
            "        [5., 1., 3.],\n",
            "        [4., 8., 7.]], dtype=torch.float64)\n",
            "tensor([[-7.3139, -1.3139, -0.3139],\n",
            "        [-0.1429, -4.1429, -2.1429],\n",
            "        [-4.3266, -0.3266, -1.3266]], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "x = t.tensor([[2,8,9],\n",
        "              [5,1,3],\n",
        "              [4,8,7]], dtype=t.float64)\n",
        "\n",
        "''' ??? 1 is likely vertical (row by row) and 0 horizontal (column by column). ??? Softmax\n",
        "    converts things to probabilities, so log softmax does the same but with log applied.\n",
        "    Also logsoftmax is for classification\n",
        "    https://www.baeldung.com/cs/softmax-vs-log-softmax '''\n",
        "ls = t.nn.LogSoftmax(dim=1)\n",
        "\n",
        "print(x)\n",
        "print(ls(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqTidUl_LQwB",
        "outputId": "6355faa5-8168-419b-8655-7c09c31ea20b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=75, out_features=3, bias=True)\n",
              "  (1): LogSoftmax(dim=1)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "# Sequential is just layers in an order.\n",
        "network = t.nn.Sequential(t.nn.Linear(len(v), 3),\n",
        "                          t.nn.LogSoftmax(dim=1))\n",
        "\n",
        "network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9crrNFOLycX",
        "outputId": "df0a7371-e348-4a37-c95b-aac1ae0546d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input for model:\n",
            "tensor([  0.,   2.,   4.,   6.,   8.,  10.,  12.,  14.,  16.,  18.,  20.,  22.,\n",
            "         24.,  26.,  28.,  30.,  32.,  34.,  36.,  38.,  40.,  42.,  44.,  46.,\n",
            "         48.,  50.,  52.,  54.,  56.,  58.,  60.,  62.,  64.,  66.,  68.,  70.,\n",
            "         72.,  74.,  76.,  78.,  80.,  82.,  84.,  86.,  88.,  90.,  92.,  94.,\n",
            "         96.,  98., 100., 102., 104., 106., 108., 110., 112., 114., 116., 118.,\n",
            "        120., 122., 124., 126., 128., 130., 132., 134., 136., 138., 140., 142.,\n",
            "        144., 146., 148.])\n",
            "\n",
            "Type: torch.float32\n",
            "\n",
            "NEW input for model:\n",
            "tensor([[  0.,   2.,   4.,   6.,   8.,  10.,  12.,  14.,  16.,  18.,  20.,  22.,\n",
            "          24.,  26.,  28.,  30.,  32.,  34.,  36.,  38.,  40.,  42.,  44.,  46.,\n",
            "          48.,  50.,  52.,  54.,  56.,  58.,  60.,  62.,  64.,  66.,  68.,  70.,\n",
            "          72.,  74.,  76.,  78.,  80.,  82.,  84.,  86.,  88.,  90.,  92.,  94.,\n",
            "          96.,  98., 100., 102., 104., 106., 108., 110., 112., 114., 116., 118.,\n",
            "         120., 122., 124., 126., 128., 130., 132., 134., 136., 138., 140., 142.,\n",
            "         144., 146., 148.]])\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  0.0000, -32.3327, -97.6060]], grad_fn=<LogSoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "''' len(v) because model input is equal to vocab length.\n",
        "    1) \"TypeError: linear(): argument 'input' (position 1) must be Tensor, not list\"\n",
        "          I converted it to a tensor because of this.\n",
        "\n",
        "    2) \"RuntimeError: mat1 and mat2 must have the same dtype, but got Long and Float\"\n",
        "          I checked the input_test dtype and it was torch.int64. Apparently that\n",
        "          qualifies as a long? A QUICK fix would be to change the input_test tensor\n",
        "          to dtype=t.float32, but I also wanted to check models input.\n",
        "\n",
        "          2.2) Checking model input.\n",
        "                Help from link:\n",
        "                https://discuss.pytorch.org/t/get-appropriate-model-in-output-type-programmatically/53742\n",
        "\n",
        "                Doing:\n",
        "                \"z = t.nn.Linear(len(v), 3)\n",
        "                list(z.parameters())\" returns a list of tensors. First tensor is 2d\n",
        "                because it has 3 inner tensors of 75 values, the vocab size.\n",
        "\n",
        "                Ex:\n",
        "                \"tensor([[-0.0353, -0.0916,  0.0258,  0.0546, -0.0598,  0.0273, -0.0447, -0.0129,\n",
        "                           0.0199, -0.0067,  0.0418,  0.1102, -0.0363, -0.0615, -0.1136,  0.0627],\n",
        "\n",
        "                          [0.0922, -0.0013, -0.0645, -0.0640, -0.0426,  0.0972,  0.0951, -0.0859,\n",
        "                            0.0891,  0.1113, -0.0431, -0.0607,  0.0699, -0.0706,  0.0240, -0.0716],\n",
        "\n",
        "                          [-0.0369,  0.0732,  0.0284, -0.0249,  0.0937, -0.0938,  0.0555,  0.0908,\n",
        "                           -0.0923, -0.0790,  0.0530,  0.0607,  0.1147,  0.0963, -0.0195, -0.1021]]\"\n",
        "\n",
        "                It's in 2d. Strange. I guess input must be in 2d as well.\n",
        "\n",
        "          But to the point of this section, which is 2, the error can be fixed by changing the\n",
        "          type of the input to dtype=t.float32.\n",
        "\n",
        "\n",
        "    3) \"IndexError: Dimension out of range (expected to be in range of [-1, 0], but got 1)\"\n",
        "          Then this one came up because I BELIEVE the input tensor was not 2d. I used\n",
        "          \"t.unsqueeze(input_test, dim=0)\" which ADDS a dimension horizontally so now its definitely\n",
        "          2d. Shape is \"torch.Size([1, 75])\"\n",
        "\n",
        "     '''\n",
        "input_test = t.tensor([i * 2 for i in range(len(v))], dtype=t.float32)\n",
        "# uit = updated input test\n",
        "uit = t.unsqueeze(input_test, dim=0)\n",
        "print(f'Input for model:\\n{input_test}\\n\\nType: {input_test.dtype}\\n\\nNEW input for model:\\n{uit}\\n\\n')\n",
        "\n",
        "# Show model result.\n",
        "network(uit)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1idStA3YWqJ3",
        "outputId": "abe9ed4f-6f3d-424d-e095-3c37dbf5feb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x shape: torch.Size([29])\n",
            "x BEFORE embedding:\n",
            "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 10, 12, 13, 14,  0, 15,\n",
            "        16, 17, 18, 19, 20, 14, 21, 22, 23, 24,  2])\n",
            "\n",
            "\n",
            "x shape: torch.Size([29, 5])\n",
            "x AFTER embedding is: tensor([[ 8.6002e-02,  1.3401e+00,  8.4724e-01, -1.6921e-01, -7.4903e-01],\n",
            "        [ 1.1128e+00, -1.0178e+00, -1.8242e-01,  1.9588e+00, -9.4974e-01],\n",
            "        [-9.0016e-01,  3.8660e-01,  1.5842e+00, -5.5649e-01, -1.4217e+00],\n",
            "        [-3.3141e-01, -1.5244e-01, -5.1314e-01, -2.0827e+00, -3.8774e-01],\n",
            "        [-1.3159e+00,  1.2744e+00, -1.4552e+00,  6.2983e-01,  2.1051e+00],\n",
            "        [ 9.5075e-01, -4.8679e-01,  8.6886e-01, -2.8780e-02, -6.3802e-01],\n",
            "        [-1.6090e+00,  1.3224e-01, -1.1635e+00, -4.7096e-01, -6.7253e-01],\n",
            "        [-3.4021e-01, -3.3820e-01, -2.0466e+00,  8.4488e-01, -7.6056e-01],\n",
            "        [ 1.3313e+00,  6.9714e-01, -3.5009e-01,  9.5036e-01,  9.4620e-01],\n",
            "        [ 1.3155e-01,  2.6122e-01, -1.5337e+00, -1.4152e-01,  1.7064e+00],\n",
            "        [-1.3386e+00, -2.4010e+00,  4.2881e-01, -8.3865e-02,  1.0764e+00],\n",
            "        [-7.7194e-01,  3.5359e-01,  5.4262e-01, -1.1803e+00, -7.3328e-01],\n",
            "        [-1.3386e+00, -2.4010e+00,  4.2881e-01, -8.3865e-02,  1.0764e+00],\n",
            "        [ 6.9010e-01, -1.2194e+00,  5.8862e-01,  5.1863e-02,  2.6335e-03],\n",
            "        [-8.1142e-01,  4.8847e-01, -6.2447e-01,  6.3462e-01,  6.2792e-01],\n",
            "        [-1.2313e+00,  5.9546e-01, -5.7416e-01, -7.8834e-01,  1.1150e+00],\n",
            "        [ 8.6002e-02,  1.3401e+00,  8.4724e-01, -1.6921e-01, -7.4903e-01],\n",
            "        [-1.6993e-01, -6.2311e-01, -9.8847e-01, -6.8425e-01, -1.9487e+00],\n",
            "        [-7.0963e-01, -4.5452e-01,  2.0555e+00, -1.1719e+00,  1.1541e+00],\n",
            "        [ 1.1939e+00, -3.7679e-01,  1.8725e+00,  3.3202e-01, -4.5785e-02],\n",
            "        [-9.7028e-01,  1.9013e+00, -1.5343e+00,  5.4722e-01, -9.8924e-03],\n",
            "        [ 1.7013e+00, -1.2038e-01,  4.2065e-01,  7.6216e-01, -1.1255e+00],\n",
            "        [-1.2719e+00,  2.8289e+00,  9.0842e-01, -2.1197e+00, -1.0652e+00],\n",
            "        [-1.2313e+00,  5.9546e-01, -5.7416e-01, -7.8834e-01,  1.1150e+00],\n",
            "        [ 5.5832e-01, -1.1171e-02,  2.5742e-01, -1.5225e+00, -6.0465e-01],\n",
            "        [ 1.7879e+00, -6.1236e-01,  1.5927e+00,  8.3189e-01, -4.9774e-01],\n",
            "        [ 1.2093e+00,  4.7495e-01, -3.2740e-01,  3.9301e-01,  1.1220e+00],\n",
            "        [-6.6650e-01, -3.4564e-01,  1.6734e-01,  1.7655e-01, -1.6036e-01],\n",
            "        [-9.0016e-01,  3.8660e-01,  1.5842e+00, -5.5649e-01, -1.4217e+00]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "\n",
            "\n",
            "x shape after t.mean: torch.Size([5])\n",
            "x after t.mean:\n",
            "tensor([-0.1748,  0.0861,  0.1078, -0.1547, -0.0653], grad_fn=<MeanBackward1>)\n",
            "\n",
            "\n",
            "Returned tensor x:\n",
            "tensor([ 0.2248,  0.2658, -0.0378], grad_fn=<ViewBackward0>)\n",
            "Returned tensor x shape: torch.Size([3])\n"
          ]
        }
      ],
      "source": [
        "''' Most basic model ever. Embedding takes in v size and outputs dimension size of whatever requested.\n",
        "    And that'll be input to the Linear layer of course.\n",
        "\n",
        "    Errors:\n",
        "    1) \"RuntimeError: Expected tensor for argument #1 'indices' to have one of the following scalar\n",
        "        types: Long, Int; but got torch.FloatTensor instead (while checking arguments for embedding)\"\n",
        "\n",
        "        Solution: \"uit = uit.type(t.long)\" type conversion\n",
        "\n",
        "\n",
        "    2) \"IndexError: index out of range in self\"\n",
        "\n",
        "        Understanding the error: https://rollbar.com/blog/how-to-handle-index-out-of-range-in-self-pytorch/#\n",
        "        The code at the beginning is simple and I made my own test code\n",
        "        \"r = t.nn.Embedding(10, 5)\n",
        "        m = t.tensor([9])\n",
        "        r(m)\"\n",
        "        The thing is, if the tensor value is 10, it breaks and gives same error. But if its 9 or less, it\n",
        "        works fine. Which tells me that the MAX range it'll accept is 10. Anything greater and it breaks.\n",
        "        Of course it indexes from 0. The above is just for a 1d dimensional tensor.\n",
        "\n",
        "        Solution: I was given numerical input to the model when the VOCAB didn't match it. The vocab\n",
        "          went to num 75. Yet I tried giving the model:\n",
        "          \"tensor([[  0.,   2.,   4.,   6.,   8.,  10.,  12.,  14.,  16.,  18.,  20.,  22.,\n",
        "                      24.,  26.,  28.,  30.,  32.,  34.,  36.,  38.,  40.,  42.,  44.,  46.,\n",
        "                      48.,  50.,  52.,  54.,  56.,  58.,  60.,  62.,  64.,  66.,  68.,  70.,\n",
        "                      72.,  74.,  76.,  78.,  80.,  82.,  84.,  86.,  88.,  90.,  92.,  94.,\n",
        "                      96.,  98., 100., 102., 104., 106., 108., 110., 112., 114., 116., 118.,\n",
        "                      120., 122., 124., 126., 128., 130., 132., 134., 136., 138., 140., 142.,\n",
        "                      144., 146., 148.]])\"\n",
        "          The aforementioned link helped me understand this with t.all(). Initially I thought\n",
        "          t.nn.Embedding(vocab size, etc) meant the LENGTH of the input tensor couldn't be bigger\n",
        "          than vocab size, but it was checking for INDIVIDUAL numbers instead. Example code below:\n",
        "\n",
        "          \" r = t.nn.Embedding(len(v), 5) # vocab len 75\n",
        "            m = t.tensor([9,4,2,4,1,4,5,8,3,6,5,2,3,2,4,6,2,4,6,5,5,5,55,31,2]) # Will pass!\n",
        "            # m = t.tensor([9,4,2,4,1,4,5,8,74,10,75]) # Will fail!\n",
        "            # m = t.tensor([9,4,2,4,1,4,5,8,74,10,74]) # Will pass!\n",
        "\n",
        "            # All literally checks ALL values in tensor.\n",
        "            if t.all(m >= 0):\n",
        "              print(f'Passed. Tensor is: {m.shape}')\n",
        "            if t.all(m < r.num_embeddings):\n",
        "              print(f'Passed. Tensor is: {m.shape}')\n",
        "            else:\n",
        "              print(f'!!! Failed. Tensor shape: {uit.shape} and num embeddings: {embedding.num_embeddings} !!!')\"\n",
        "\n",
        "\n",
        "\n",
        "    3) \"RuntimeError: mat1 and mat2 shapes cannot be multiplied (1x29 and 5x3)\"\n",
        "        Why did this happen? 1x29 is the size of the num input tenor which is:\n",
        "        \"tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 10, 12, 13, 14,  0, 15,\n",
        "                 16, 17, 18, 19, 20, 14, 21, 22, 23, 24,  2])\"\n",
        "         Real tokenized sentence of above numerical sentence is:\n",
        "            \"['wall', 'st', '.', 'bears', 'claw', 'back', 'into', 'the', 'black', '(',\n",
        "               'reuters', ')', 'reuters', '-', 'short-sellers', ',', 'wall', 'street', \"'\", 's',\n",
        "               'dwindling\\\\band', 'of', 'ultra-cynics', ',', 'are', 'seeing', 'green', 'again', '.']\"\n",
        "\n",
        "\n",
        "        Solution 1: I commented out:\n",
        "          \"# x = t.mean(x,dim=1)\n",
        "           # print(f'x shape after t.mean: {x.shape}\\nx after t.mean:\\n{x}')\"\n",
        "           And it worked perfectly. Why?\n",
        "\n",
        "           Answer: Because if input is:\n",
        "             \"tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 10, 12, 13, 14,  0, 15,\n",
        "                      16, 17, 18, 19, 20, 14, 21, 22, 23, 24,  2])\", that's length 29. If\n",
        "                      embedding dimension arg for model (which is the output of the embedding\n",
        "                      layer and input to the linear layer) is say, 5, then the embedding\n",
        "                      layer will output a 2d matrix of size 29,5 because there's 29 values in\n",
        "                      the original tensor so theres a nested tensor for each one. Remember the\n",
        "                      embedding dimension is INPUT to the linear layer, it has the same value\n",
        "                      of 5. Since the embedding layer output shape is 29,5 , it works.\n",
        "\n",
        "\n",
        "          Solution 2: I used t.mean(x,dim=0) which get the mean in a horizontal fashion. Why did\n",
        "            it work? BEFORE matrix x goes into the embedding layer, the tensor is:\n",
        "            \"tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 10, 12, 13, 14,  0, 15,\n",
        "                     16, 17, 18, 19, 20, 14, 21, 22, 23, 24,  2])\" More importantly the shape/size\n",
        "            is 29. AFTER the matrix x goes through the embedding layer, it's shape/size is (29,5).\n",
        "            It's now 2d. Why? Well because the output of the embedding layer (called embed_dim)\n",
        "            is 5. So it gets 29 matrices of length 5 each. Then the linear layers INPUT is embed_dim\n",
        "            as well which is of course 5. So the linear layer can take a 2d matrix as long as the\n",
        "            columns of the 2d matrix (the \"5\" in 29,5) matches the linear layers INPUT (input is\n",
        "            also 5).\n",
        "            Ex Code:\n",
        "            \"td = t.tensor([[1,4,2,8],\n",
        "                            [6,9,3,7]], dtype=t.float32)\n",
        "              x = t.nn.Linear(4, 1)\n",
        "              x(td)\"\n",
        "\n",
        "            Will print something like:\n",
        "            \"tensor([[2.5558],\n",
        "                     [4.6453]], grad_fn=<AddmmBackward0>)\"\n",
        "\n",
        "            Ex code 2 (1d):\n",
        "            \" # 1d linear layer test. Tensor is \"tensor([5., 5., 5.])\", shape is torch.Size([3])\n",
        "              e = t.tensor([5] * 3, dtype=t.float32)\n",
        "              x = t.nn.Linear(3, 1)\n",
        "              # Will print something like \"tensor([0.6625], grad_fn=<ViewBackward0>)\" is linear output is 1.\n",
        "              print(x(e))\"\n",
        "\n",
        "\n",
        "\n",
        "          Conclusion: Solving the issue WITHOUT messing with t.mean(x, dim=1) is impossible. Simply\n",
        "            because of the dimensions of both x (after it goes through t.mean) and the input of the\n",
        "            linear layer.\n",
        "            1) Dimension of x after t.mean(x, dim=1) - torch.Size([29])\n",
        "            2) Dimensions of linear layer - 5,3. 5 input, 3 output.\n",
        "\n",
        "            I initially THOUGHT the REAL size was 30, due to programming indexing from 0. If that\n",
        "            was the case I had an idea to resize the x matrix into shape (6,5) because that'll be\n",
        "            accepted by the linear linear and it'd work. As a matter of fact I wrote some test\n",
        "            code for just that issue, resizing a tensor that was initially 30 in length but the\n",
        "            wrong input size for a linear layer that had input as 5. See code below:\n",
        "            \"\n",
        "              # Get same values.\n",
        "              t.manual_seed(0)\n",
        "\n",
        "              # nt = new tensor. Make tensor of size 30, (0-29)\n",
        "              nt = t.rand(30)\n",
        "              print(f'New tensor:\\n{nt}\\nNew tensor SIZE: {nt.shape}\\n\\n')\n",
        "\n",
        "              # Create a linear layer which only takes 1d tensors of 5, and 2d tensors of (n, 5).\n",
        "              ll = t.nn.Linear(5, 1)\n",
        "\n",
        "              # Try reshaping the new tensor to be in form (n, 5). First get size and check if its divisible by embed_dim (ed) 5\n",
        "              ed = 5\n",
        "              cur_mat_size = nt.size()[0]\n",
        "\n",
        "              # Can 30 be divided by 5? If so, we can make a new tensor evenly.\n",
        "              if cur_mat_size % ed == 0:\n",
        "                rows_for_reshape = int(cur_mat_size / ed)\n",
        "\n",
        "                # nm = new matrix.\n",
        "                nm = t.reshape(nt, (rows_for_reshape, ed))\n",
        "                print(f'New reshaped matrix is:\\n{nm}\\nNew reshaped matrix shape: {nm.shape}\\n\\n')\n",
        "\n",
        "                print(ll(nm))\n",
        "            \"\n",
        "\n",
        "            Feel free to copy and past in a different cell. The point of the code was to demonstrate how\n",
        "            it would be POSSIBLE to reshape a tensor so it can be passed to a linear layer, which I initially\n",
        "            thought was possible with the tensor([ 0,  1,  2,  3,  4,  5,  6,  7, etc]) input tensor used\n",
        "            below. But I remembered it was size 29 and not 30. '''\n",
        "\n",
        "class EmbedClassifier(t.nn.Module):\n",
        "  def __init__(self, vocab_size, embed_dim, num_class):\n",
        "    super().__init__()\n",
        "    self.embedding = t.nn.Embedding(num_embeddings=vocab_size, embedding_dim=embed_dim)\n",
        "    self.fc = t.nn.Linear(embed_dim, num_class)\n",
        "\n",
        "  def forward(self, x):\n",
        "    print(f'x shape: {x.shape}\\nx BEFORE embedding:\\n{x}\\n\\n')\n",
        "    x = self.embedding(x)\n",
        "    print(f'x shape: {x.shape}\\nx AFTER embedding is: {x}\\n\\n')\n",
        "    x = t.mean(x,dim=0)\n",
        "    print(f'x shape after t.mean: {x.shape}\\nx after t.mean:\\n{x}\\n\\n')\n",
        "\n",
        "    return self.fc(x)\n",
        "\n",
        "ec = EmbedClassifier(len(v), 5, 3)\n",
        "\n",
        "''' Tokenized text is:\n",
        "    \"['wall', 'st', '.', 'bears', 'claw', 'back', 'into', 'the', 'black', '(',\n",
        "      'reuters', ')', 'reuters', '-', 'short-sellers', ',', 'wall', 'street',\n",
        "      \"'\", 's', 'dwindling\\\\band', 'of', 'ultra-cynics', ',', 'are', 'seeing',\n",
        "      'green', 'again', '.']\n",
        "\n",
        "    Must get appropriate input for the model. Length is 29. Actual tensor is:\n",
        "    \"tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 10, 12, 13, 14,  0, 15,\n",
        "              16, 17, 18, 19, 20, 14, 21, 22, 23, 24,  2])\"  '''\n",
        "t_test = t.tensor([v.get_stoi()[cur_token] for cur_token in es], dtype=t.long)\n",
        "\n",
        "x = ec(t_test)\n",
        "print(f'Returned tensor x:\\n{x}\\nReturned tensor x shape: {x.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' This code documents why solving the 3rd error: \"RuntimeError: mat1 and mat2 shapes cannot\n",
        "    be multiplied (1x29 and 5x3)\" in the above cell, was impossible. '''\n",
        "\n",
        "# Get same values.\n",
        "t.manual_seed(0)\n",
        "\n",
        "# nt = new tensor. Make tensor of size 30, (0-29)\n",
        "nt = t.rand(30)\n",
        "print(f'New tensor:\\n{nt}\\nNew tensor SIZE: {nt.shape}\\n\\n')\n",
        "\n",
        "# Create a linear layer which only takes 1d tensors of 5, and 2d tensors of (n, 5).\n",
        "ll = t.nn.Linear(5, 1)\n",
        "\n",
        "# Try reshaping the new tensor to be in form (n, 5). First get size and check if its divisible by embed_dim (ed) 5\n",
        "ed = 5\n",
        "cur_mat_size = nt.size()[0]\n",
        "\n",
        "# Can 30 be divided by 5? If so, we can make a new tensor evenly.\n",
        "if cur_mat_size % ed == 0:\n",
        "  rows_for_reshape = int(cur_mat_size / ed)\n",
        "\n",
        "  # nm = new matrix.\n",
        "  nm = t.reshape(nt, (rows_for_reshape, ed))\n",
        "  print(f'New reshaped matrix is:\\n{nm}\\nNew reshaped matrix shape: {nm.shape}\\n\\n')\n",
        "\n",
        "  print(ll(nm))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiWS4I5YhLyc",
        "outputId": "d6f38cb2-407c-4044-8492-cecf67e4ef30"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New tensor:\n",
            "tensor([0.4963, 0.7682, 0.0885, 0.1320, 0.3074, 0.6341, 0.4901, 0.8964, 0.4556,\n",
            "        0.6323, 0.3489, 0.4017, 0.0223, 0.1689, 0.2939, 0.5185, 0.6977, 0.8000,\n",
            "        0.1610, 0.2823, 0.6816, 0.9152, 0.3971, 0.8742, 0.4194, 0.5529, 0.9527,\n",
            "        0.0362, 0.1852, 0.3734])\n",
            "New tensor SIZE: torch.Size([30])\n",
            "\n",
            "\n",
            "New reshaped matrix is:\n",
            "tensor([[0.4963, 0.7682, 0.0885, 0.1320, 0.3074],\n",
            "        [0.6341, 0.4901, 0.8964, 0.4556, 0.6323],\n",
            "        [0.3489, 0.4017, 0.0223, 0.1689, 0.2939],\n",
            "        [0.5185, 0.6977, 0.8000, 0.1610, 0.2823],\n",
            "        [0.6816, 0.9152, 0.3971, 0.8742, 0.4194],\n",
            "        [0.5529, 0.9527, 0.0362, 0.1852, 0.3734]])\n",
            "New reshaped matrix shape: torch.Size([6, 5])\n",
            "\n",
            "\n",
            "tensor([[-0.3574],\n",
            "        [-0.8912],\n",
            "        [-0.4575],\n",
            "        [-0.5929],\n",
            "        [-0.6101],\n",
            "        [-0.3124]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.2) Updating embedding weights, using Gensim, model creation, save/load model"
      ],
      "metadata": {
        "id": "TPZubnmE9rp-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "'''\n",
        "\n",
        "Commenting this out because it takes forever to download\n",
        "\n",
        "'''\n",
        "\n",
        "# # w2v has word embeddings and pytorch neural nets work with them.\n",
        "# w2v = api.load('word2vec-google-news-300')\n",
        "\n",
        "# print(type(w2v['taco'])) # Returns numpy.ndarray\n",
        "# print(w2v['taco'][:10]) # Get first 10 values of 300 embedded vector.\n",
        "\n",
        "# ''' [('Jackson', 0.5326348543167114),\n",
        "#      ('Prince', 0.5306329727172852),\n",
        "#      ('Tupou_V.', 0.5292826294898987),\n",
        "#      ('KIng', 0.5227501392364502),\n",
        "#      ('e_mail_robert.king_@', 0.5173623561859131)] '''\n",
        "# print(w2v.similar_by_word('King', topn=5)) # This got the values in below comment.\n",
        "\n",
        "# '''\n",
        "# w is vehicle and x is 0.7821096181869507\n",
        "# w is cars and x is 0.7423831224441528\n",
        "# w is SUV and x is 0.7160962224006653\n",
        "# w is minivan and x is 0.6907036900520325\n",
        "# w is truck and x is 0.6735789775848389\n",
        "# w is Car and x is 0.6677608489990234\n",
        "# w is Ford_Focus and x is 0.667320191860199\n",
        "# w is Honda_Civic and x is 0.6626849174499512\n",
        "# w is Jeep and x is 0.651133120059967\n",
        "# w is pickup_truck and x is 0.6441438794136047 '''\n",
        "\n",
        "# # This gets comment above.\n",
        "# for w, x in w2v.most_similar('car'):\n",
        "#   print(f'w is {w} and x is {x}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "NsYpORhtytMj",
        "outputId": "aa099a67-896b-41b5-a539-32cec07346cc"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nCommenting this out because it takes forever to download\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A bit quicker to download.\n",
        "te = api.load(\"glove-twitter-25\")"
      ],
      "metadata": {
        "id": "PZ5iz1dV6N12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f85da3ab-ee7c-4eb2-d9ff-d05f55160f63"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 104.8/104.8MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' .vocab can't be used with this set of embeddings, so key_to_index returns a dictionary. Also\n",
        "     index_to_key returns a list which is much better.'''\n",
        "len(te.key_to_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luE9EBQr7lRh",
        "outputId": "8b4027e5-1106-4fa8-b334-511bfb00db9c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1193514"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_words = te.index_to_key\n",
        "selected_word = all_words[0]\n",
        "emb = te[selected_word]\n",
        "\n",
        "print(f'Word: {selected_word}\\nEmbedding FOR {selected_word}:\\n{emb}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OE9xLVIG8OIW",
        "outputId": "5df7800d-212b-41d6-f281-50b4b4c2aed6"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word: <user>\n",
            "Embedding FOR <user>:\n",
            "[ 0.62415   0.62476  -0.082335  0.20101  -0.13741  -0.11431   0.77909\n",
            "  2.6356   -0.46351   0.57465  -0.024888 -0.015466 -2.9696   -0.49876\n",
            "  0.095034 -0.94879  -0.017336 -0.86349  -1.3348    0.046811  0.36999\n",
            " -0.57663  -0.48469   0.40078   0.75345 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' The concept of this is literally one embedding layer borrowing/taking embedding values.\n",
        "    In a real model, there might be certain words that don't have proper embedding values at\n",
        "    all. So why not plug those holes up? First I'll use an example embedding layer. It'll\n",
        "    take a vocab size and output a embed_dim size tensor.\n",
        "\n",
        "    The issue that also happened in the EmbedClassifier model should be talked about here.\n",
        "    The second error that happened was \"IndexError: index out of range in self\". Basically,\n",
        "    to sum the error, if there's a tensor like t.tensor([15]) and the embedding layer is:\n",
        "    t.nn.Embedding(num_embeddings=15, embedding_dim=5), we can't pass the tensor to it. The\n",
        "    embedding first arg is the MAX value for ALL elements in a given tensor. So I need to be\n",
        "    careful about the size of the embedding layer.\n",
        "\n",
        "    Errors:\n",
        "    1) \"RuntimeError: a view of a leaf Variable that requires grad is being used in an\n",
        "        in-place operation.\"\n",
        "\n",
        "        Solution: el.weight.requires_grad = False '''\n",
        "\n",
        "# Get max length of vocab dictionary.\n",
        "el = t.nn.Embedding(num_embeddings=len(te.key_to_index), embedding_dim=25)\n",
        "el.weight.requires_grad = False\n",
        "\n",
        "num_words = 5\n",
        "\n",
        "# Loop for first 5 words.\n",
        "for i, x in zip(range(num_words), all_words):\n",
        "  print(f'-----Index {i}-----\\nWord: {x}\\nWord embedding in glove embeddings:\\n{te[x]}\\n\\n')\n",
        "  print(f'--- Previous model embedding:\\n{el.weight[i]}')\n",
        "  # Update the embedding with embedding in downloaded word embeddings (currently \"glove-twitter-25\")\n",
        "  el.weight[i] = t.tensor(te[x], dtype=t.float32)\n",
        "  print(f'--- UPDATE model embedding:\\n{el.weight[i]}\\n\\n')\n",
        "\n",
        "# Get all new weights and display them.\n",
        "updated_weights = el.weight[:num_words]\n",
        "print(f'New updated first {num_words} word embeddings in embedding layer:\\n{updated_weights}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljE-xb5G9pKn",
        "outputId": "18a845f6-f8fb-4305-910f-d8eb0c3a99e8"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----Index 0-----\n",
            "Word: <user>\n",
            "Word embedding in glove embeddings:\n",
            "[ 0.62415   0.62476  -0.082335  0.20101  -0.13741  -0.11431   0.77909\n",
            "  2.6356   -0.46351   0.57465  -0.024888 -0.015466 -2.9696   -0.49876\n",
            "  0.095034 -0.94879  -0.017336 -0.86349  -1.3348    0.046811  0.36999\n",
            " -0.57663  -0.48469   0.40078   0.75345 ]\n",
            "\n",
            "\n",
            "--- Previous model embedding:\n",
            "tensor([ 0.4397,  0.1124,  0.6408,  0.4412, -0.2159, -0.7425,  0.5627,  0.2596,\n",
            "         0.5229,  2.3022, -1.4689, -1.5867,  1.2032,  0.0845, -1.2001, -0.0048,\n",
            "        -0.2303, -0.3918,  0.5433, -0.3952,  0.2055, -0.4503, -0.5731, -0.5554,\n",
            "        -1.5312])\n",
            "--- UPDATE model embedding:\n",
            "tensor([ 0.6241,  0.6248, -0.0823,  0.2010, -0.1374, -0.1143,  0.7791,  2.6356,\n",
            "        -0.4635,  0.5746, -0.0249, -0.0155, -2.9696, -0.4988,  0.0950, -0.9488,\n",
            "        -0.0173, -0.8635, -1.3348,  0.0468,  0.3700, -0.5766, -0.4847,  0.4008,\n",
            "         0.7534])\n",
            "\n",
            "\n",
            "-----Index 1-----\n",
            "Word: .\n",
            "Word embedding in glove embeddings:\n",
            "[ 0.69586  -1.1469   -0.41797  -0.022311 -0.023801  0.82358   1.2228\n",
            "  1.741    -0.90979   1.3725    0.1153   -0.63906  -3.2252    0.61269\n",
            "  0.33544  -0.57058  -0.50861  -0.16575  -0.98153  -0.8213    0.24333\n",
            " -0.14482  -0.67877   0.7061    0.40833 ]\n",
            "\n",
            "\n",
            "--- Previous model embedding:\n",
            "tensor([-1.2341,  1.8197, -0.5515, -1.3253,  0.1886, -0.0691, -0.4949, -1.4782,\n",
            "         2.5672, -0.4731,  0.3356,  1.5091,  2.0820,  1.7067,  2.3804, -1.0670,\n",
            "         1.1149, -0.1407,  0.8058,  0.3276, -0.7607, -1.5991,  0.0185,  0.8419,\n",
            "        -0.4000])\n",
            "--- UPDATE model embedding:\n",
            "tensor([ 0.6959, -1.1469, -0.4180, -0.0223, -0.0238,  0.8236,  1.2228,  1.7410,\n",
            "        -0.9098,  1.3725,  0.1153, -0.6391, -3.2252,  0.6127,  0.3354, -0.5706,\n",
            "        -0.5086, -0.1657, -0.9815, -0.8213,  0.2433, -0.1448, -0.6788,  0.7061,\n",
            "         0.4083])\n",
            "\n",
            "\n",
            "-----Index 2-----\n",
            "Word: :\n",
            "Word embedding in glove embeddings:\n",
            "[ 1.1242    0.054519 -0.037362  0.10046   0.11923  -0.30009   1.0938\n",
            "  2.537    -0.072802  1.0491    1.0931    0.066084 -2.7036   -0.14391\n",
            " -0.22031  -0.99347  -0.65072  -0.030948 -1.0817   -0.64701   0.32341\n",
            " -0.41612  -0.5268   -0.047166  0.71549 ]\n",
            "\n",
            "\n",
            "--- Previous model embedding:\n",
            "tensor([ 1.0395,  0.3582, -0.0033, -0.5344,  1.1687,  0.3945, -1.0450, -0.9565,\n",
            "         0.0335,  0.7101, -1.5353, -0.4127,  0.9663,  1.6248, -2.6133, -1.6965,\n",
            "        -0.2282,  0.2800,  0.0732,  1.1133,  0.2823,  0.4342,  0.4569, -0.8654,\n",
            "         0.7813])\n",
            "--- UPDATE model embedding:\n",
            "tensor([ 1.1242,  0.0545, -0.0374,  0.1005,  0.1192, -0.3001,  1.0938,  2.5370,\n",
            "        -0.0728,  1.0491,  1.0931,  0.0661, -2.7036, -0.1439, -0.2203, -0.9935,\n",
            "        -0.6507, -0.0309, -1.0817, -0.6470,  0.3234, -0.4161, -0.5268, -0.0472,\n",
            "         0.7155])\n",
            "\n",
            "\n",
            "-----Index 3-----\n",
            "Word: rt\n",
            "Word embedding in glove embeddings:\n",
            "[ 0.74056  0.9155  -0.16352  0.35843  0.05266  0.1456   1.0421   2.8073\n",
            "  0.12865  1.0492   0.13033  0.20508 -2.6686  -0.50551 -0.29574 -0.91433\n",
            " -0.40456 -1.0988  -1.0333  -0.17875  0.37979 -0.25922 -0.74854  0.36001\n",
            "  0.61206]\n",
            "\n",
            "\n",
            "--- Previous model embedding:\n",
            "tensor([-0.9268,  0.2064, -0.3334, -0.4288,  0.2329,  0.9625,  0.3492, -0.9215,\n",
            "        -0.0562, -0.7015,  1.0367, -0.6037, -1.2788,  0.1239,  1.1648,  0.9234,\n",
            "         1.3873,  1.3750,  0.6596,  0.4766, -1.0163,  0.6104,  0.4669,  1.9507,\n",
            "        -1.0631])\n",
            "--- UPDATE model embedding:\n",
            "tensor([ 0.7406,  0.9155, -0.1635,  0.3584,  0.0527,  0.1456,  1.0421,  2.8073,\n",
            "         0.1286,  1.0492,  0.1303,  0.2051, -2.6686, -0.5055, -0.2957, -0.9143,\n",
            "        -0.4046, -1.0988, -1.0333, -0.1787,  0.3798, -0.2592, -0.7485,  0.3600,\n",
            "         0.6121])\n",
            "\n",
            "\n",
            "-----Index 4-----\n",
            "Word: ,\n",
            "Word embedding in glove embeddings:\n",
            "[ 0.84705  -1.0349   -0.050419  0.27164  -0.58659   0.99514   0.25267\n",
            "  1.6963    0.10313   0.80073   0.74655  -1.2667   -4.036    -0.22557\n",
            "  0.16322  -0.67015  -0.64812   0.010373 -0.71889  -0.74997   0.24862\n",
            "  0.10319  -1.1732    0.58196   0.33846 ]\n",
            "\n",
            "\n",
            "--- Previous model embedding:\n",
            "tensor([ 1.1404, -0.0899,  0.7298, -1.8453, -0.1021, -1.0335, -0.3126,  0.2458,\n",
            "         0.3772,  1.1012, -1.1428,  0.0376,  0.2886,  0.3866, -0.2011, -0.1179,\n",
            "        -0.8294, -1.4073,  1.6268,  0.1723, -0.7043,  0.3147,  0.1574,  0.3854,\n",
            "         0.5737])\n",
            "--- UPDATE model embedding:\n",
            "tensor([ 0.8471, -1.0349, -0.0504,  0.2716, -0.5866,  0.9951,  0.2527,  1.6963,\n",
            "         0.1031,  0.8007,  0.7466, -1.2667, -4.0360, -0.2256,  0.1632, -0.6701,\n",
            "        -0.6481,  0.0104, -0.7189, -0.7500,  0.2486,  0.1032, -1.1732,  0.5820,\n",
            "         0.3385])\n",
            "\n",
            "\n",
            "New updated first 5 word embeddings in embedding layer:\n",
            "tensor([[ 0.6241,  0.6248, -0.0823,  0.2010, -0.1374, -0.1143,  0.7791,  2.6356,\n",
            "         -0.4635,  0.5746, -0.0249, -0.0155, -2.9696, -0.4988,  0.0950, -0.9488,\n",
            "         -0.0173, -0.8635, -1.3348,  0.0468,  0.3700, -0.5766, -0.4847,  0.4008,\n",
            "          0.7534],\n",
            "        [ 0.6959, -1.1469, -0.4180, -0.0223, -0.0238,  0.8236,  1.2228,  1.7410,\n",
            "         -0.9098,  1.3725,  0.1153, -0.6391, -3.2252,  0.6127,  0.3354, -0.5706,\n",
            "         -0.5086, -0.1657, -0.9815, -0.8213,  0.2433, -0.1448, -0.6788,  0.7061,\n",
            "          0.4083],\n",
            "        [ 1.1242,  0.0545, -0.0374,  0.1005,  0.1192, -0.3001,  1.0938,  2.5370,\n",
            "         -0.0728,  1.0491,  1.0931,  0.0661, -2.7036, -0.1439, -0.2203, -0.9935,\n",
            "         -0.6507, -0.0309, -1.0817, -0.6470,  0.3234, -0.4161, -0.5268, -0.0472,\n",
            "          0.7155],\n",
            "        [ 0.7406,  0.9155, -0.1635,  0.3584,  0.0527,  0.1456,  1.0421,  2.8073,\n",
            "          0.1286,  1.0492,  0.1303,  0.2051, -2.6686, -0.5055, -0.2957, -0.9143,\n",
            "         -0.4046, -1.0988, -1.0333, -0.1787,  0.3798, -0.2592, -0.7485,  0.3600,\n",
            "          0.6121],\n",
            "        [ 0.8471, -1.0349, -0.0504,  0.2716, -0.5866,  0.9951,  0.2527,  1.6963,\n",
            "          0.1031,  0.8007,  0.7466, -1.2667, -4.0360, -0.2256,  0.1632, -0.6701,\n",
            "         -0.6481,  0.0104, -0.7189, -0.7500,  0.2486,  0.1032, -1.1732,  0.5820,\n",
            "          0.3385]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' Basic model. I desired to see how certain things worked.\n",
        "\n",
        "    Error(s) resolved:\n",
        "\n",
        "    1) \"RuntimeError: mat1 and mat2 shapes cannot be multiplied (3x5 and 3x5)\"\n",
        "        Why did this happen? Ex: I remembered from a EmbedClassifier model I had\n",
        "        this code:\n",
        "        \"self.embedding = t.nn.Embedding(num_embeddings=vocab_size, embedding_dim=embed_dim)\n",
        "         self.fc = t.nn.Linear(embed_dim, num_class)\"\n",
        "        vocab_size = 75\n",
        "        embed_dim = 5\n",
        "        num_class = 3\n",
        "        So the linear layer is EXPECTING something of size 5. To quote my own comment\n",
        "        \"So the linear layer can take a 2d matrix as long as the columns of the 2d matrix\n",
        "        (the \"5\" in 29,5) matches the linear layers INPUT (input is also 5).\"\n",
        "\n",
        "          - Dealing with 2d tensors.\n",
        "        The above explanation applies to 1d tensors. In THIS case with the code below,\n",
        "        the input of t.ones is 3,5 which is 3 rows and 5 columns. The linear layer is:\n",
        "        \"Linear(in_features=3, out_features=5, bias=True)\". So in this case the t.ones\n",
        "        tensor is 3 rows and 5 columns but it needs 5 rows and 3 columns, and that's why\n",
        "        the code uses transpose with \"preds = tnn(x.T)\" which literally flips the\n",
        "        dimensions FROM 3,5, to 5,3. As long as the matrix columns match the\n",
        "        input of the Linear layer, it works. '''\n",
        "\n",
        "model_h = 3\n",
        "model_w = 5\n",
        "\n",
        "class NeuralNetwork(t.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    # ll = linear layer.\n",
        "    self.layers = t.nn.Sequential(\n",
        "        t.nn.Linear(model_h, model_w, 10)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    logits = self.layers(x)\n",
        "    return logits\n",
        "\n",
        "# test neural network = tnn\n",
        "tnn = NeuralNetwork()\n",
        "\n",
        "# Create dummy data\n",
        "x = t.ones((model_h, model_w))\n",
        "\n",
        "preds = tnn(x.T)\n",
        "print(preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVe9aVRfl899",
        "outputId": "923c9446-b698-4c25-cd2c-e430ef0e63bb"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.4528,  0.6201,  0.6881,  1.1022, -0.4014],\n",
            "        [-1.4528,  0.6201,  0.6881,  1.1022, -0.4014],\n",
            "        [-1.4528,  0.6201,  0.6881,  1.1022, -0.4014],\n",
            "        [-1.4528,  0.6201,  0.6881,  1.1022, -0.4014],\n",
            "        [-1.4528,  0.6201,  0.6881,  1.1022, -0.4014]],\n",
            "       grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Save a model\n",
        "import os\n",
        "\n",
        "# ndn = new dir name\n",
        "ndn = \"testmodel\"\n",
        "\n",
        "curdir = os.getcwd()\n",
        "\n",
        "# cd = combined dir\n",
        "cd = os.path.join(curdir, ndn + \".pth\")\n",
        "\n",
        "# create dir\n",
        "print(cd)\n",
        "\n",
        "t.save(tnn.state_dict(), cd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-PmORjQsK5h",
        "outputId": "dff84173-2c2b-4c2e-d969-a786741b0265"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/testmodel.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- load model\n",
        "\n",
        "# instantiate one first. lnn = loaded neural network\n",
        "lnn = NeuralNetwork()\n",
        "lnn.load_state_dict(t.load(cd))\n",
        "\n",
        "lnn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5njCMD-sa2x",
        "outputId": "6231dda6-e805-4e46-dd60-0130cabd9448"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NeuralNetwork(\n",
              "  (layers): Sequential(\n",
              "    (0): Linear(in_features=3, out_features=5, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.3) Glove embeddings"
      ],
      "metadata": {
        "id": "kBvHndWxFfH-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ttv = torchtext vocab\n",
        "ttv = torchtext.vocab.GloVe(name='6B', dim=50)"
      ],
      "metadata": {
        "id": "JffEtUNgGQaA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e051c00b-b220-42c4-faee-818b06d5aa8d"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [02:39, 5.39MB/s]                           \n",
            "100%|| 399999/400000 [00:15<00:00, 25397.90it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Very similar to the vocab created earlier since this has stoi and itos as well\n",
        "ttv[\"Car\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skeSoubLUGeZ",
        "outputId": "68cf2260-f8d2-4398-f68a-2ecadf15d15e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ttv.stoi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vl43A1A4VUKV",
        "outputId": "3a66cfb3-3ef0-417b-eb33-f0ef0cb91867"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'the': 0,\n",
              " ',': 1,\n",
              " '.': 2,\n",
              " 'of': 3,\n",
              " 'to': 4,\n",
              " 'and': 5,\n",
              " 'in': 6,\n",
              " 'a': 7,\n",
              " '\"': 8,\n",
              " \"'s\": 9,\n",
              " 'for': 10,\n",
              " '-': 11,\n",
              " 'that': 12,\n",
              " 'on': 13,\n",
              " 'is': 14,\n",
              " 'was': 15,\n",
              " 'said': 16,\n",
              " 'with': 17,\n",
              " 'he': 18,\n",
              " 'as': 19,\n",
              " 'it': 20,\n",
              " 'by': 21,\n",
              " 'at': 22,\n",
              " '(': 23,\n",
              " ')': 24,\n",
              " 'from': 25,\n",
              " 'his': 26,\n",
              " \"''\": 27,\n",
              " '``': 28,\n",
              " 'an': 29,\n",
              " 'be': 30,\n",
              " 'has': 31,\n",
              " 'are': 32,\n",
              " 'have': 33,\n",
              " 'but': 34,\n",
              " 'were': 35,\n",
              " 'not': 36,\n",
              " 'this': 37,\n",
              " 'who': 38,\n",
              " 'they': 39,\n",
              " 'had': 40,\n",
              " 'i': 41,\n",
              " 'which': 42,\n",
              " 'will': 43,\n",
              " 'their': 44,\n",
              " ':': 45,\n",
              " 'or': 46,\n",
              " 'its': 47,\n",
              " 'one': 48,\n",
              " 'after': 49,\n",
              " 'new': 50,\n",
              " 'been': 51,\n",
              " 'also': 52,\n",
              " 'we': 53,\n",
              " 'would': 54,\n",
              " 'two': 55,\n",
              " 'more': 56,\n",
              " \"'\": 57,\n",
              " 'first': 58,\n",
              " 'about': 59,\n",
              " 'up': 60,\n",
              " 'when': 61,\n",
              " 'year': 62,\n",
              " 'there': 63,\n",
              " 'all': 64,\n",
              " '--': 65,\n",
              " 'out': 66,\n",
              " 'she': 67,\n",
              " 'other': 68,\n",
              " 'people': 69,\n",
              " \"n't\": 70,\n",
              " 'her': 71,\n",
              " 'percent': 72,\n",
              " 'than': 73,\n",
              " 'over': 74,\n",
              " 'into': 75,\n",
              " 'last': 76,\n",
              " 'some': 77,\n",
              " 'government': 78,\n",
              " 'time': 79,\n",
              " '$': 80,\n",
              " 'you': 81,\n",
              " 'years': 82,\n",
              " 'if': 83,\n",
              " 'no': 84,\n",
              " 'world': 85,\n",
              " 'can': 86,\n",
              " 'three': 87,\n",
              " 'do': 88,\n",
              " ';': 89,\n",
              " 'president': 90,\n",
              " 'only': 91,\n",
              " 'state': 92,\n",
              " 'million': 93,\n",
              " 'could': 94,\n",
              " 'us': 95,\n",
              " 'most': 96,\n",
              " '_': 97,\n",
              " 'against': 98,\n",
              " 'u.s.': 99,\n",
              " 'so': 100,\n",
              " 'them': 101,\n",
              " 'what': 102,\n",
              " 'him': 103,\n",
              " 'united': 104,\n",
              " 'during': 105,\n",
              " 'before': 106,\n",
              " 'may': 107,\n",
              " 'since': 108,\n",
              " 'many': 109,\n",
              " 'while': 110,\n",
              " 'where': 111,\n",
              " 'states': 112,\n",
              " 'because': 113,\n",
              " 'now': 114,\n",
              " 'city': 115,\n",
              " 'made': 116,\n",
              " 'like': 117,\n",
              " 'between': 118,\n",
              " 'did': 119,\n",
              " 'just': 120,\n",
              " 'national': 121,\n",
              " 'day': 122,\n",
              " 'country': 123,\n",
              " 'under': 124,\n",
              " 'such': 125,\n",
              " 'second': 126,\n",
              " 'then': 127,\n",
              " 'company': 128,\n",
              " 'group': 129,\n",
              " 'any': 130,\n",
              " 'through': 131,\n",
              " 'china': 132,\n",
              " 'four': 133,\n",
              " 'being': 134,\n",
              " 'down': 135,\n",
              " 'war': 136,\n",
              " 'back': 137,\n",
              " 'off': 138,\n",
              " 'south': 139,\n",
              " 'american': 140,\n",
              " 'minister': 141,\n",
              " 'police': 142,\n",
              " 'well': 143,\n",
              " 'including': 144,\n",
              " 'team': 145,\n",
              " 'international': 146,\n",
              " 'week': 147,\n",
              " 'officials': 148,\n",
              " 'still': 149,\n",
              " 'both': 150,\n",
              " 'even': 151,\n",
              " 'high': 152,\n",
              " 'part': 153,\n",
              " 'told': 154,\n",
              " 'those': 155,\n",
              " 'end': 156,\n",
              " 'former': 157,\n",
              " 'these': 158,\n",
              " 'make': 159,\n",
              " 'billion': 160,\n",
              " 'work': 161,\n",
              " 'our': 162,\n",
              " 'home': 163,\n",
              " 'school': 164,\n",
              " 'party': 165,\n",
              " 'house': 166,\n",
              " 'old': 167,\n",
              " 'later': 168,\n",
              " 'get': 169,\n",
              " 'another': 170,\n",
              " 'tuesday': 171,\n",
              " 'news': 172,\n",
              " 'long': 173,\n",
              " 'five': 174,\n",
              " 'called': 175,\n",
              " '1': 176,\n",
              " 'wednesday': 177,\n",
              " 'military': 178,\n",
              " 'way': 179,\n",
              " 'used': 180,\n",
              " 'much': 181,\n",
              " 'next': 182,\n",
              " 'monday': 183,\n",
              " 'thursday': 184,\n",
              " 'friday': 185,\n",
              " 'game': 186,\n",
              " 'here': 187,\n",
              " '?': 188,\n",
              " 'should': 189,\n",
              " 'take': 190,\n",
              " 'very': 191,\n",
              " 'my': 192,\n",
              " 'north': 193,\n",
              " 'security': 194,\n",
              " 'season': 195,\n",
              " 'york': 196,\n",
              " 'how': 197,\n",
              " 'public': 198,\n",
              " 'early': 199,\n",
              " 'according': 200,\n",
              " 'several': 201,\n",
              " 'court': 202,\n",
              " 'say': 203,\n",
              " 'around': 204,\n",
              " 'foreign': 205,\n",
              " '10': 206,\n",
              " 'until': 207,\n",
              " 'set': 208,\n",
              " 'political': 209,\n",
              " 'says': 210,\n",
              " 'market': 211,\n",
              " 'however': 212,\n",
              " 'family': 213,\n",
              " 'life': 214,\n",
              " 'same': 215,\n",
              " 'general': 216,\n",
              " '': 217,\n",
              " 'left': 218,\n",
              " 'good': 219,\n",
              " 'top': 220,\n",
              " 'university': 221,\n",
              " 'going': 222,\n",
              " 'number': 223,\n",
              " 'major': 224,\n",
              " 'known': 225,\n",
              " 'points': 226,\n",
              " 'won': 227,\n",
              " 'six': 228,\n",
              " 'month': 229,\n",
              " 'dollars': 230,\n",
              " 'bank': 231,\n",
              " '2': 232,\n",
              " 'iraq': 233,\n",
              " 'use': 234,\n",
              " 'members': 235,\n",
              " 'each': 236,\n",
              " 'area': 237,\n",
              " 'found': 238,\n",
              " 'official': 239,\n",
              " 'sunday': 240,\n",
              " 'place': 241,\n",
              " 'go': 242,\n",
              " 'based': 243,\n",
              " 'among': 244,\n",
              " 'third': 245,\n",
              " 'times': 246,\n",
              " 'took': 247,\n",
              " 'right': 248,\n",
              " 'days': 249,\n",
              " 'local': 250,\n",
              " 'economic': 251,\n",
              " 'countries': 252,\n",
              " 'see': 253,\n",
              " 'best': 254,\n",
              " 'report': 255,\n",
              " 'killed': 256,\n",
              " 'held': 257,\n",
              " 'business': 258,\n",
              " 'west': 259,\n",
              " 'does': 260,\n",
              " 'own': 261,\n",
              " '%': 262,\n",
              " 'came': 263,\n",
              " 'law': 264,\n",
              " 'months': 265,\n",
              " 'women': 266,\n",
              " \"'re\": 267,\n",
              " 'power': 268,\n",
              " 'think': 269,\n",
              " 'service': 270,\n",
              " 'children': 271,\n",
              " 'bush': 272,\n",
              " 'show': 273,\n",
              " '/': 274,\n",
              " 'help': 275,\n",
              " 'chief': 276,\n",
              " 'saturday': 277,\n",
              " 'system': 278,\n",
              " 'john': 279,\n",
              " 'support': 280,\n",
              " 'series': 281,\n",
              " 'play': 282,\n",
              " 'office': 283,\n",
              " 'following': 284,\n",
              " 'me': 285,\n",
              " 'meeting': 286,\n",
              " 'expected': 287,\n",
              " 'late': 288,\n",
              " 'washington': 289,\n",
              " 'games': 290,\n",
              " 'european': 291,\n",
              " 'league': 292,\n",
              " 'reported': 293,\n",
              " 'final': 294,\n",
              " 'added': 295,\n",
              " 'without': 296,\n",
              " 'british': 297,\n",
              " 'white': 298,\n",
              " 'history': 299,\n",
              " 'man': 300,\n",
              " 'men': 301,\n",
              " 'became': 302,\n",
              " 'want': 303,\n",
              " 'march': 304,\n",
              " 'case': 305,\n",
              " 'few': 306,\n",
              " 'run': 307,\n",
              " 'money': 308,\n",
              " 'began': 309,\n",
              " 'open': 310,\n",
              " 'name': 311,\n",
              " 'trade': 312,\n",
              " 'center': 313,\n",
              " '3': 314,\n",
              " 'israel': 315,\n",
              " 'oil': 316,\n",
              " 'too': 317,\n",
              " 'al': 318,\n",
              " 'film': 319,\n",
              " 'win': 320,\n",
              " 'led': 321,\n",
              " 'east': 322,\n",
              " 'central': 323,\n",
              " '20': 324,\n",
              " 'air': 325,\n",
              " 'come': 326,\n",
              " 'chinese': 327,\n",
              " 'town': 328,\n",
              " 'leader': 329,\n",
              " 'army': 330,\n",
              " 'line': 331,\n",
              " 'never': 332,\n",
              " 'little': 333,\n",
              " 'played': 334,\n",
              " 'prime': 335,\n",
              " 'death': 336,\n",
              " 'companies': 337,\n",
              " 'least': 338,\n",
              " 'put': 339,\n",
              " 'forces': 340,\n",
              " 'past': 341,\n",
              " 'de': 342,\n",
              " 'half': 343,\n",
              " 'june': 344,\n",
              " 'saying': 345,\n",
              " 'know': 346,\n",
              " 'federal': 347,\n",
              " 'french': 348,\n",
              " 'peace': 349,\n",
              " 'earlier': 350,\n",
              " 'capital': 351,\n",
              " 'force': 352,\n",
              " 'great': 353,\n",
              " 'union': 354,\n",
              " 'near': 355,\n",
              " 'released': 356,\n",
              " 'small': 357,\n",
              " 'department': 358,\n",
              " 'every': 359,\n",
              " 'health': 360,\n",
              " 'japan': 361,\n",
              " 'head': 362,\n",
              " 'ago': 363,\n",
              " 'night': 364,\n",
              " 'big': 365,\n",
              " 'cup': 366,\n",
              " 'election': 367,\n",
              " 'region': 368,\n",
              " 'director': 369,\n",
              " 'talks': 370,\n",
              " 'program': 371,\n",
              " 'far': 372,\n",
              " 'today': 373,\n",
              " 'statement': 374,\n",
              " 'july': 375,\n",
              " 'although': 376,\n",
              " 'district': 377,\n",
              " 'again': 378,\n",
              " 'born': 379,\n",
              " 'development': 380,\n",
              " 'leaders': 381,\n",
              " 'council': 382,\n",
              " 'close': 383,\n",
              " 'record': 384,\n",
              " 'along': 385,\n",
              " 'county': 386,\n",
              " 'france': 387,\n",
              " 'went': 388,\n",
              " 'point': 389,\n",
              " 'must': 390,\n",
              " 'spokesman': 391,\n",
              " 'your': 392,\n",
              " 'member': 393,\n",
              " 'plan': 394,\n",
              " 'financial': 395,\n",
              " 'april': 396,\n",
              " 'recent': 397,\n",
              " 'campaign': 398,\n",
              " 'become': 399,\n",
              " 'troops': 400,\n",
              " 'whether': 401,\n",
              " 'lost': 402,\n",
              " 'music': 403,\n",
              " '15': 404,\n",
              " 'got': 405,\n",
              " 'israeli': 406,\n",
              " '30': 407,\n",
              " 'need': 408,\n",
              " '4': 409,\n",
              " 'lead': 410,\n",
              " 'already': 411,\n",
              " 'russia': 412,\n",
              " 'though': 413,\n",
              " 'might': 414,\n",
              " 'free': 415,\n",
              " 'hit': 416,\n",
              " 'rights': 417,\n",
              " '11': 418,\n",
              " 'information': 419,\n",
              " 'away': 420,\n",
              " '12': 421,\n",
              " '5': 422,\n",
              " 'others': 423,\n",
              " 'control': 424,\n",
              " 'within': 425,\n",
              " 'large': 426,\n",
              " 'economy': 427,\n",
              " 'press': 428,\n",
              " 'agency': 429,\n",
              " 'water': 430,\n",
              " 'died': 431,\n",
              " 'career': 432,\n",
              " 'making': 433,\n",
              " '...': 434,\n",
              " 'deal': 435,\n",
              " 'attack': 436,\n",
              " 'side': 437,\n",
              " 'seven': 438,\n",
              " 'better': 439,\n",
              " 'less': 440,\n",
              " 'september': 441,\n",
              " 'once': 442,\n",
              " 'clinton': 443,\n",
              " 'main': 444,\n",
              " 'due': 445,\n",
              " 'committee': 446,\n",
              " 'building': 447,\n",
              " 'conference': 448,\n",
              " 'club': 449,\n",
              " 'january': 450,\n",
              " 'decision': 451,\n",
              " 'stock': 452,\n",
              " 'america': 453,\n",
              " 'given': 454,\n",
              " 'give': 455,\n",
              " 'often': 456,\n",
              " 'announced': 457,\n",
              " 'television': 458,\n",
              " 'industry': 459,\n",
              " 'order': 460,\n",
              " 'young': 461,\n",
              " \"'ve\": 462,\n",
              " 'palestinian': 463,\n",
              " 'age': 464,\n",
              " 'start': 465,\n",
              " 'administration': 466,\n",
              " 'russian': 467,\n",
              " 'prices': 468,\n",
              " 'round': 469,\n",
              " 'december': 470,\n",
              " 'nations': 471,\n",
              " \"'m\": 472,\n",
              " 'human': 473,\n",
              " 'india': 474,\n",
              " 'defense': 475,\n",
              " 'asked': 476,\n",
              " 'total': 477,\n",
              " 'october': 478,\n",
              " 'players': 479,\n",
              " 'bill': 480,\n",
              " 'important': 481,\n",
              " 'southern': 482,\n",
              " 'move': 483,\n",
              " 'fire': 484,\n",
              " 'population': 485,\n",
              " 'rose': 486,\n",
              " 'november': 487,\n",
              " 'include': 488,\n",
              " 'further': 489,\n",
              " 'nuclear': 490,\n",
              " 'street': 491,\n",
              " 'taken': 492,\n",
              " 'media': 493,\n",
              " 'different': 494,\n",
              " 'issue': 495,\n",
              " 'received': 496,\n",
              " 'secretary': 497,\n",
              " 'return': 498,\n",
              " 'college': 499,\n",
              " 'working': 500,\n",
              " 'community': 501,\n",
              " 'eight': 502,\n",
              " 'groups': 503,\n",
              " 'despite': 504,\n",
              " 'level': 505,\n",
              " 'largest': 506,\n",
              " 'whose': 507,\n",
              " 'attacks': 508,\n",
              " 'germany': 509,\n",
              " 'august': 510,\n",
              " 'change': 511,\n",
              " 'church': 512,\n",
              " 'nation': 513,\n",
              " 'german': 514,\n",
              " 'station': 515,\n",
              " 'london': 516,\n",
              " 'weeks': 517,\n",
              " 'having': 518,\n",
              " '18': 519,\n",
              " 'research': 520,\n",
              " 'black': 521,\n",
              " 'services': 522,\n",
              " 'story': 523,\n",
              " '6': 524,\n",
              " 'europe': 525,\n",
              " 'sales': 526,\n",
              " 'policy': 527,\n",
              " 'visit': 528,\n",
              " 'northern': 529,\n",
              " 'lot': 530,\n",
              " 'across': 531,\n",
              " 'per': 532,\n",
              " 'current': 533,\n",
              " 'board': 534,\n",
              " 'football': 535,\n",
              " 'ministry': 536,\n",
              " 'workers': 537,\n",
              " 'vote': 538,\n",
              " 'book': 539,\n",
              " 'fell': 540,\n",
              " 'seen': 541,\n",
              " 'role': 542,\n",
              " 'students': 543,\n",
              " 'shares': 544,\n",
              " 'iran': 545,\n",
              " 'process': 546,\n",
              " 'agreement': 547,\n",
              " 'quarter': 548,\n",
              " 'full': 549,\n",
              " 'match': 550,\n",
              " 'started': 551,\n",
              " 'growth': 552,\n",
              " 'yet': 553,\n",
              " 'moved': 554,\n",
              " 'possible': 555,\n",
              " 'western': 556,\n",
              " 'special': 557,\n",
              " '100': 558,\n",
              " 'plans': 559,\n",
              " 'interest': 560,\n",
              " 'behind': 561,\n",
              " 'strong': 562,\n",
              " 'england': 563,\n",
              " 'named': 564,\n",
              " 'food': 565,\n",
              " 'period': 566,\n",
              " 'real': 567,\n",
              " 'authorities': 568,\n",
              " 'car': 569,\n",
              " 'term': 570,\n",
              " 'rate': 571,\n",
              " 'race': 572,\n",
              " 'nearly': 573,\n",
              " 'korea': 574,\n",
              " 'enough': 575,\n",
              " 'site': 576,\n",
              " 'opposition': 577,\n",
              " 'keep': 578,\n",
              " '25': 579,\n",
              " 'call': 580,\n",
              " 'future': 581,\n",
              " 'taking': 582,\n",
              " 'island': 583,\n",
              " '2008': 584,\n",
              " '2006': 585,\n",
              " 'road': 586,\n",
              " 'outside': 587,\n",
              " 'really': 588,\n",
              " 'century': 589,\n",
              " 'democratic': 590,\n",
              " 'almost': 591,\n",
              " 'single': 592,\n",
              " 'share': 593,\n",
              " 'leading': 594,\n",
              " 'trying': 595,\n",
              " 'find': 596,\n",
              " 'album': 597,\n",
              " 'senior': 598,\n",
              " 'minutes': 599,\n",
              " 'together': 600,\n",
              " 'congress': 601,\n",
              " 'index': 602,\n",
              " 'australia': 603,\n",
              " 'results': 604,\n",
              " 'hard': 605,\n",
              " 'hours': 606,\n",
              " 'land': 607,\n",
              " 'action': 608,\n",
              " 'higher': 609,\n",
              " 'field': 610,\n",
              " 'cut': 611,\n",
              " 'coach': 612,\n",
              " 'elections': 613,\n",
              " 'san': 614,\n",
              " 'issues': 615,\n",
              " 'executive': 616,\n",
              " 'february': 617,\n",
              " 'production': 618,\n",
              " 'areas': 619,\n",
              " 'river': 620,\n",
              " 'face': 621,\n",
              " 'using': 622,\n",
              " 'japanese': 623,\n",
              " 'province': 624,\n",
              " 'park': 625,\n",
              " 'price': 626,\n",
              " 'commission': 627,\n",
              " 'california': 628,\n",
              " 'father': 629,\n",
              " 'son': 630,\n",
              " 'education': 631,\n",
              " '7': 632,\n",
              " 'village': 633,\n",
              " 'energy': 634,\n",
              " 'shot': 635,\n",
              " 'short': 636,\n",
              " 'africa': 637,\n",
              " 'key': 638,\n",
              " 'red': 639,\n",
              " 'association': 640,\n",
              " 'average': 641,\n",
              " 'pay': 642,\n",
              " 'exchange': 643,\n",
              " 'eu': 644,\n",
              " 'something': 645,\n",
              " 'gave': 646,\n",
              " 'likely': 647,\n",
              " 'player': 648,\n",
              " 'george': 649,\n",
              " '2007': 650,\n",
              " 'victory': 651,\n",
              " '8': 652,\n",
              " 'low': 653,\n",
              " 'things': 654,\n",
              " '2010': 655,\n",
              " 'pakistan': 656,\n",
              " '14': 657,\n",
              " 'post': 658,\n",
              " 'social': 659,\n",
              " 'continue': 660,\n",
              " 'ever': 661,\n",
              " 'look': 662,\n",
              " 'chairman': 663,\n",
              " 'job': 664,\n",
              " '2000': 665,\n",
              " 'soldiers': 666,\n",
              " 'able': 667,\n",
              " 'parliament': 668,\n",
              " 'front': 669,\n",
              " 'himself': 670,\n",
              " 'problems': 671,\n",
              " 'private': 672,\n",
              " 'lower': 673,\n",
              " 'list': 674,\n",
              " 'built': 675,\n",
              " '13': 676,\n",
              " 'efforts': 677,\n",
              " 'dollar': 678,\n",
              " 'miles': 679,\n",
              " 'included': 680,\n",
              " 'radio': 681,\n",
              " 'live': 682,\n",
              " 'form': 683,\n",
              " 'david': 684,\n",
              " 'african': 685,\n",
              " 'increase': 686,\n",
              " 'reports': 687,\n",
              " 'sent': 688,\n",
              " 'fourth': 689,\n",
              " 'always': 690,\n",
              " 'king': 691,\n",
              " '50': 692,\n",
              " 'tax': 693,\n",
              " 'taiwan': 694,\n",
              " 'britain': 695,\n",
              " '16': 696,\n",
              " 'playing': 697,\n",
              " 'title': 698,\n",
              " 'middle': 699,\n",
              " 'meet': 700,\n",
              " 'global': 701,\n",
              " 'wife': 702,\n",
              " '2009': 703,\n",
              " 'position': 704,\n",
              " 'located': 705,\n",
              " 'clear': 706,\n",
              " 'ahead': 707,\n",
              " '2004': 708,\n",
              " '2005': 709,\n",
              " 'iraqi': 710,\n",
              " 'english': 711,\n",
              " 'result': 712,\n",
              " 'release': 713,\n",
              " 'violence': 714,\n",
              " 'goal': 715,\n",
              " 'project': 716,\n",
              " 'closed': 717,\n",
              " 'border': 718,\n",
              " 'body': 719,\n",
              " 'soon': 720,\n",
              " 'crisis': 721,\n",
              " 'division': 722,\n",
              " '&amp;': 723,\n",
              " 'served': 724,\n",
              " 'tour': 725,\n",
              " 'hospital': 726,\n",
              " 'kong': 727,\n",
              " 'test': 728,\n",
              " 'hong': 729,\n",
              " 'u.n.': 730,\n",
              " 'inc.': 731,\n",
              " 'technology': 732,\n",
              " 'believe': 733,\n",
              " 'organization': 734,\n",
              " 'published': 735,\n",
              " 'weapons': 736,\n",
              " 'agreed': 737,\n",
              " 'why': 738,\n",
              " 'nine': 739,\n",
              " 'summer': 740,\n",
              " 'wanted': 741,\n",
              " 'republican': 742,\n",
              " 'act': 743,\n",
              " 'recently': 744,\n",
              " 'texas': 745,\n",
              " 'course': 746,\n",
              " 'problem': 747,\n",
              " 'senate': 748,\n",
              " 'medical': 749,\n",
              " 'un': 750,\n",
              " 'done': 751,\n",
              " 'reached': 752,\n",
              " 'star': 753,\n",
              " 'continued': 754,\n",
              " 'investors': 755,\n",
              " 'living': 756,\n",
              " 'care': 757,\n",
              " 'signed': 758,\n",
              " '17': 759,\n",
              " 'art': 760,\n",
              " 'provide': 761,\n",
              " 'worked': 762,\n",
              " 'presidential': 763,\n",
              " 'gold': 764,\n",
              " 'obama': 765,\n",
              " 'morning': 766,\n",
              " 'dead': 767,\n",
              " 'opened': 768,\n",
              " \"'ll\": 769,\n",
              " 'event': 770,\n",
              " 'previous': 771,\n",
              " 'cost': 772,\n",
              " 'instead': 773,\n",
              " 'canada': 774,\n",
              " 'band': 775,\n",
              " 'teams': 776,\n",
              " 'daily': 777,\n",
              " '2001': 778,\n",
              " 'available': 779,\n",
              " 'drug': 780,\n",
              " 'coming': 781,\n",
              " '2003': 782,\n",
              " 'investment': 783,\n",
              " 's': 784,\n",
              " 'michael': 785,\n",
              " 'civil': 786,\n",
              " 'woman': 787,\n",
              " 'training': 788,\n",
              " 'appeared': 789,\n",
              " '9': 790,\n",
              " 'involved': 791,\n",
              " 'indian': 792,\n",
              " 'similar': 793,\n",
              " 'situation': 794,\n",
              " '24': 795,\n",
              " 'los': 796,\n",
              " 'running': 797,\n",
              " 'fighting': 798,\n",
              " 'mark': 799,\n",
              " '40': 800,\n",
              " 'trial': 801,\n",
              " 'hold': 802,\n",
              " 'australian': 803,\n",
              " 'thought': 804,\n",
              " '!': 805,\n",
              " 'study': 806,\n",
              " 'fall': 807,\n",
              " 'mother': 808,\n",
              " 'met': 809,\n",
              " 'relations': 810,\n",
              " 'anti': 811,\n",
              " '2002': 812,\n",
              " 'song': 813,\n",
              " 'popular': 814,\n",
              " 'base': 815,\n",
              " 'tv': 816,\n",
              " 'ground': 817,\n",
              " 'markets': 818,\n",
              " 'ii': 819,\n",
              " 'newspaper': 820,\n",
              " 'staff': 821,\n",
              " 'saw': 822,\n",
              " 'hand': 823,\n",
              " 'hope': 824,\n",
              " 'operations': 825,\n",
              " 'pressure': 826,\n",
              " 'americans': 827,\n",
              " 'eastern': 828,\n",
              " 'st.': 829,\n",
              " 'legal': 830,\n",
              " 'asia': 831,\n",
              " 'budget': 832,\n",
              " 'returned': 833,\n",
              " 'considered': 834,\n",
              " 'love': 835,\n",
              " 'wrote': 836,\n",
              " 'stop': 837,\n",
              " 'fight': 838,\n",
              " 'currently': 839,\n",
              " 'charges': 840,\n",
              " 'try': 841,\n",
              " 'aid': 842,\n",
              " 'ended': 843,\n",
              " 'management': 844,\n",
              " 'brought': 845,\n",
              " 'cases': 846,\n",
              " 'decided': 847,\n",
              " 'failed': 848,\n",
              " 'network': 849,\n",
              " 'works': 850,\n",
              " 'gas': 851,\n",
              " 'turned': 852,\n",
              " 'fact': 853,\n",
              " 'vice': 854,\n",
              " 'ca': 855,\n",
              " 'mexico': 856,\n",
              " 'trading': 857,\n",
              " 'especially': 858,\n",
              " 'reporters': 859,\n",
              " 'afghanistan': 860,\n",
              " 'common': 861,\n",
              " 'looking': 862,\n",
              " 'space': 863,\n",
              " 'rates': 864,\n",
              " 'manager': 865,\n",
              " 'loss': 866,\n",
              " '2011': 867,\n",
              " 'justice': 868,\n",
              " 'thousands': 869,\n",
              " 'james': 870,\n",
              " 'rather': 871,\n",
              " 'fund': 872,\n",
              " 'thing': 873,\n",
              " 'republic': 874,\n",
              " 'opening': 875,\n",
              " 'accused': 876,\n",
              " 'winning': 877,\n",
              " 'scored': 878,\n",
              " 'championship': 879,\n",
              " 'example': 880,\n",
              " 'getting': 881,\n",
              " 'biggest': 882,\n",
              " 'performance': 883,\n",
              " 'sports': 884,\n",
              " '1998': 885,\n",
              " 'let': 886,\n",
              " 'allowed': 887,\n",
              " 'schools': 888,\n",
              " 'means': 889,\n",
              " 'turn': 890,\n",
              " 'leave': 891,\n",
              " 'no.': 892,\n",
              " 'robert': 893,\n",
              " 'personal': 894,\n",
              " 'stocks': 895,\n",
              " 'showed': 896,\n",
              " 'light': 897,\n",
              " 'arrested': 898,\n",
              " 'person': 899,\n",
              " 'either': 900,\n",
              " 'offer': 901,\n",
              " 'majority': 902,\n",
              " 'battle': 903,\n",
              " '19': 904,\n",
              " 'class': 905,\n",
              " 'evidence': 906,\n",
              " 'makes': 907,\n",
              " 'society': 908,\n",
              " 'products': 909,\n",
              " 'regional': 910,\n",
              " 'needed': 911,\n",
              " 'stage': 912,\n",
              " 'am': 913,\n",
              " 'doing': 914,\n",
              " 'families': 915,\n",
              " 'construction': 916,\n",
              " 'various': 917,\n",
              " '1996': 918,\n",
              " 'sold': 919,\n",
              " 'independent': 920,\n",
              " 'kind': 921,\n",
              " 'airport': 922,\n",
              " 'paul': 923,\n",
              " 'judge': 924,\n",
              " 'internet': 925,\n",
              " 'movement': 926,\n",
              " 'room': 927,\n",
              " 'followed': 928,\n",
              " 'original': 929,\n",
              " 'angeles': 930,\n",
              " 'italy': 931,\n",
              " '`': 932,\n",
              " 'data': 933,\n",
              " 'comes': 934,\n",
              " 'parties': 935,\n",
              " 'nothing': 936,\n",
              " 'sea': 937,\n",
              " 'bring': 938,\n",
              " '2012': 939,\n",
              " 'annual': 940,\n",
              " 'officer': 941,\n",
              " 'beijing': 942,\n",
              " 'present': 943,\n",
              " 'remain': 944,\n",
              " 'nato': 945,\n",
              " '1999': 946,\n",
              " '22': 947,\n",
              " 'remains': 948,\n",
              " 'allow': 949,\n",
              " 'florida': 950,\n",
              " 'computer': 951,\n",
              " '21': 952,\n",
              " 'contract': 953,\n",
              " 'coast': 954,\n",
              " 'created': 955,\n",
              " 'demand': 956,\n",
              " 'operation': 957,\n",
              " 'events': 958,\n",
              " 'islamic': 959,\n",
              " 'beat': 960,\n",
              " 'analysts': 961,\n",
              " 'interview': 962,\n",
              " 'helped': 963,\n",
              " 'child': 964,\n",
              " 'probably': 965,\n",
              " 'spent': 966,\n",
              " 'asian': 967,\n",
              " 'effort': 968,\n",
              " 'cooperation': 969,\n",
              " 'shows': 970,\n",
              " 'calls': 971,\n",
              " 'investigation': 972,\n",
              " 'lives': 973,\n",
              " 'video': 974,\n",
              " 'yen': 975,\n",
              " 'runs': 976,\n",
              " 'tried': 977,\n",
              " 'bad': 978,\n",
              " 'described': 979,\n",
              " '1994': 980,\n",
              " 'toward': 981,\n",
              " 'written': 982,\n",
              " 'throughout': 983,\n",
              " 'established': 984,\n",
              " 'mission': 985,\n",
              " 'associated': 986,\n",
              " 'buy': 987,\n",
              " 'growing': 988,\n",
              " 'green': 989,\n",
              " 'forward': 990,\n",
              " 'competition': 991,\n",
              " 'poor': 992,\n",
              " 'latest': 993,\n",
              " 'banks': 994,\n",
              " 'question': 995,\n",
              " '1997': 996,\n",
              " 'prison': 997,\n",
              " 'feel': 998,\n",
              " 'attention': 999,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ttv.itos[379]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7VX01Sb5VaQ8",
        "outputId": "e2a4bbaa-8047-4ca4-9859-93ac5f158c2c"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'born'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.4) Etc Neural Network related topics/code"
      ],
      "metadata": {
        "id": "G7nvCQdtXrxD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.transforms import ToTensor, Lambda\n",
        "\n",
        "# --- lambdas\n",
        "\n",
        "# simple one. Type is <class 'function'>\n",
        "a = lambda x: x * 2\n",
        "print(f'Custom lambda: {a(2)}\\nCustom lambda TYPE: {type(a)}\\n\\n')\n",
        "\n",
        "''' this type is:\n",
        "torchvision.transforms.transforms.Lambda\n",
        "Does the same thing of course. All that's\n",
        "done is the previous lambda is given to it. '''\n",
        "b = Lambda(a)\n",
        "print(f'torchvision.transforms Lambda: {b(4)}\\ntorchvision.transforms Lambda TYPE: {type(b)}')"
      ],
      "metadata": {
        "id": "u6RC96jE4fss",
        "outputId": "054aa489-8f52-42b5-eebb-f26f0dbe57a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Custom lambda: 4\n",
            "Custom lambda TYPE: <class 'function'>\n",
            "\n",
            "\n",
            "torchvision.transforms Lambda: 8\n",
            "torchvision.transforms Lambda TYPE: <class 'torchvision.transforms.transforms.Lambda'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as f\n",
        "\n",
        "''' One hot encoding\n",
        "\n",
        "\"Used to indicate the presence\n",
        "of a value and lack of presence\n",
        "of other values.\"\n",
        "\n",
        "Below goes in order in each\n",
        "Tensor. Like index 0,1,2,3,4,5\n",
        "Will be indicative of the slot\n",
        "For each num. Hence why 5s tensor\n",
        "Gets ITS 1 at end. '''\n",
        "\n",
        "l = t.tensor([5,1,0,1,0])\n",
        "f.one_hot(l, num_classes=6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORVOeY24XvSq",
        "outputId": "69b4b3b1-e616-4434-d08b-9a482731df20"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 0, 0, 0, 0, 1],\n",
              "        [0, 1, 0, 0, 0, 0],\n",
              "        [1, 0, 0, 0, 0, 0],\n",
              "        [0, 1, 0, 0, 0, 0],\n",
              "        [1, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' Loss function example. Loss funcs get difference between predictions\n",
        "    and ground truths.\n",
        "\n",
        "    Also requires_grad is used. Needed because back propagation to calculate\n",
        "    gradients for each tensor that has \"requires_grad\" to true.\n",
        "\n",
        "    The first tensor is the ground truths aka what the CORRECT values\n",
        "    are, and the predictions are what a model would predict for example.\n",
        "    The model got 4 out of 5 correct but there's more math in the background\n",
        "    of the loss function going on, hence why the loss value isn't 0.8\n",
        "    exactly. '''\n",
        "\n",
        "lf = t.nn.CrossEntropyLoss()\n",
        "\n",
        "ground_truths = t.tensor([1,0,1,1,0], dtype=t.float32, requires_grad=True)\n",
        "preds = t.tensor([1,1,1,1,0], dtype=t.float32, requires_grad=True)\n",
        "\n",
        "l = lf(ground_truths, preds)\n",
        "\n",
        "print(f'Loss: {l}')\n",
        "\n",
        "l.backward()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkIMWO5Pd348",
        "outputId": "e045b604-617c-4137-da5d-2f79a3431329"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 6.271803855895996\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# See the gradients mentioned above.\n",
        "print(ground_truths.grad)\n",
        "print(preds.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOU5xl6GuRYC",
        "outputId": "546fd669-8f2f-489d-c551-69e80eb813ea"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.0707, -0.6061,  0.0707,  0.0707,  0.3939])\n",
            "tensor([1.3180, 2.3180, 1.3180, 1.3180, 2.3180])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stop ts from computational history. Sometimes computation isn't needed.\n",
        "z = preds.detach()\n",
        "print(z.requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfOmufN8vezB",
        "outputId": "5c916775-3371-4dfb-9ded-ad20dcf71420"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' Flatten layer. Interesting because it dramatically changes the shape\n",
        "\n",
        "    Testing an images nn input with 28 height and width\n",
        "    Flatten - This helps it work. Because the code\n",
        "    \"t.ones((num, num)), gets a 2d matrix of say\n",
        "    size (28,28). But the linear layer\n",
        "    requires it to be 1d due to the input\n",
        "    being num * num.\n",
        "\n",
        "    Also you can change the height/width as much as\n",
        "    you want because at the end of the day the\n",
        "    multiplication math will work. Definitely works for 3d and up\n",
        "    as well  '''\n",
        "\n",
        "height = 25\n",
        "width = 28\n",
        "\n",
        "# tt = test tensor. Of proper size.\n",
        "tt = t.ones((height, width))\n",
        "\n",
        "# 28 * 28 = 784\n",
        "ll = t.nn.Linear(height * width, 100)\n",
        "\n",
        "ll(tt.flatten())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1yONXegeXhS",
        "outputId": "7cf5b24e-34cf-4190-ee22-010040794d3a"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.0741,  0.4089,  0.3737, -0.2707, -0.0272, -0.4843, -0.0669, -0.1538,\n",
              "        -0.2415, -0.3134, -1.3957,  0.7815, -1.3746,  0.7480, -0.0760, -0.4360,\n",
              "         1.1383,  0.4808,  0.6637,  0.3833, -0.7154,  0.5242, -0.3230,  0.7998,\n",
              "        -0.9154,  0.1342,  0.4628,  0.6280, -0.0844,  1.2271, -0.1102, -1.0103,\n",
              "         0.4213,  0.7421,  0.5243, -0.5112,  0.2357, -0.0971, -0.8332, -0.0836,\n",
              "        -0.4302, -0.1669,  0.6612, -1.2081,  0.1913, -0.5197, -0.6149, -0.0942,\n",
              "         0.9280, -0.0220, -0.6618,  0.6094,  0.3318,  0.1174, -0.9837, -1.1060,\n",
              "         0.1541,  0.3663, -0.3196,  0.1374,  0.3263, -0.5648, -0.5835,  0.4989,\n",
              "         0.0666,  0.1372,  0.7819,  0.1181, -0.5437,  1.0324,  0.9498, -0.0302,\n",
              "        -0.1829, -0.0233, -0.4555, -0.6643,  0.3441,  0.2438,  0.2928, -0.2203,\n",
              "        -0.0129, -0.4925, -1.5830,  0.5887, -1.0196,  0.0602,  0.3125,  0.1881,\n",
              "         0.2223, -0.6951,  0.3112,  0.8646,  0.2355,  0.3442,  0.0583, -0.3290,\n",
              "        -0.8411,  0.5196, -0.0149, -0.0946], grad_fn=<ViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7) Data pipes"
      ],
      "metadata": {
        "id": "iGx9K-UqzybV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchdata.datapipes as dp\n",
        "\n",
        "''' these are good for handling\n",
        "Data. Different types of data\n",
        "Pipes as well. Choosing one that\n",
        "Fits needs/requirements is key\n",
        "'''\n",
        "\n",
        "x = t.tensor([5,4,7])\n",
        "\n",
        "p = dp.iter.IterableWrapper(x)\n",
        "\n",
        "for y in p:\n",
        "   print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdz14WZnzxoq",
        "outputId": "ccbb10db-d422-45de-de5d-9ae4853ca609"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(5)\n",
            "tensor(4)\n",
            "tensor(7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fl = dp.iter.FileLister(curdir)\n",
        "\n",
        "print(curdir)\n",
        "\n",
        "''' Prints the model path created earlier. If getting\n",
        "    a sizeable number of files is necessary, FileLister is definitely\n",
        "    the data pipe to go with. '''\n",
        "for x in fl:\n",
        "   print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9IBlhFBz54-",
        "outputId": "3352c3dd-df59-419d-a513-a9c843d9816c"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content/testmodel.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert to list, if desired\n",
        "dpl = list(p)\n",
        "dpl[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FV3aQ3hl0JFM",
        "outputId": "5dc9bf2b-29bf-4ff7-d501-ca67a509ac6d"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mapping helps change all elements in simple code.\n",
        "for x in p:\n",
        "  print(x)\n",
        "print('\\n')\n",
        "\n",
        "def multiply(val):\n",
        "  return val * 2\n",
        "\n",
        "# p = p.map(lambda x: x * 2) # Can do lambda but a not supported warning appears.\n",
        "p = p.map(multiply)\n",
        "\n",
        "for x in p:\n",
        "  print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ry6MBeE_0NDT",
        "outputId": "8b3fb1eb-6680-4bcb-ac94-c0dc9f0e61d2"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(5)\n",
            "tensor(4)\n",
            "tensor(7)\n",
            "\n",
            "\n",
            "tensor(10)\n",
            "tensor(8)\n",
            "tensor(14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8) Build vocab from iterator"
      ],
      "metadata": {
        "id": "0G4xzvQs0P-d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "''' PyTorch way to get a vocab\n",
        "And a vocab is numerical versions\n",
        "Of each word.\n",
        "'''\n",
        "\n",
        "# sentences for BASIC tokenization\n",
        "s = [\n",
        "   \"This is a test\",\n",
        "   \"Gaming is still fun but I don't have time for much of it anymore\",\n",
        "   \"Hello there sir, how are you?\"\n",
        "]\n",
        "print(f'Sentences:\\n{s}\\n')\n",
        "\n",
        "''' ts = tokenized sentences. cs = current sentences.\n",
        "    Loop through all sentences and get each word into\n",
        "    lowercase and split the sentence up word by word.\n",
        "'''\n",
        "ts = [cs.lower().split() for cs in s]\n",
        "print(f'TOKENIZED Sentences:\\n{ts}\\n')\n",
        "\n",
        "# yield pauses when func is looped and continues where it left off\n",
        "def get_ts(cs):\n",
        "  for s in cs:\n",
        "    yield s.lower().split()\n",
        "\n",
        "''' if v gets given a word it\n",
        " doesn't know, it'll give unk '''\n",
        "v = build_vocab_from_iterator(get_ts(s),\n",
        "                              specials=[\"<pad>\", \"<unk>\"],\n",
        "                              special_first=True)\n",
        "\n",
        "# stoi is string to int. Take notice to the special tokens.\n",
        "v.get_stoi()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHAywQi_0Tro",
        "outputId": "3f2da8c5-f4ec-4c15-8424-37851114a627"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentences:\n",
            "['This is a test', \"Gaming is still fun but I don't have time for much of it anymore\", 'Hello there sir, how are you?']\n",
            "\n",
            "TOKENIZED Sentences:\n",
            "[['this', 'is', 'a', 'test'], ['gaming', 'is', 'still', 'fun', 'but', 'i', \"don't\", 'have', 'time', 'for', 'much', 'of', 'it', 'anymore'], ['hello', 'there', 'sir,', 'how', 'are', 'you?']]\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'you?': 24,\n",
              " 'there': 21,\n",
              " 'test': 20,\n",
              " 'still': 19,\n",
              " 'sir,': 18,\n",
              " 'time': 23,\n",
              " 'this': 22,\n",
              " 'of': 17,\n",
              " 'much': 16,\n",
              " '<unk>': 1,\n",
              " 'hello': 12,\n",
              " 'i': 14,\n",
              " '<pad>': 0,\n",
              " 'for': 8,\n",
              " 'a': 3,\n",
              " 'are': 5,\n",
              " 'is': 2,\n",
              " 'anymore': 4,\n",
              " \"don't\": 7,\n",
              " 'it': 15,\n",
              " 'how': 13,\n",
              " 'but': 6,\n",
              " 'gaming': 10,\n",
              " 'fun': 9,\n",
              " 'have': 11}"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.data.utils import get_tokenizer\n",
        "\n",
        "tk = get_tokenizer('basic_english')\n",
        "\n",
        "''' Quick comparison with the tokenizer torchtext\n",
        "    has.\n",
        "    Using get_tokenizer:\n",
        "    1) s[0] - gets sentence.\n",
        "    2) tk() - tokenizes that sentence.\n",
        "    3) v - Pass to vocab to get numerical\n",
        "        representations of words.\n",
        "\n",
        "    Using my method:\n",
        "    1) ts[0] - Sentence tokenized already with\n",
        "        list comprehension code:\n",
        "        \"[cs.lower().split() for cs in s]\"\n",
        "        cs = current sentence\n",
        "\n",
        "    2) v - Pass to vocab to get numerical\n",
        "        representations of words. '''\n",
        "\n",
        "\n",
        "\n",
        "print(v(tk(s[0])))\n",
        "print(v(ts[0]))\n",
        "\n",
        "# ns = num sentence\n",
        "ns = v(ts[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGVPtY_X0ZLB",
        "outputId": "0e9fb67d-e2d7-4257-bc76-e6702588e425"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22, 2, 3, 20]\n",
            "[22, 2, 3, 20]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9) Transforms"
      ],
      "metadata": {
        "id": "6Tf6JOBV1gBV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchtext.transforms as T\n",
        "\n",
        "''' Transforms are good for altering text in a step by step manner. Similar to how a neural network class has a forward func\n",
        "    which passes the output of one layer as input to the next.\n",
        "\n",
        "      1) VocabTransform - Just takes the vocab and does exactly as seen in previous cell.\n",
        "\n",
        "      2) AddToken - Can add a numerical token that'll do some sort of special job. Ex: the unk token signifies if any\n",
        "          unknown values to the vocab are given. The primary reason why the output shows both pad and unk tokens is\n",
        "          because earlier when the build vocab from iterator object was created, this line was present:\n",
        "          \"specials=[\"<pad>\", \"<unk>\"]\" and 0 was assigned to pad and 1 was assigned to unk. It literally\n",
        "          shows that when we access the vocab dictionary with \".get_itos()\"\n",
        "\n",
        "\n",
        "\n",
        "3) AddToken - This time put it in the end\n",
        "\n",
        "'''\n",
        "\n",
        "x = T.Sequential(\n",
        "    T.VocabTransform(vocab=v),\n",
        "    T.AddToken(0, begin=True),\n",
        "    T.AddToken(1, begin=False)\n",
        ")\n",
        "\n",
        "# Get numerical sentence WITH tokens\n",
        "ns = x(ts[0])\n",
        "print(f'Numerical sentence:\\n{ns}')\n",
        "\n",
        "# Convert sentence back to text\n",
        "vocab_dict = v.get_itos()\n",
        "\n",
        "# Loop through all the nums in numerical sentence (ns)\n",
        "for i in ns:\n",
        "  print(vocab_dict[i], end=\" \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oix5qM8h0ZGQ",
        "outputId": "8b5f5226-1255-45fa-fd53-351e209c3814"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numerical sentence:\n",
            "[0, 22, 2, 3, 20, 1]\n",
            "<pad> this is a test <unk> "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10) Batches & Lambdas"
      ],
      "metadata": {
        "id": "WbombjG31pm2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''' Networks are always trained in batches. Data pipes have BucketBatch functions\n",
        "    in them. Can give them a regular list, tensor, whatever iterable desired.\n",
        "    1) batch_size - Size of each batch\n",
        "    2) batch_num - # of batches IN a bucket.\n",
        "    3) drop_last - If there's leftovers like if batch size if 4, but the iterator\n",
        "        has 15 elements, the first 3 batches will have 4 each. A total of 12 values\n",
        "        used so far. Setting drop_last to true will get rid of the final 3\n",
        "        values in the last batch.\n",
        "\n",
        " '''\n",
        "\n",
        "p = dp.iter.IterableWrapper(range(15))\n",
        "\n",
        "x = p.bucketbatch(batch_size=4)\n",
        "\n",
        "for i in x:\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ot_hBB0N0Y8y",
        "outputId": "36940a26-17fb-4170-986f-fafbc4ae6ab2"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3, 11, 9, 7]\n",
            "[8, 2, 14, 1]\n",
            "[12, 0, 4, 13]\n",
            "[6, 5, 10]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' Can use lambdas with the tokenizer\n",
        "    and vocab for quick text editing.\n",
        "\n",
        "    Remember variable \"s\" has multiple\n",
        "    sentences in it.\n",
        "\n",
        "    tl = tokenize lambda\n",
        "    vl = vocab lambda. Input MUST be\n",
        "      tokenized. always the specific vocab\n",
        "      built in code below was created\n",
        "      with build_vocab_from_iterator\n",
        "      with the sentence in the \"s\"\n",
        "      variable.\n",
        "'''\n",
        "\n",
        "tl = lambda x: tk(x)\n",
        "print(f'Real sentence:\\n{s[0]}\\nTokenized sentence:\\n{tl(s[0])}\\n\\n')\n",
        "\n",
        "vl = lambda y: v(tk(s[0]))\n",
        "print(f'Real sentence:\\n{s[0]}\\nNumerial sentence:\\n{vl(s[0])}\\n\\n')\n",
        "\n",
        "print(f'View vocab itos to see above numerical sentence MATCHES the vocab:')\n",
        "for key, value in v.get_stoi().items():\n",
        "  print(f'Key: {key} - Value: {value}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MsY5zSJe1tjy",
        "outputId": "220133a4-45ba-460d-f2a4-f8ad87323e13"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Real sentence:\n",
            "This is a test\n",
            "Tokenized sentence:\n",
            "['this', 'is', 'a', 'test']\n",
            "\n",
            "\n",
            "Real sentence:\n",
            "This is a test\n",
            "Numerial sentence:\n",
            "[22, 2, 3, 20]\n",
            "\n",
            "\n",
            "View vocab itos to see above numerical sentence MATCHES the vocab:\n",
            "Key: you? - Value: 24\n",
            "Key: there - Value: 21\n",
            "Key: test - Value: 20\n",
            "Key: still - Value: 19\n",
            "Key: sir, - Value: 18\n",
            "Key: time - Value: 23\n",
            "Key: this - Value: 22\n",
            "Key: of - Value: 17\n",
            "Key: much - Value: 16\n",
            "Key: <unk> - Value: 1\n",
            "Key: hello - Value: 12\n",
            "Key: i - Value: 14\n",
            "Key: <pad> - Value: 0\n",
            "Key: for - Value: 8\n",
            "Key: a - Value: 3\n",
            "Key: are - Value: 5\n",
            "Key: is - Value: 2\n",
            "Key: anymore - Value: 4\n",
            "Key: don't - Value: 7\n",
            "Key: it - Value: 15\n",
            "Key: how - Value: 13\n",
            "Key: but - Value: 6\n",
            "Key: gaming - Value: 10\n",
            "Key: fun - Value: 9\n",
            "Key: have - Value: 11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10) Packed Sequences"
      ],
      "metadata": {
        "id": "F0x6CfCTj54V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''' What are packed sequences?\n",
        "    Mainly for RNN.\n",
        "\n",
        "    [[1,2,3,4,5],\n",
        "     [6,7,8,0,0],\n",
        "     [9,0,0,0,0]]\"\n",
        "    Len is 5,3,1. RNN cells train with 1,6,9. Then 2,7. Then 3,8 Etc. So packed sequence is one\n",
        "    vec \"[1,6,9,2,7,3,8,4,5]\" Len of vec still 5,3,1.\n",
        "\n",
        "    First we need sentences of different lengths. \"ts\" is from section 1, tokenized sentences. '''\n",
        "\n",
        "for tks in ts:\n",
        "  print(tks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwwt3Zbej8Zb",
        "outputId": "7452837d-01e0-46df-e740-7caa74adaf09"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['this', 'is', 'a', 'test']\n",
            "['gaming', 'is', 'still', 'fun', 'but', 'i', \"don't\", 'have', 'time', 'for', 'much', 'of', 'it', 'anymore']\n",
            "['hello', 'there', 'sir,', 'how', 'are', 'you?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# encode them, function in section 1.\n",
        "num_sents = [encode(tks) for tks in ts]\n",
        "\n",
        "for ns in num_sents:\n",
        "  print(ns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4pTRRmVma7-",
        "outputId": "edf50909-0261-4a1f-9f02-579093cac5d4"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22, 2, 3, 20]\n",
            "[10, 2, 19, 9, 6, 14, 7, 11, 23, 8, 16, 17, 15, 4]\n",
            "[12, 21, 18, 13, 5, 24]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now pad. This code was written already in section 1 as well.\n",
        "padded_sents = [t.nn.functional.pad(t.tensor(sent), (0, max_length - len(sent))) for sent in num_sents]\n",
        "\n",
        "padded_sents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfhJx_LFmzzy",
        "outputId": "8f5837d5-57dd-43ae-e65a-47a625cef29a"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([22,  2,  3, 20,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0]),\n",
              " tensor([10,  2, 19,  9,  6, 14,  7, 11, 23,  8, 16, 17, 15,  4,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0]),\n",
              " tensor([12, 21, 18, 13,  5, 24,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0])]"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create 2d tensor of 0s to be used and have the num sents added to them soon.\n",
        "a = t.zeros((len(padded_sents), len(padded_sents[0])))\n",
        "\n",
        "# Get lengths of each numerical sentence\n",
        "num_sent_lens = [len(s) for s in num_sents]\n",
        "print(f'Num sent lengths: {num_sent_lens}')\n",
        "\n",
        "# Get longest one, in this case it's 42.\n",
        "max_len = max(num_sent_lens)\n",
        "print(f'Max length: {max_len}\\n')\n",
        "\n",
        "''' Loop over the numerical sentences ALONG with the specific lengths. But do so with index,\n",
        "    that's why enumerate is used with \"i\". Remember \"a\" is a 2d tensor and I can access each\n",
        "    index with \"a[i, etc]\". num_sent will be current numerical sentence, and same concept for\n",
        "    sent_len, which will be the current length.\n",
        "\n",
        "    Ex numerical sentence: \" 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.,\n",
        "    10., 12., 13., 14.,  0., 15., 16., 17., 18., 19., 20., 14., 21., 22., 23., 24.,\n",
        "    2.\"\n",
        "    Ex length: 29\n",
        "\n",
        "    So if i is 0, then in the tensor of 0's, which is \"a\", go to the tensor in index 0\n",
        "    which would be \"[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
        "    0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
        "    0., 0., 0., 0.]\" and UP UNTIL the numerical sentence length, which is \":sent_len\",\n",
        "    apply the real numerical sentence. '''\n",
        "for i, (num_sent, sent_len) in enumerate(zip(num_sents, num_sent_lens)):\n",
        "  a[i, :sent_len] = t.FloatTensor(num_sent)\n",
        "\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Q3uBSW-oXIC",
        "outputId": "36f06747-49cd-45eb-c5fe-26ea17d3eb2f"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num sent lengths: [4, 14, 6]\n",
            "Max length: 14\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[22.,  2.,  3., 20.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
              "        [10.,  2., 19.,  9.,  6., 14.,  7., 11., 23.,  8., 16., 17., 15.,  4.,\n",
              "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
              "        [12., 21., 18., 13.,  5., 24.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t.LongTensor(num_sent_lens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVRs1T8JKThu",
        "outputId": "9e1c225b-7618-4d1a-c319-cf107a2fe39a"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 4, 14,  6])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = t.LongTensor(num_sent_lens).sort(0, descending=True)\n",
        "\n",
        "print(x)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDzaJNvlKZyY",
        "outputId": "41b00a0e-f275-488c-dcd1-9c41f6753bff"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([14,  6,  4])\n",
            "tensor([1, 2, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 11) Character encoding"
      ],
      "metadata": {
        "id": "9V6uwVpSaR7u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# build vocab for chars\n",
        "\n",
        "# counter keeps track\n",
        "c = collections.Counter()\n",
        "\n",
        "# need ds\n",
        "ds = [\n",
        "   (0, \"A test sentence\"),\n",
        "   (1, \"I'm here studying\"),\n",
        "   (1, \"Tacos are unhealthy\"),\n",
        "   (0, \"The Superbowl is over\")\n",
        "]\n",
        "\n",
        "# ct is current tuple\n",
        "for ct in ds:\n",
        "   ''' list cast turns sentence\n",
        "   into list of individual letters\n",
        "   counter has dictionary in it.\n",
        "   Keys are letters/chars but nums\n",
        "   are how many times. Ex: letter\n",
        "   \"A\" was only seen once so it\n",
        "   is \"'A':1\" '''\n",
        "   c.update(list(ct[1]))\n",
        "\n",
        "# get stoi is dictionary\n",
        "# can use stoi & itos\n",
        "v = torchtext.vocab.vocab(c)\n",
        "v.get_stoi()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTZbvQ0VaPpN",
        "outputId": "3d621768-d005-4ebc-dc33-507aa2ab6c01"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'w': 24,\n",
              " 'l': 20,\n",
              " 'S': 21,\n",
              " 'o': 19,\n",
              " 'a': 18,\n",
              " 'T': 17,\n",
              " 'g': 16,\n",
              " 'i': 15,\n",
              " 'y': 14,\n",
              " 'v': 25,\n",
              " 's': 4,\n",
              " 'I': 7,\n",
              " 'r': 11,\n",
              " 't': 2,\n",
              " 'e': 3,\n",
              " 'd': 13,\n",
              " 'n': 5,\n",
              " 'c': 6,\n",
              " 'b': 23,\n",
              " 'A': 0,\n",
              " \"'\": 8,\n",
              " 'm': 9,\n",
              " 'p': 22,\n",
              " ' ': 1,\n",
              " 'h': 10,\n",
              " 'u': 12}"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# func for encoding. c = current character\n",
        "\n",
        "def encode_chars(s):\n",
        "   return [v[cc] for cc in list(s)]\n",
        "\n",
        "encode_chars(ds[0][1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DhMXzOMaP0T",
        "outputId": "0796b11e-1df4-4985-eba2-c98b7cae8813"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2, 3, 4, 2, 1, 4, 3, 5, 2, 3, 5, 6, 3]"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 12) Bert"
      ],
      "metadata": {
        "id": "5Z0Ae54H2Sdh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "''' Bert is a cool model for\n",
        "natural language processing (nlp)\n",
        "and the models let us skip the\n",
        "sometimes tedious and long process\n",
        "Of training a large model.\n",
        "'''\n",
        "\n",
        "b = BertTokenizer.from_pretrained('bert-base-uncased',\n",
        "do_lower_case=True)\n",
        "\n",
        "b"
      ],
      "metadata": {
        "id": "Oo8r0tHS2Xt6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395,
          "referenced_widgets": [
            "7269cb2668d743c5889ae9b8367f6fb0",
            "d6d283357f8d4e1bb37ac6cea057c6df",
            "0254b489ac5241ea9152dc0a33ef0954",
            "bcc20d014e7b473899eb702d38b2fe6d",
            "dd024be897664549b8d119be5e1af17b",
            "6bc52b8fed80494385295c9c891b571f",
            "d3531bd1202c4e9b83790057e5655b83",
            "523a01b1071a48e792db6c8816d37494",
            "c5414f733ba04aee947adfb06a174413",
            "cb07117351424611912cb6ac01154b99",
            "4352906e874b4977a97f426af9676d32",
            "10b4ca0936a24b5eb60cf9fae01f6863",
            "168ad1ae237d4a75b5386d1ce0e72f32",
            "c8e8c170e29e49e09170a24612113052",
            "0440f24ad72a486db00ea5edd96c70f2",
            "7571a27cc3e94e22bd485a0dcc044c42",
            "6bff1982ce58424398a72235fc13f676",
            "caf16a3d487a4aafb5b8534db9294bd9",
            "88b7f755f5c74d1d9e8e8068e28c9272",
            "3c04010d176142d788320bd3e61b6cc1",
            "1653ba56b3a44268ad2db7a4b8718266",
            "cd8c9264b0b349d7a9a868772140c7ab",
            "8f6accedde934b14a09d916299f2f825",
            "d66f51748bd04b5292da7552b46b116b",
            "42b6d75298bc45d78be3f35e575e400b",
            "23a2f5af31f7447982da3ae17958af17",
            "2848fd2f90484422a120ad7283172acf",
            "ab075099b06b42548a7ce855084e0da8",
            "8c8cf34aa7374a4da04864b228ec15fe",
            "6a6afa3236fd4a649dff89bc6b481a03",
            "ecf7aba1aaf4487c9770009efbb828a3",
            "eff12c38679545459ee481edfee7ae03",
            "3c7eb858d65f48ac82ff37e42912b211",
            "6698438f50914737864dc497e07ac43a",
            "5fb2757cea0640bea8fefd7094dc0571",
            "a15bb2c32a4b452fa236d0727ac9ea41",
            "59c4837148e34a24aeb2b6128255ecfc",
            "4fff468347b64a15a29673d2af2bb704",
            "cce6b9bb6cdd44edbe70e65bb4c9b785",
            "fab711d07c3a49688e3adafdac95ec57",
            "ff65415a43034eb6baed85b41f74a84c",
            "d0cc249676894d2f85a4d84f90f47bab",
            "26552c8275e74de786b81cf18e779106",
            "a7685ebe7214444b8485ca39da2ae73c"
          ]
        },
        "outputId": "088987e7-9bcf-42ba-d61a-3f6f0f360556"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7269cb2668d743c5889ae9b8367f6fb0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "10b4ca0936a24b5eb60cf9fae01f6863"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8f6accedde934b14a09d916299f2f825"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6698438f50914737864dc497e07ac43a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertTokenizer(name_or_path='bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
              "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "''' The comment below is from my own personal Kaggle project found\n",
        "Here: https://www.kaggle.com/code/omarmoodie/social-media-pytorch-huggingface\n",
        "\n",
        "\"Using the tokenizer this way gets input_ids which are string\n",
        "to num conversions, and also puts in special tokens like 101,\n",
        "and 102 for us. Then includes the token_type_ids and\n",
        "attention_mask.\"\n",
        "\n",
        "Look at previous cell to see the special tokens mentioned\n",
        "In the comment.\n",
        "\n",
        "1) input IDs - string to num conversions according to the vocabulary.\n",
        "2) Token type IDs - Pays attention to certain parts of the converted\n",
        "string.\n",
        "3) Attention mask - Which of the converted nums to pay attention to\n",
        "\n",
        "All the above probably explained better than me, here:\n",
        "https://huggingface.co/docs/transformers/en/glossary\n",
        "\n",
        "'''\n",
        "\n",
        "ts = \"this is a test\"\n",
        "b(ts)"
      ],
      "metadata": {
        "id": "mf6fxP-22ZfO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcf22b36-8bfc-49f6-9f9e-093d2d68ac9a"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [101, 2023, 2003, 1037, 3231, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# .encode only gets input IDs\n",
        "b.encode(ts)"
      ],
      "metadata": {
        "id": "-jIedkQO2fM2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "490e7ba5-2aa0-45f9-ab9e-4242aa731fcd"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[101, 2023, 2003, 1037, 3231, 102]"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' encode plus mainly gives\n",
        "Extra OPTIONS to the user.\n",
        "Example below where I made sure add\n",
        "Special tokens was false so they\n",
        "Don't appear.\n",
        "\n",
        "See: https://stackoverflow.com/questions/61708486/whats-difference-between-tokenizer-encode-and-tokenizer-encode-plus-in-hugging\n",
        "And also see: https://huggingface.co/transformers/v2.11.0/main_classes/tokenizer.html\n",
        "'''\n",
        "b.encode_plus(ts,\n",
        "              add_special_tokens=False)"
      ],
      "metadata": {
        "id": "Bc9-s7J62iEd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "280a9292-177f-430a-d74b-86ebc581a273"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [2023, 2003, 1037, 3231], 'token_type_ids': [0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 13) Predictons"
      ],
      "metadata": {
        "id": "N0Tw5pnfzNpd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''' Not every portion of code aimed at model predictions is the same, but the below\n",
        "    few cells represent some ways I've collectively seen.\n",
        "\n",
        "    argmax(1) is useful because predictions for classes can use it. If there's\n",
        "    5 classes, like \"bike, car, scooter, skateboard, jetski\", all numbered 0-4,\n",
        "    then argmax will get the index of what the model predicted. I mainly did the\n",
        "    above code to test argmax things on a 2d tensor. Why? Because argmax(1)\n",
        "    goes row by row in a 2d column to get the index of the HIGHEST num in the\n",
        "    inner/nested tensor. But argmax(0) only works with 1d tensors.\n",
        "\n",
        "    Ex code:\n",
        "    \"r = t.tensor([3,5,7,22,5])\n",
        "     t.argmax(r, dim=0)\"\n",
        "    Gives: tensor(3).\n",
        "    And 3 is the index of course.\n",
        "\n",
        "'''\n",
        "\n",
        "# Same set of nums.\n",
        "t.manual_seed(0)\n",
        "\n",
        "# tt = test tensor, 2d shape\n",
        "tt = t.rand((5,5))\n",
        "\n",
        "# Create labels/ground_truths. tl = test labels\n",
        "tl = {\n",
        "    'bike':0,\n",
        "    'car':1,\n",
        "    'scooter':2,\n",
        "    'skateboard':3,\n",
        "    'jetski':4\n",
        "}\n",
        "\n",
        "print(f'Test labels:\\n{tl}\\n\\nTest tensor:\\n{tt}\\n\\n')\n",
        "\n",
        "# Dummy model predictions.\n",
        "x = tt.argmax(1)\n",
        "print(f'\"Model\" predictions:\\n{x}\\n\\n')\n",
        "\n",
        "# rtl = reversed test labels dictionary. Get labels from test labels\n",
        "rtl = {value:key for key, value in tl.items()}\n",
        "\n",
        "# Then convert the indices to real labels\n",
        "text_preds = [rtl[num.item()] for num in x]\n",
        "print(f'Real predicted labels:\\n{text_preds}\\n\\n')\n",
        "\n",
        "\n",
        "''' Since manual seed is used, when the code runs again, outputs\n",
        "    won't be the same. So to explain how it works, the tensor I'm\n",
        "    CURRENTLY seeing is:\n",
        "    \"tensor([[0.4963, 0.7682, 0.0885, 0.1320, 0.3074],\n",
        "        [0.6341, 0.4901, 0.8964, 0.4556, 0.6323],\n",
        "        [0.3489, 0.4017, 0.0223, 0.1689, 0.2939],\n",
        "        [0.5185, 0.6977, 0.8000, 0.1610, 0.2823],\n",
        "        [0.6816, 0.9152, 0.3971, 0.8742, 0.4194]])\"\n",
        "\n",
        "    First row the highest index is 1, with the value of 0.7682.\n",
        "    Hence why doing \"tt[0].argmax(0)\" gets 1. We can take that index\n",
        "    and translate it into a str prediction with the list using\n",
        "    \"text_preds[tt[0].argmax(0)]\". Since scooter is index 1, this gives\n",
        "    us scooter. '''\n",
        "text_preds[tt[0].argmax(0)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "WXquvLkhzPiM",
        "outputId": "d77cf186-4f86-496d-b5d0-ca5d93bef582"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test labels:\n",
            "{'bike': 0, 'car': 1, 'scooter': 2, 'skateboard': 3, 'jetski': 4}\n",
            "\n",
            "Test tensor:\n",
            "tensor([[0.4963, 0.7682, 0.0885, 0.1320, 0.3074],\n",
            "        [0.6341, 0.4901, 0.8964, 0.4556, 0.6323],\n",
            "        [0.3489, 0.4017, 0.0223, 0.1689, 0.2939],\n",
            "        [0.5185, 0.6977, 0.8000, 0.1610, 0.2823],\n",
            "        [0.6816, 0.9152, 0.3971, 0.8742, 0.4194]])\n",
            "\n",
            "\n",
            "\"Model\" predictions:\n",
            "tensor([1, 2, 1, 2, 1])\n",
            "\n",
            "\n",
            "Real predicted labels:\n",
            "['car', 'scooter', 'car', 'scooter', 'car']\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'scooter'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Simplier example of above\n",
        "# --- Testing argmax again\n",
        "\n",
        "classes = [\"Taco\", \"John\", \"Dog\"]\n",
        "\n",
        "test_preds = t.tensor([\n",
        "   [0.2, 0.1, 0.5],\n",
        "   [0.85, 0.50, 0.3],\n",
        "   [0.2, 0.92, 0.55]\n",
        "])\n",
        "\n",
        "''' get first row of 2d preds\n",
        "And get argmax 0 which gets the\n",
        "Highest value by its index in\n",
        "That row. Then of course apply\n",
        "That to to the list\n",
        "'''\n",
        "classes[test_preds[0].argmax(0)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "yRxAVHce3IQ4",
        "outputId": "b624c52f-7777-43a1-bcaa-771a5aec7260"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Dog'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' 3) Predictons and labels\n",
        "       In code projects something like \"torch.sum(predictions == labels).item()\" so\n",
        "       why not mess around with that here.\n",
        "\n",
        "       x = ground truths\n",
        "       y = predictions\n",
        "'''\n",
        "\n",
        "x = t.tensor([1,0,1,1,1,1,0,1]) # ground truths\n",
        "y = t.tensor([1,1,0,1,1,1,0,1]) # predictions\n",
        "\n",
        "''' == will get boolean vec on which columns MATCH. Ex in x and y above, index 0 is\n",
        "    both 1, so that's true, they equal eachother. Then the sum just how many Trues and\n",
        "    adds them since in a numerical fashion True is 1 and False is 0. So:\n",
        "    t.sum(tensor([ True, False, False,  True,  True,  True,  True,  True])) will be 6.\n",
        "    And of course .item just gets the number itself, out of the tensor. '''\n",
        "# print(x == y)\n",
        "# print(t.sum(x == y))\n",
        "print(t.sum(x == y).item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUUVsHboXQap",
        "outputId": "b5e9f1db-80af-4a22-ac17-421132a6e3ba"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 14) Tensor Dataset"
      ],
      "metadata": {
        "id": "OjOR69GnSpt0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "''' Takes a tensor and makes each\n",
        "Element an individual tensor.\n",
        "'''\n",
        "\n",
        "x = t.tensor([7,5,9])\n",
        "td = TensorDataset(x)\n",
        "\n",
        "for i in td:\n",
        "   print(i)"
      ],
      "metadata": {
        "id": "oqB_5bOnSpbV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7394813-4d32-42cb-9622-7d8189ea4994"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor(7),)\n",
            "(tensor(5),)\n",
            "(tensor(9),)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext import models\n",
        "\n",
        "''' different models that require\n",
        "Different args. Weights can also\n",
        "Be set to true to utilize them.\n",
        "'''\n",
        "\n",
        "# tm = test model\n",
        "tm = models.XLMR_LARGE_ENCODER\n",
        "\n",
        "tm"
      ],
      "metadata": {
        "id": "pzmFeVBhSw7H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4c0015b-b9b3-4243-c27f-6a3f1ba81bbd"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RobertaBundle(_encoder_conf=RobertaEncoderConf(vocab_size=250002, embedding_dim=1024, ffn_dimension=4096, padding_idx=1, max_seq_len=514, num_attention_heads=16, num_encoder_layers=24, dropout=0.1, scaling=None, normalize_before=False), _path='https://download.pytorch.org/models/text/xlmr.large.encoder.pt', _head=None, transform=<function <lambda> at 0x78ca2b84a4d0>)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7269cb2668d743c5889ae9b8367f6fb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d6d283357f8d4e1bb37ac6cea057c6df",
              "IPY_MODEL_0254b489ac5241ea9152dc0a33ef0954",
              "IPY_MODEL_bcc20d014e7b473899eb702d38b2fe6d"
            ],
            "layout": "IPY_MODEL_dd024be897664549b8d119be5e1af17b"
          }
        },
        "d6d283357f8d4e1bb37ac6cea057c6df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6bc52b8fed80494385295c9c891b571f",
            "placeholder": "",
            "style": "IPY_MODEL_d3531bd1202c4e9b83790057e5655b83",
            "value": "tokenizer_config.json:100%"
          }
        },
        "0254b489ac5241ea9152dc0a33ef0954": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_523a01b1071a48e792db6c8816d37494",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c5414f733ba04aee947adfb06a174413",
            "value": 28
          }
        },
        "bcc20d014e7b473899eb702d38b2fe6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb07117351424611912cb6ac01154b99",
            "placeholder": "",
            "style": "IPY_MODEL_4352906e874b4977a97f426af9676d32",
            "value": "28.0/28.0[00:00&lt;00:00,882B/s]"
          }
        },
        "dd024be897664549b8d119be5e1af17b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bc52b8fed80494385295c9c891b571f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3531bd1202c4e9b83790057e5655b83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "523a01b1071a48e792db6c8816d37494": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5414f733ba04aee947adfb06a174413": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cb07117351424611912cb6ac01154b99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4352906e874b4977a97f426af9676d32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "10b4ca0936a24b5eb60cf9fae01f6863": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_168ad1ae237d4a75b5386d1ce0e72f32",
              "IPY_MODEL_c8e8c170e29e49e09170a24612113052",
              "IPY_MODEL_0440f24ad72a486db00ea5edd96c70f2"
            ],
            "layout": "IPY_MODEL_7571a27cc3e94e22bd485a0dcc044c42"
          }
        },
        "168ad1ae237d4a75b5386d1ce0e72f32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6bff1982ce58424398a72235fc13f676",
            "placeholder": "",
            "style": "IPY_MODEL_caf16a3d487a4aafb5b8534db9294bd9",
            "value": "vocab.txt:100%"
          }
        },
        "c8e8c170e29e49e09170a24612113052": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88b7f755f5c74d1d9e8e8068e28c9272",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3c04010d176142d788320bd3e61b6cc1",
            "value": 231508
          }
        },
        "0440f24ad72a486db00ea5edd96c70f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1653ba56b3a44268ad2db7a4b8718266",
            "placeholder": "",
            "style": "IPY_MODEL_cd8c9264b0b349d7a9a868772140c7ab",
            "value": "232k/232k[00:00&lt;00:00,3.34MB/s]"
          }
        },
        "7571a27cc3e94e22bd485a0dcc044c42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bff1982ce58424398a72235fc13f676": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "caf16a3d487a4aafb5b8534db9294bd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "88b7f755f5c74d1d9e8e8068e28c9272": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c04010d176142d788320bd3e61b6cc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1653ba56b3a44268ad2db7a4b8718266": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd8c9264b0b349d7a9a868772140c7ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f6accedde934b14a09d916299f2f825": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d66f51748bd04b5292da7552b46b116b",
              "IPY_MODEL_42b6d75298bc45d78be3f35e575e400b",
              "IPY_MODEL_23a2f5af31f7447982da3ae17958af17"
            ],
            "layout": "IPY_MODEL_2848fd2f90484422a120ad7283172acf"
          }
        },
        "d66f51748bd04b5292da7552b46b116b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab075099b06b42548a7ce855084e0da8",
            "placeholder": "",
            "style": "IPY_MODEL_8c8cf34aa7374a4da04864b228ec15fe",
            "value": "tokenizer.json:100%"
          }
        },
        "42b6d75298bc45d78be3f35e575e400b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a6afa3236fd4a649dff89bc6b481a03",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ecf7aba1aaf4487c9770009efbb828a3",
            "value": 466062
          }
        },
        "23a2f5af31f7447982da3ae17958af17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eff12c38679545459ee481edfee7ae03",
            "placeholder": "",
            "style": "IPY_MODEL_3c7eb858d65f48ac82ff37e42912b211",
            "value": "466k/466k[00:00&lt;00:00,9.49MB/s]"
          }
        },
        "2848fd2f90484422a120ad7283172acf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab075099b06b42548a7ce855084e0da8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c8cf34aa7374a4da04864b228ec15fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a6afa3236fd4a649dff89bc6b481a03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ecf7aba1aaf4487c9770009efbb828a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eff12c38679545459ee481edfee7ae03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c7eb858d65f48ac82ff37e42912b211": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6698438f50914737864dc497e07ac43a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5fb2757cea0640bea8fefd7094dc0571",
              "IPY_MODEL_a15bb2c32a4b452fa236d0727ac9ea41",
              "IPY_MODEL_59c4837148e34a24aeb2b6128255ecfc"
            ],
            "layout": "IPY_MODEL_4fff468347b64a15a29673d2af2bb704"
          }
        },
        "5fb2757cea0640bea8fefd7094dc0571": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cce6b9bb6cdd44edbe70e65bb4c9b785",
            "placeholder": "",
            "style": "IPY_MODEL_fab711d07c3a49688e3adafdac95ec57",
            "value": "config.json:100%"
          }
        },
        "a15bb2c32a4b452fa236d0727ac9ea41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff65415a43034eb6baed85b41f74a84c",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d0cc249676894d2f85a4d84f90f47bab",
            "value": 570
          }
        },
        "59c4837148e34a24aeb2b6128255ecfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26552c8275e74de786b81cf18e779106",
            "placeholder": "",
            "style": "IPY_MODEL_a7685ebe7214444b8485ca39da2ae73c",
            "value": "570/570[00:00&lt;00:00,25.8kB/s]"
          }
        },
        "4fff468347b64a15a29673d2af2bb704": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cce6b9bb6cdd44edbe70e65bb4c9b785": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fab711d07c3a49688e3adafdac95ec57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff65415a43034eb6baed85b41f74a84c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0cc249676894d2f85a4d84f90f47bab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "26552c8275e74de786b81cf18e779106": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7685ebe7214444b8485ca39da2ae73c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}